{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "c08_regression_modelling_sklearn_gbr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python (dataSc)",
      "language": "python",
      "name": "datasc"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p0xjof2N44pA",
        "toc": "true"
      },
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-Description\" data-toc-modified-id=\"Data-Description-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data Description</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Important-Scripts\" data-toc-modified-id=\"Important-Scripts-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Important Scripts</a></span></li><li><span><a href=\"#Load-the-data\" data-toc-modified-id=\"Load-the-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Load the data</a></span></li><li><span><a href=\"#Log-transform-large-values\" data-toc-modified-id=\"Log-transform-large-values-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Log transform large values</a></span></li><li><span><a href=\"#Train-Test-split-after-log-transform\" data-toc-modified-id=\"Train-Test-split-after-log-transform-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Train-Test split after log transform</a></span></li><li><span><a href=\"#Scaling-the-Data\" data-toc-modified-id=\"Scaling-the-Data-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Scaling the Data</a></span></li><li><span><a href=\"#GBR-Modelling\" data-toc-modified-id=\"GBR-Modelling-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>GBR Modelling</a></span></li><li><span><a href=\"#GBR-modelling-using-pipeline\" data-toc-modified-id=\"GBR-modelling-using-pipeline-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>GBR modelling using pipeline</a></span></li><li><span><a href=\"#Cross-Validation-Results\" data-toc-modified-id=\"Cross-Validation-Results-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Cross Validation Results</a></span></li><li><span><a href=\"#HPO-(Hyper-Parameters-Optimization)\" data-toc-modified-id=\"HPO-(Hyper-Parameters-Optimization)-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>HPO (Hyper Parameters Optimization)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grid-Search-for-Gradient-Boosting-Regressor\" data-toc-modified-id=\"Grid-Search-for-Gradient-Boosting-Regressor-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>Grid Search for Gradient Boosting Regressor</a></span></li></ul></li><li><span><a href=\"#Hyper-Parameter-using-hyperopt-sklearn-for-Gradient-Boosting-Regressor\" data-toc-modified-id=\"Hyper-Parameter-using-hyperopt-sklearn-for-Gradient-Boosting-Regressor-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Hyper Parameter using hyperopt-sklearn for Gradient Boosting Regressor</a></span></li><li><span><a href=\"#Scale-data-for-hyperparameter-tuning\" data-toc-modified-id=\"Scale-data-for-hyperparameter-tuning-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Scale data for hyperparameter tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#HPO-without-scaling-the-data\" data-toc-modified-id=\"HPO-without-scaling-the-data-13.1\"><span class=\"toc-item-num\">13.1&nbsp;&nbsp;</span>HPO without scaling the data</a></span></li></ul></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VwrXuQrH44pE"
      },
      "source": [
        "# Data Description\n",
        "\n",
        "This dataset contains house sale prices for King County,\n",
        "which includes Seattle.\n",
        "It includes homes sold between May 2014 and May 2015.\n",
        "\n",
        "- Dependent features: 1 (price)\n",
        "- Features : 19 home features\n",
        "- Id:  1 house ID\n",
        "\n",
        "Task: Try to estimate the price based on given features.\n",
        "\n",
        "![](https://github.com/bhishanpdl/Project_House_Price_Prediction/blob/master/data/raw/data_description.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mcUE4kVk44pE"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:15.553817Z",
          "start_time": "2019-11-20T01:11:15.549974Z"
        },
        "colab_type": "code",
        "id": "tpMc6QvO44pF",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "IN_BHISHAN = 'bhishan' in sys.modules\n",
        "\n",
        "if IN_BHISHAN:\n",
        "    print('Environment: Personal environment')\n",
        "    import src\n",
        "    import bhishan\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:15.559295Z",
          "start_time": "2019-11-20T01:11:15.556158Z"
        },
        "colab_type": "code",
        "id": "FQX0h7dcOrHN",
        "outputId": "4455582e-aa67-4f48-b358-163950987415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    #!pip install hpsklearn\n",
        "\n",
        "    # set OMP_NUM_THREADS=1 for hpsklearn package\n",
        "    #!export OMP_NUM_THREADS=1\n",
        "    print('Environment: Google Colab')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Environment: Google Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:16.331694Z",
          "start_time": "2019-11-20T01:11:15.561180Z"
        },
        "colab_type": "code",
        "id": "ZFubck-r44pH",
        "outputId": "a9e5d4db-e12e-4092-f981-19f4dcf4cc7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set(color_codes=True)\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "# random state\n",
        "RANDOM_STATE=100\n",
        "np.random.seed(RANDOM_STATE) # we need this in each cell\n",
        "\n",
        "\n",
        "# Jupyter notebook settings for pandas\n",
        "pd.set_option('display.max_columns', 200)\n",
        "# pd.set_option('display.float_format', '{:,.4f}'.format) # numbers sep by comma\n",
        "pd.set_option('display.max_rows', 100) # None for all the rows\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "print([(x.__name__,x.__version__) for x in [np, pd,sns,matplotlib]])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('numpy', '1.17.4'), ('pandas', '0.25.3'), ('seaborn', '0.9.0'), ('matplotlib', '3.1.1')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:16.347214Z",
          "start_time": "2019-11-20T01:11:16.338933Z"
        },
        "colab_type": "code",
        "id": "oIXUJ81Z44pK",
        "outputId": "79ee582b-f43c-4dca-ffb8-9f8b1cb55481",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "%%javascript\n",
        "IPython.OutputArea.auto_scroll_threshold = 9999;"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.OutputArea.auto_scroll_threshold = 9999;"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:16.384736Z",
          "start_time": "2019-11-20T01:11:16.358013Z"
        },
        "colab_type": "code",
        "id": "Aq_hgFag44pM",
        "outputId": "6134a07c-492c-4b83-edb9-01416521046d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import scipy\n",
        "import sklearn\n",
        "\n",
        "print([(x.__name__,x.__version__) for x in [scipy, sklearn]])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('scipy', '1.3.2'), ('sklearn', '0.21.3')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:16.793651Z",
          "start_time": "2019-11-20T01:11:16.394609Z"
        },
        "colab_type": "code",
        "id": "qBmcsybv44pO",
        "colab": {}
      },
      "source": [
        "# scale and split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:16.800796Z",
          "start_time": "2019-11-20T01:11:16.795816Z"
        },
        "colab_type": "code",
        "id": "TC6HKGq_44pV",
        "colab": {}
      },
      "source": [
        "# pipeline\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:16.856953Z",
          "start_time": "2019-11-20T01:11:16.803460Z"
        },
        "id": "I4b6sMhUg7NK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classifier\n",
        "from sklearn.ensemble import GradientBoostingRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:16.863337Z",
          "start_time": "2019-11-20T01:11:16.859082Z"
        },
        "colab_type": "code",
        "id": "GtHea_AG44pX",
        "colab": {}
      },
      "source": [
        "# metrics\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:16.870647Z",
          "start_time": "2019-11-20T01:11:16.866443Z"
        },
        "colab_type": "code",
        "id": "R99zpuD_44pY",
        "colab": {}
      },
      "source": [
        "# cross validation\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:16.890258Z",
          "start_time": "2019-11-20T01:11:16.879471Z"
        },
        "colab_type": "code",
        "id": "dZRyd5ak44pa",
        "colab": {}
      },
      "source": [
        "df_eval = pd.DataFrame({'Model': [],\n",
        "                           'Details':[],\n",
        "                           'Root Mean Squared Error (RMSE)':[],\n",
        "                           'R-squared (training)':[],\n",
        "                           'Adjusted R-squared (training)':[],\n",
        "                           'R-squared (test)':[],\n",
        "                           'Adjusted R-squared (test)':[],\n",
        "                           '5-Fold Cross Validation':[]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_vArIrIYIRlc"
      },
      "source": [
        "# Important Scripts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:16.907111Z",
          "start_time": "2019-11-20T01:11:16.896053Z"
        },
        "colab_type": "code",
        "id": "71Gnb9Z9IT3g",
        "colab": {}
      },
      "source": [
        "def show_method_attributes(obj, ncols=7,start=None, inside=None):\n",
        "    \"\"\" Show all the attributes of a given method.\n",
        "    Example:\n",
        "    ========\n",
        "    show_method_attributes(list)\n",
        "     \"\"\"\n",
        "\n",
        "    print(f'Object Type: {type(obj)}\\n')\n",
        "    lst = [elem for elem in dir(obj) if elem[0]!='_' ]\n",
        "    lst = [elem for elem in lst \n",
        "           if elem not in 'os np pd sys time psycopg2'.split() ]\n",
        "\n",
        "    if isinstance(start,str):\n",
        "        lst = [elem for elem in lst if elem.startswith(start)]\n",
        "        \n",
        "    if isinstance(start,tuple) or isinstance(start,list):\n",
        "        lst = [elem for elem in lst for start_elem in start\n",
        "               if elem.startswith(start_elem)]\n",
        "        \n",
        "    if isinstance(inside,str):\n",
        "        lst = [elem for elem in lst if inside in elem]\n",
        "        \n",
        "    if isinstance(inside,tuple) or isinstance(inside,list):\n",
        "        lst = [elem for elem in lst for inside_elem in inside\n",
        "               if inside_elem in elem]\n",
        "\n",
        "    return pd.DataFrame(np.array_split(lst,ncols)).T.fillna('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:16.913612Z",
          "start_time": "2019-11-20T01:11:16.910072Z"
        },
        "colab_type": "code",
        "id": "H1JrjcmiK66M",
        "colab": {}
      },
      "source": [
        "def adjustedR2(rsquared,nrows,kcols):\n",
        "    return rsquared- (kcols-1)/(nrows-kcols) * (1-rsquared)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AopwXJ3B44pv"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:22.829290Z",
          "start_time": "2019-11-20T01:11:16.916884Z"
        },
        "colab_type": "code",
        "id": "efpgvfDk44px",
        "outputId": "66d643b2-73ed-4fa7-eae0-a3941fe06050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "# df_clean = pd.read_csv('../data/processed/data_cleaned_encoded.csv')\n",
        "df_clean = pd.read_csv('https://github.com/bhishanpdl/Project_House_Price_Prediction/blob/master/data/processed/data_cleaned_encoded.csv?raw=true')\n",
        "print(df_clean.shape)\n",
        "df_clean.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21613, 92)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>sqft_living15</th>\n",
              "      <th>sqft_lot15</th>\n",
              "      <th>yr_sales</th>\n",
              "      <th>age</th>\n",
              "      <th>yr_renovated2</th>\n",
              "      <th>age_after_renovation</th>\n",
              "      <th>zipcode_top10</th>\n",
              "      <th>zipcode_houses</th>\n",
              "      <th>basement_bool</th>\n",
              "      <th>renovation_bool</th>\n",
              "      <th>age_cat</th>\n",
              "      <th>age_after_renovation_cat</th>\n",
              "      <th>waterfront_0</th>\n",
              "      <th>waterfront_1</th>\n",
              "      <th>view_0</th>\n",
              "      <th>view_1</th>\n",
              "      <th>view_2</th>\n",
              "      <th>view_3</th>\n",
              "      <th>view_4</th>\n",
              "      <th>condition_1</th>\n",
              "      <th>condition_2</th>\n",
              "      <th>condition_3</th>\n",
              "      <th>condition_4</th>\n",
              "      <th>condition_5</th>\n",
              "      <th>grade_1</th>\n",
              "      <th>grade_10</th>\n",
              "      <th>grade_11</th>\n",
              "      <th>grade_12</th>\n",
              "      <th>grade_13</th>\n",
              "      <th>grade_3</th>\n",
              "      <th>grade_4</th>\n",
              "      <th>grade_5</th>\n",
              "      <th>grade_6</th>\n",
              "      <th>grade_7</th>\n",
              "      <th>grade_8</th>\n",
              "      <th>grade_9</th>\n",
              "      <th>zipcode_top10_98004</th>\n",
              "      <th>zipcode_top10_98006</th>\n",
              "      <th>zipcode_top10_98033</th>\n",
              "      <th>zipcode_top10_98039</th>\n",
              "      <th>zipcode_top10_98040</th>\n",
              "      <th>zipcode_top10_98102</th>\n",
              "      <th>zipcode_top10_98105</th>\n",
              "      <th>zipcode_top10_98155</th>\n",
              "      <th>zipcode_top10_98177</th>\n",
              "      <th>zipcode_top10_others</th>\n",
              "      <th>age_cat_0</th>\n",
              "      <th>age_cat_1</th>\n",
              "      <th>age_cat_2</th>\n",
              "      <th>age_cat_3</th>\n",
              "      <th>age_cat_4</th>\n",
              "      <th>age_cat_5</th>\n",
              "      <th>age_cat_6</th>\n",
              "      <th>age_cat_7</th>\n",
              "      <th>age_cat_8</th>\n",
              "      <th>age_cat_9</th>\n",
              "      <th>age_after_renovation_cat_0</th>\n",
              "      <th>age_after_renovation_cat_1</th>\n",
              "      <th>age_after_renovation_cat_2</th>\n",
              "      <th>age_after_renovation_cat_3</th>\n",
              "      <th>age_after_renovation_cat_4</th>\n",
              "      <th>age_after_renovation_cat_5</th>\n",
              "      <th>age_after_renovation_cat_6</th>\n",
              "      <th>age_after_renovation_cat_7</th>\n",
              "      <th>age_after_renovation_cat_8</th>\n",
              "      <th>age_after_renovation_cat_9</th>\n",
              "      <th>log1p_price</th>\n",
              "      <th>log1p_sqft_living</th>\n",
              "      <th>log1p_sqft_lot</th>\n",
              "      <th>log1p_sqft_above</th>\n",
              "      <th>log1p_sqft_basement</th>\n",
              "      <th>log1p_sqft_living15</th>\n",
              "      <th>log1p_sqft_lot15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7129300520</td>\n",
              "      <td>2014-10-13</td>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1180</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "      <td>1340</td>\n",
              "      <td>5650</td>\n",
              "      <td>2014</td>\n",
              "      <td>59</td>\n",
              "      <td>1955</td>\n",
              "      <td>59</td>\n",
              "      <td>others</td>\n",
              "      <td>262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12.309987</td>\n",
              "      <td>7.074117</td>\n",
              "      <td>8.639588</td>\n",
              "      <td>7.074117</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.201171</td>\n",
              "      <td>8.639588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6414100192</td>\n",
              "      <td>2014-12-09</td>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2570</td>\n",
              "      <td>7242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2170</td>\n",
              "      <td>400</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>98125</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>1690</td>\n",
              "      <td>7639</td>\n",
              "      <td>2014</td>\n",
              "      <td>63</td>\n",
              "      <td>1991</td>\n",
              "      <td>23</td>\n",
              "      <td>others</td>\n",
              "      <td>410</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.195616</td>\n",
              "      <td>7.852050</td>\n",
              "      <td>8.887791</td>\n",
              "      <td>7.682943</td>\n",
              "      <td>5.993961</td>\n",
              "      <td>7.433075</td>\n",
              "      <td>8.941153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5631500400</td>\n",
              "      <td>2015-02-25</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>770</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>770</td>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>98028</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>2720</td>\n",
              "      <td>8062</td>\n",
              "      <td>2015</td>\n",
              "      <td>82</td>\n",
              "      <td>1933</td>\n",
              "      <td>82</td>\n",
              "      <td>others</td>\n",
              "      <td>283</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12.100718</td>\n",
              "      <td>6.647688</td>\n",
              "      <td>9.210440</td>\n",
              "      <td>6.647688</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.908755</td>\n",
              "      <td>8.995041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2487200875</td>\n",
              "      <td>2014-12-09</td>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1960</td>\n",
              "      <td>5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1050</td>\n",
              "      <td>910</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>98136</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>1360</td>\n",
              "      <td>5000</td>\n",
              "      <td>2014</td>\n",
              "      <td>49</td>\n",
              "      <td>1965</td>\n",
              "      <td>49</td>\n",
              "      <td>others</td>\n",
              "      <td>263</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.311331</td>\n",
              "      <td>7.581210</td>\n",
              "      <td>8.517393</td>\n",
              "      <td>6.957497</td>\n",
              "      <td>6.814543</td>\n",
              "      <td>7.215975</td>\n",
              "      <td>8.517393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1954400510</td>\n",
              "      <td>2015-02-18</td>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1680</td>\n",
              "      <td>8080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1680</td>\n",
              "      <td>0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>98074</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "      <td>1800</td>\n",
              "      <td>7503</td>\n",
              "      <td>2015</td>\n",
              "      <td>28</td>\n",
              "      <td>1987</td>\n",
              "      <td>28</td>\n",
              "      <td>others</td>\n",
              "      <td>441</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.142168</td>\n",
              "      <td>7.427144</td>\n",
              "      <td>8.997271</td>\n",
              "      <td>7.427144</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.496097</td>\n",
              "      <td>8.923191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id        date     price  bedrooms  bathrooms  sqft_living  \\\n",
              "0  7129300520  2014-10-13  221900.0         3       1.00         1180   \n",
              "1  6414100192  2014-12-09  538000.0         3       2.25         2570   \n",
              "2  5631500400  2015-02-25  180000.0         2       1.00          770   \n",
              "3  2487200875  2014-12-09  604000.0         4       3.00         1960   \n",
              "4  1954400510  2015-02-18  510000.0         3       2.00         1680   \n",
              "\n",
              "   sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
              "0      5650     1.0           0     0          3      7        1180   \n",
              "1      7242     2.0           0     0          3      7        2170   \n",
              "2     10000     1.0           0     0          3      6         770   \n",
              "3      5000     1.0           0     0          5      7        1050   \n",
              "4      8080     1.0           0     0          3      8        1680   \n",
              "\n",
              "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
              "0              0      1955             0    98178  47.5112 -122.257   \n",
              "1            400      1951          1991    98125  47.7210 -122.319   \n",
              "2              0      1933             0    98028  47.7379 -122.233   \n",
              "3            910      1965             0    98136  47.5208 -122.393   \n",
              "4              0      1987             0    98074  47.6168 -122.045   \n",
              "\n",
              "   sqft_living15  sqft_lot15  yr_sales  age  yr_renovated2  \\\n",
              "0           1340        5650      2014   59           1955   \n",
              "1           1690        7639      2014   63           1991   \n",
              "2           2720        8062      2015   82           1933   \n",
              "3           1360        5000      2014   49           1965   \n",
              "4           1800        7503      2015   28           1987   \n",
              "\n",
              "   age_after_renovation zipcode_top10  zipcode_houses  basement_bool  \\\n",
              "0                    59        others             262              0   \n",
              "1                    23        others             410              1   \n",
              "2                    82        others             283              0   \n",
              "3                    49        others             263              1   \n",
              "4                    28        others             441              0   \n",
              "\n",
              "   renovation_bool  age_cat  age_after_renovation_cat  waterfront_0  \\\n",
              "0                0        5                         5             1   \n",
              "1                1        5                         2             1   \n",
              "2                0        7                         7             1   \n",
              "3                0        4                         4             1   \n",
              "4                0        2                         2             1   \n",
              "\n",
              "   waterfront_1  view_0  view_1  view_2  view_3  view_4  condition_1  \\\n",
              "0             0       1       0       0       0       0            0   \n",
              "1             0       1       0       0       0       0            0   \n",
              "2             0       1       0       0       0       0            0   \n",
              "3             0       1       0       0       0       0            0   \n",
              "4             0       1       0       0       0       0            0   \n",
              "\n",
              "   condition_2  condition_3  condition_4  condition_5  grade_1  grade_10  \\\n",
              "0            0            1            0            0        0         0   \n",
              "1            0            1            0            0        0         0   \n",
              "2            0            1            0            0        0         0   \n",
              "3            0            0            0            1        0         0   \n",
              "4            0            1            0            0        0         0   \n",
              "\n",
              "   grade_11  grade_12  grade_13  grade_3  grade_4  grade_5  grade_6  grade_7  \\\n",
              "0         0         0         0        0        0        0        0        1   \n",
              "1         0         0         0        0        0        0        0        1   \n",
              "2         0         0         0        0        0        0        1        0   \n",
              "3         0         0         0        0        0        0        0        1   \n",
              "4         0         0         0        0        0        0        0        0   \n",
              "\n",
              "   grade_8  grade_9  zipcode_top10_98004  zipcode_top10_98006  \\\n",
              "0        0        0                    0                    0   \n",
              "1        0        0                    0                    0   \n",
              "2        0        0                    0                    0   \n",
              "3        0        0                    0                    0   \n",
              "4        1        0                    0                    0   \n",
              "\n",
              "   zipcode_top10_98033  zipcode_top10_98039  zipcode_top10_98040  \\\n",
              "0                    0                    0                    0   \n",
              "1                    0                    0                    0   \n",
              "2                    0                    0                    0   \n",
              "3                    0                    0                    0   \n",
              "4                    0                    0                    0   \n",
              "\n",
              "   zipcode_top10_98102  zipcode_top10_98105  zipcode_top10_98155  \\\n",
              "0                    0                    0                    0   \n",
              "1                    0                    0                    0   \n",
              "2                    0                    0                    0   \n",
              "3                    0                    0                    0   \n",
              "4                    0                    0                    0   \n",
              "\n",
              "   zipcode_top10_98177  zipcode_top10_others  age_cat_0  age_cat_1  age_cat_2  \\\n",
              "0                    0                     1          0          0          0   \n",
              "1                    0                     1          0          0          0   \n",
              "2                    0                     1          0          0          0   \n",
              "3                    0                     1          0          0          0   \n",
              "4                    0                     1          0          0          1   \n",
              "\n",
              "   age_cat_3  age_cat_4  age_cat_5  age_cat_6  age_cat_7  age_cat_8  \\\n",
              "0          0          0          1          0          0          0   \n",
              "1          0          0          1          0          0          0   \n",
              "2          0          0          0          0          1          0   \n",
              "3          0          1          0          0          0          0   \n",
              "4          0          0          0          0          0          0   \n",
              "\n",
              "   age_cat_9  age_after_renovation_cat_0  age_after_renovation_cat_1  \\\n",
              "0          0                           0                           0   \n",
              "1          0                           0                           0   \n",
              "2          0                           0                           0   \n",
              "3          0                           0                           0   \n",
              "4          0                           0                           0   \n",
              "\n",
              "   age_after_renovation_cat_2  age_after_renovation_cat_3  \\\n",
              "0                           0                           0   \n",
              "1                           1                           0   \n",
              "2                           0                           0   \n",
              "3                           0                           0   \n",
              "4                           1                           0   \n",
              "\n",
              "   age_after_renovation_cat_4  age_after_renovation_cat_5  \\\n",
              "0                           0                           1   \n",
              "1                           0                           0   \n",
              "2                           0                           0   \n",
              "3                           1                           0   \n",
              "4                           0                           0   \n",
              "\n",
              "   age_after_renovation_cat_6  age_after_renovation_cat_7  \\\n",
              "0                           0                           0   \n",
              "1                           0                           0   \n",
              "2                           0                           1   \n",
              "3                           0                           0   \n",
              "4                           0                           0   \n",
              "\n",
              "   age_after_renovation_cat_8  age_after_renovation_cat_9  log1p_price  \\\n",
              "0                           0                           0    12.309987   \n",
              "1                           0                           0    13.195616   \n",
              "2                           0                           0    12.100718   \n",
              "3                           0                           0    13.311331   \n",
              "4                           0                           0    13.142168   \n",
              "\n",
              "   log1p_sqft_living  log1p_sqft_lot  log1p_sqft_above  log1p_sqft_basement  \\\n",
              "0           7.074117        8.639588          7.074117             0.000000   \n",
              "1           7.852050        8.887791          7.682943             5.993961   \n",
              "2           6.647688        9.210440          6.647688             0.000000   \n",
              "3           7.581210        8.517393          6.957497             6.814543   \n",
              "4           7.427144        8.997271          7.427144             0.000000   \n",
              "\n",
              "   log1p_sqft_living15  log1p_sqft_lot15  \n",
              "0             7.201171          8.639588  \n",
              "1             7.433075          8.941153  \n",
              "2             7.908755          8.995041  \n",
              "3             7.215975          8.517393  \n",
              "4             7.496097          8.923191  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:24.582427Z",
          "start_time": "2019-11-20T01:11:22.832361Z"
        },
        "colab_type": "code",
        "id": "8m7Fw_XU44pw",
        "outputId": "c7525ebd-b593-4e83-850f-17546abd0959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# I will just take column names from this and will use cleaned data further.\n",
        "# df_raw = pd.read_csv('../data/raw/kc_house_data.csv')\n",
        "df_raw = pd.read_csv('https://github.com/bhishanpdl/Project_House_Price_Prediction/blob/master/data/raw/kc_house_data.csv?raw=true',nrows=1)\n",
        "df_raw.columns"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
              "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
              "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
              "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:24.591503Z",
          "start_time": "2019-11-20T01:11:24.584581Z"
        },
        "colab_type": "code",
        "id": "C8_gawQE44p5",
        "colab": {}
      },
      "source": [
        "features_raw_all = ['bedrooms', 'bathrooms', 'sqft_living',\n",
        "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
        "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
        "       'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
        "\n",
        "df = df_clean[features_raw_all + ['price']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rz_Ixx6944p7"
      },
      "source": [
        "# Log transform large values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:24.649735Z",
          "start_time": "2019-11-20T01:11:24.594811Z"
        },
        "colab_type": "code",
        "id": "l_hbgsndhI0J",
        "outputId": "52e1ee62-2bec-4802-beb6-b8cf38f530a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "log_cols = ['price','sqft_living','sqft_living15','sqft_lot','sqft_lot15']\n",
        "\n",
        "for col in log_cols:\n",
        "    df[col] = np.log1p(df[col].to_numpy())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qLTMmNdOhVKE"
      },
      "source": [
        "# Train-Test split after log transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:24.708584Z",
          "start_time": "2019-11-20T01:11:24.667849Z"
        },
        "colab_type": "code",
        "id": "6wk_ZV6U44p8",
        "outputId": "06454b99-ad42-4c87-841c-f8c38653fa5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X = df[features_raw_all].to_numpy()\n",
        "\n",
        "y = df['price'].to_numpy()\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split (X,y,test_size=0.20,\n",
        "                                                 random_state=RANDOM_STATE)\n",
        "\n",
        "Xtrain.shape, ytrain.shape, Xtest.shape, ytest.shape, Xtrain[0][:2], Xtest[0][:2]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17290, 18),\n",
              " (17290,),\n",
              " (4323, 18),\n",
              " (4323,),\n",
              " array([3.  , 1.75]),\n",
              " array([3. , 2.5]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeRorpmJg7Ni",
        "colab_type": "text"
      },
      "source": [
        "# Scaling the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:24.731018Z",
          "start_time": "2019-11-20T01:11:24.711429Z"
        },
        "id": "2Gr0xGrng7Ni",
        "colab_type": "code",
        "outputId": "a2e388d4-eb87-4d8d-f44b-ed6892af3793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(Xtrain)\n",
        "\n",
        "Xtrain_scaled = scaler.transform(Xtrain)\n",
        "Xtest_scaled = scaler.transform(Xtest)\n",
        "\n",
        "Xtrain_scaled[0][:2], Xtest_scaled[0][:2]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.39032991, -0.46881139]), array([-0.39032991,  0.50625765]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZgVaQWtg7Nl",
        "colab_type": "text"
      },
      "source": [
        "# GBR Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:25.921626Z",
          "start_time": "2019-11-20T01:11:24.736324Z"
        },
        "id": "BiK88lVug7Nm",
        "colab_type": "code",
        "outputId": "02c3ba72-23d7-42d2-fbc6-d2c20a5fe617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "model = GradientBoostingRegressor()\n",
        "model.fit(Xtrain_scaled,ytrain)\n",
        "\n",
        "show_method_attributes(model)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Object Type: <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>alpha</td>\n",
              "      <td>get_params</td>\n",
              "      <td>max_depth</td>\n",
              "      <td>min_samples_leaf</td>\n",
              "      <td>n_estimators_</td>\n",
              "      <td>random_state</td>\n",
              "      <td>tol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apply</td>\n",
              "      <td>init</td>\n",
              "      <td>max_features</td>\n",
              "      <td>min_samples_split</td>\n",
              "      <td>n_features_</td>\n",
              "      <td>score</td>\n",
              "      <td>train_score_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>criterion</td>\n",
              "      <td>init_</td>\n",
              "      <td>max_features_</td>\n",
              "      <td>min_weight_fraction_leaf</td>\n",
              "      <td>n_iter_no_change</td>\n",
              "      <td>set_params</td>\n",
              "      <td>validation_fraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>estimators_</td>\n",
              "      <td>learning_rate</td>\n",
              "      <td>max_leaf_nodes</td>\n",
              "      <td>n_classes_</td>\n",
              "      <td>predict</td>\n",
              "      <td>staged_predict</td>\n",
              "      <td>verbose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>feature_importances_</td>\n",
              "      <td>loss</td>\n",
              "      <td>min_impurity_decrease</td>\n",
              "      <td>n_estimators</td>\n",
              "      <td>presort</td>\n",
              "      <td>subsample</td>\n",
              "      <td>warm_start</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>fit</td>\n",
              "      <td>loss_</td>\n",
              "      <td>min_impurity_split</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      0              1                      2  \\\n",
              "0                 alpha     get_params              max_depth   \n",
              "1                 apply           init           max_features   \n",
              "2             criterion          init_          max_features_   \n",
              "3           estimators_  learning_rate         max_leaf_nodes   \n",
              "4  feature_importances_           loss  min_impurity_decrease   \n",
              "5                   fit          loss_     min_impurity_split   \n",
              "\n",
              "                          3                 4               5  \\\n",
              "0          min_samples_leaf     n_estimators_    random_state   \n",
              "1         min_samples_split       n_features_           score   \n",
              "2  min_weight_fraction_leaf  n_iter_no_change      set_params   \n",
              "3                n_classes_           predict  staged_predict   \n",
              "4              n_estimators           presort       subsample   \n",
              "5                                                               \n",
              "\n",
              "                     6  \n",
              "0                  tol  \n",
              "1         train_score_  \n",
              "2  validation_fraction  \n",
              "3              verbose  \n",
              "4           warm_start  \n",
              "5                       "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:26.410006Z",
          "start_time": "2019-11-20T01:11:25.925236Z"
        },
        "id": "MpznfBnvg7Nn",
        "colab_type": "code",
        "outputId": "3a458ff9-1e32-4b0b-e015-fff3cd830b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        }
      },
      "source": [
        "ypreds = model.predict(Xtest_scaled)\n",
        "\n",
        "# rmse\n",
        "rmse = np.sqrt(sklearn.metrics.mean_squared_error(ytest,ypreds))\n",
        "print(f'Test RMSE: {rmse}')\n",
        "\n",
        "# r-squared values\n",
        "r2 = sklearn.metrics.r2_score(ytest, ypreds)\n",
        "ar2 = adjustedR2(r2, Xtest_scaled.shape[0], Xtest_scaled.shape[1])\n",
        "print('r_squared: ', r2)\n",
        "print('adjustedr2: ', ar2)\n",
        "\n",
        "# feature importance\n",
        "df_imp = pd.DataFrame({'Feature': features_raw_all,\n",
        "                       'Importance': model.feature_importances_\n",
        "                       }) \n",
        "df_imp.sort_values('Importance').set_index('Feature').sort_values('Importance').plot.barh(figsize=(12,8))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test RMSE: 0.18540888671808947\n",
            "r_squared:  0.8773803471582997\n",
            "adjustedr2:  0.8768961348241977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3a9121bb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxgAAAHUCAYAAAC5yI6CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzde5hddX3v8feECAgZLh3GK8cmtZ6v\nIEhsAyo2lSiFQoUca0AqUMAIRalSvBRbUdGmaluoQMFjqZGL4qWK5QAiRIJRUFCCJgHBr6Kk3ooZ\nYzQzkgwkM+ePtaKbIZfZydqz197zfj0PD3uv63fvb+0zH36/39o9o6OjSJIkSVIVprS7AEmSJEnd\nw4AhSZIkqTIGDEmSJEmVMWBIkiRJqszUdhegSu0CHAz8D7CxzbVIkiSpO+0EPB24Gxgeu9OA0V0O\nBm5vdxGSJEmaFGYDd4zdaMDoLv8DsGbNrxkZ8fHDddLXN43Vq4faXYbGsC/1ZF/qyb7Uk32pp27v\ny5QpPey99+5Q/u05lgGju2wEGBkZNWDUkD2pJ/tST/alnuxLPdmXepokfdnslHwXeUuSJEmqjAFD\nkiRJUmUMGJIkSZIq0zM6Oinmh00W04GH2l2EJEmSWmv98AYG165ry72nTOmhr28awAxg5dj9LvLu\nQvMXLGLVmvb8H5wkSZJa74YL5zLY7iK2wClSkiRJkipjwGiDiBiNiGnbOGaviPjbiapJkiRJqoIB\no772AgwYkiRJ6iiuwWiziLgAeCmwM/Bz4LWZ+d/AZcBeEbEMeCQzD21jmZIkSdK4GDDa7wOZ+VaA\niHgd8E/ACcBZwNLMnNnO4iRJkqRmGDDa76iIOAuYhv2QJEnSOPX397a7hM3yD9o2iojfBT4IHJyZ\nD0XEocAn2lyWJEmSOsDAQHseVNvwOxib3z+BteiJ9gAeBR6OiCnAmQ371gK7RYQhUJIkSR3DgNFG\nmXkv8BngfuDrNPwKd2b+ArgGuDcivtaeCiVJkqTm+F/H2yAzexpenw2c3bD73Q37Tp/IuiRJkqQd\n5QiGJEmSpMr0jI6OtrsGVWc6DdOsJEmS1J3WD29gcO26tty7YZH3DGDl2P1OkepCq1cPMTJicKyT\n/v7etj3pQVtmX+rJvtSTfakn+1JPk70vTpGSJEmSVBkDhiRJkqTKGDAkSZIkVcaAIUmSJKkyBgxJ\nkiRJlTFgSJIkSaqMAUOSJElSZQwYkiRJkipjwJAkSZJUGQOGJEmSpMr0jI6OtrsGVWc68FC7i5Ak\nSWqH9cMbGFy7rt1l0N/fy8DAYLvLaJkpU3ro65sGMANYOXb/1IkuSK03f8EiVq1p//+4JEmSJtIN\nF86le/+s7xxOkaqBiLgyIv663XVIkiRJO8qA0QIR4ciQJEmSJiX/EG5SRLwK+EdgHfCZ8nUvMAi8\nB/gz4OaI+E/gQ8DuwK7A5Zl5UXmNZwJXA0+nmLc20nD9PYB/BZ5fnvcl4M2ZuXECPp4kSZK0QxzB\naEJEPBW4HDgmM19AETIarcvMgzPznRTB4fDM/APgEOCMiNivPO4S4CuZuT/w18BLG67xr8CXM/MQ\nYCbwFOC1rfpMkiRJUpUcwWjOC4FvZub3yvcfpQgEm1zV8Ho34P9GxEEUIxTPAA4CHgDmAG8CyMwf\nRMTihvOOBQ6JiLc0XOfHVX8QSZKkbtTf39vuEoD61NEOBoxqDTW8fh/wMHBqZm6IiEUUU562pQf4\nP5n5g1YUKEmS1M3q8HjYSfSY2s3vn8BausHXgT+IiGeX70/ZyrF7AT8qw8UBwOyGfbcBpwFExAzg\n5Q37rgfeHhE7lfv3KY+RJEmSas+A0YTM/BlwJnBTRHwL6AceAx7ZzOELgNMjYgVwPvCVhn1nA3Mi\n4n7gUmBJw76/ATYCyyPiXuBm4JnVfhJJkiSpNZwi1bybM/MzABFxGvCNzByhmNr0G5n5LeCAzV0g\nM3/C40ctGvcNAq+vtGJJkiRpghgwmvemiDiO4rv7BXB6m+uRJEmSaqNndHS03TWoOtOBh9pdhCRJ\nUjusH97A4NqxvyIw8SbRIu8ZFD/N8DiOYHSh1auHGBkxONZJt/8/mk5lX+rJvtSTfakn+6I6cpG3\nJEmSpMoYMCRJkiRVxoAhSZIkqTIGDEmSJEmVMWBIkiRJqowBQ5IkSVJlDBiSJEmSKmPAkCRJklQZ\nA4YkSZKkyhgwJEmSJFWmZ3R0tN01qDrTgYfaXYQkSVIz1g9vYHDtunaXUZn+/l4GBgbbXUbLTJnS\nQ1/fNIAZwMqx+6dOdEFqvfkLFrFqTff8j1SSJHW3Gy6cS/f+OT75OEVKkiRJUmUMGJIkSZIqM6kD\nRkQsiIjvRMTtETE9Is4YxzmnRsRny9ezIuKacZzz3oh4dRU1S5IkSXU22ddgvAV4VmYORMRhwBnA\n5eM9OTOXAieO47h3bXeFkiRJUgfpmoAREbsBVwHPAx4DMjOPj4gFwAnAGmAJMCczZ0XE7cCuwOKI\nuAU4GpgREcuABzNz3jjueRhwQXm9jwD3ZubF5b4DgOuBZwNXAEsz89KIOB8IYE/g94DvA8dl5iMR\nsSfw0fIz/KT8Z1VmvnXHvyFJkqT66u/vbXcJleq2z9OMrgkYwJHAHpm5P0BE7B0RxwDHAjOBdcB1\nmw7OzNkRMQocmplDEfF5yrCwnfe/ErgEuLh8fxpwZWaORsTYY2cBBwO/Am6hGAX5D+BdwJrMfG5E\n/A5wD3DtdtYjSZLUMbrpsa6T6DG1m98/gbW02nJgv4i4LCKOA4aBOcCnM3MoMzcCC1t188y8A+iN\niAMjYirwFxQjKptzS2b+MjNHga9TjHJQ1ntFeb1f0BCIJEmSpE7QNQEjM39AMbXoi8DhFIFjol0F\nnAocBTyQmf+9hePWN7zeSHeNJEmSJGkS65qAERH7Ahsz8zrgHKAfWAYcHxG7R8ROFNOWtmQtxbqI\nHXE1xcjF6yhHIpq0BPhLgIjYC5i7g/VIkiRJE6prAgZwIHBnRCwHvgG8PzOvBm6kGM24C/juVs5f\nAWRE3LfpMbTNyswfAvcDhwGf245LvBd4SkR8B/gvYCnFOg1JkiSpI/SMjo62u4YJ0/jUp3bXsjkR\n8SRgp8xcHxF7AHcAb87MW8d5ienAQ62qT5IkqRXWD29gcO26dpdRmUm0yHsGsHLsfuf+18vewBfK\n6Vy7Ap9oIlz8xurVQ4yMTJ7g2Am6/f/RdCr7Uk/2pZ7sSz3ZF9XRpAoYmbmE4hGx2xQRS3ni93NX\nZp5ZdV2bZOYq4A9bdX1JkiSp1SZVwGhGXadRSZIkSXXWTYu8JUmSJLWZAUOSJElSZQwYkiRJkipj\nwJAkSZJUGQOGJEmSpMoYMCRJkiRVxoAhSZIkqTIGDEmSJEmV8Yf2ulBf37R2l1C59cMbGFy7rt1l\nSJIkaRsMGF1o/oJFrFrTXX+M33DhXAbbXYQkSZK2ySlSkiRJkipjwJAkSZJUma6YIhURC4B5wABw\nMnBEZl6+jXNOBV6RmfMiYhZwTmaeuI1z3gt8OzM/vQO1zgQuA14A3JSZ88bUdBGwstz0UGa+cnvv\nJUmSJE20rggYwFuAZ2XmQEQcBpwBbDVgNMrMpcBWw0V53Lu2u8LfWgW8GZgJ/Mlm9t/aGDokSZKk\nTlK7gBERuwFXAc8DHgMyM48vRylOANYAS4A5mTkrIm4HdgUWR8QtwNHAjIhYBjw4nj/Wy1ByQXm9\njwD3ZubF5b4DgOuBZwNXAEsz89KIOB8IYE/g94DvA8dl5iMRsSfw0fIz/KT8Z1VmvjUzfwr8NCL2\n2+Eva5Lp7+9tdwk7pNPr71b2pZ7sSz3Zl3qyL/U0mftSu4ABHAnskZn7A0TE3hFxDHAsxX/1Xwdc\nt+ngzJwdEaPAoZk5FBGfpwwL23n/K4FLgIvL96cBV2bmaESMPXYWcDDwK+AWilGQ/wDeBazJzOdG\nxO8A9wDXjvP+Ly3D0VrgnzLz89v5ObrOwEDnPkeqv7+3o+vvVvalnuxLPdmXerIv9dTtfZkypWer\nP4tQx0Xey4H9IuKyiDgOGAbmAJ/OzKHM3AgsbNXNM/MOoDciDoyIqcBfUIyobM4tmfnLzBwFvk4x\nykFZ7xXl9X5BQyDahhsppnrNBM4GFjrSIUmSpE5Su4CRmT+gmFr0ReBwisAx0a4CTgWOAh7IzP/e\nwnHrG15vZAdHhDLz55m5rnz9LeCrwCE7ck1JkiRpItUuYETEvsDGzLwOOAfoB5YBx0fE7hGxE8W0\npS1ZS7EuYkdcTTFy8TrKkYgmLQH+EiAi9gLmjuekiHhmw+vfBV4ErNiO+0uSJEltUcc1GAcCHyjX\nO+wEvD8zr45iw3J+u8j7mVs4fwWQEXEf8J3teSJTZv4wIu4HDqMIGs16L3BFRHwH+B9gKcU6DSJi\nOnAHsBuwa0T8GHh3Zi4EzoqIucCG8jp/X45kSJIkSR2hZ3R0tN01NK3xqU/trmVzIuJJwE6ZuT4i\n9qAIFG/OzFtbfOvpwEMtvkdbrB/ewODade0uY7t1+2KvTmVf6sm+1JN9qSf7Uk/d3peGRd4z+O3v\nt/1GHUcwusHewBfK6Vy7Ap+YgHDxG6tXDzEy0nnBUZIkSZ2vIwNGZi6heETsNkXEUp74Oe/KzDOr\nrmuTzFwF/GGrri9JkiTVVUcGjGbUdRqVJEmS1I1q9xQpSZIkSZ3LgCFJkiSpMgYMSZIkSZUxYEiS\nJEmqjAFDkiRJUmUMGJIkSZIqY8CQJEmSVBkDhiRJkqTKdP0P7U1GfX3T2l3CuKwf3sDg2nXtLkOS\nJEkVMmB0ofkLFrFqTf3/cL/hwrkMtrsISZIkVcopUpIkSZIqY8CoUESMRkRnzE+SJEmSWsCAIUmS\nJKkyrsFokYg4GLgE2B34NfCmzLw7IqYDS4F/B44GdgPmZ+Yd5Xl/DZwN/BK4CTgrM/eZ+E8gSZIk\nNc+A0QIRsTNwLXBaZi6OiMOBayPi98tD+oA7M/MdEXEi8E/ASyLi+cDfATMzcyAiLm7LB5hA/f29\n7S5hwkymz9pJ7Es92Zd6si/1ZF/qaTL3xYDRGgE8mpmLATLz1oh4tNw+CAxl5o3lsXcBF5avDwNu\nysyB8v1HgRMnrOo2GBiYHM+R6u/vnTSftZPYl3qyL/VkX+rJvtRTt/dlypSerf4sgmsw2mO44fVG\nDHqSJEnqEgaM1khg54iYAxARLwOeVG7fmi8DR0XEpjUXp7SuREmSJKl6BowWyMxHgVcB74uIFcA/\nAvPK7Vs7bznwz8CdEXEPsAH4VavrlSRJkqri1JwKZWZPw+u7gRdv5piVwD5beg9ckZmXAETE+cCd\nralWkiRJqp4Bo34+EBEvAXYGfgCc0ewFFp53ROVFtcL64Q3tLkGSJEkVM2DUTGaetaPXWL16iJGR\n0SrKkSRJkpriGgxJkiRJlTFgSJIkSaqMAUOSJElSZQwYkiRJkipjwJAkSZJUGQOGJEmSpMoYMCRJ\nkiRVxoAhSZIkqTIGDEmSJEmVMWBIkiRJqszUdheg6vX1TWt3CVu0fngDg2vXtbsMSZIktYgBowvN\nX7CIVWvq+Uf8DRfOZbDdRUiSJKllnCIlSZIkqTIGjBaKiDMj4px21yFJkiRNFKdItVBmfrjdNUiS\nJEkTyYBRgYg4D+jLzHPK931AAlcAPZn51nL7ucCrKL73nwCnZ+bDEfET4AWZuSoibgJGM/PPIuIp\nwDczc982fCxJkiSpaQaMalwNfD0i3paZG4DXANcDvwamAUTEScCzgRdl5khEvB64EDgR+BLwsoi4\nFpgBjEbEk4CXl/u6Sn9/b7tLaIvJ+rnrzr7Uk32pJ/tST/alniZzXwwYFcjMH0bEt4GjKYLFqcA5\nwMsaDjsWmAV8MyKg+O5/Ve5bDBxOMapxF9ADvLDcdlvrP8HEGhiYfM+R6u/vnZSfu+7sSz3Zl3qy\nL/VkX+qp2/syZUrPVn8WwYBRnSuBUyLiIWBP4HYeHzB6gAWZ+dHNnHsb8C7gxxRho4di9OLlwHta\nWLMkSZJUKZ8iVZ3PAX8MvAW4MjNHx+y/HnhDROwNEBG7RMRBAJn538BG4BSKgLGYYhTkscz84cSU\nL0mSJO04A0ZFMvMR4P8BJ1OsyRi7/2PANcCXI2IFcA/wkoZDFgOPZOb/ZOZPgXV04fQoSZIkdTen\nSFUoM18HvK7h/flj9n8Q+OAWzv2rMe/3b0GJkiRJUksZMLrQwvOOaHcJW7R+eEO7S5AkSVILGTC6\n0OrVQ4yMjF0CIkmSJLWeazAkSZIkVcaAIUmSJKkyBgxJkiRJlTFgSJIkSaqMAUOSJElSZQwYkiRJ\nkipjwJAkSZJUGQOGJEmSpMoYMCRJkiRVxoAhSZIkqTJT212AqtfXN63dJWzW+uENDK5d1+4yJEmS\n1EIGjC40f8EiVq2p3x/yN1w4l8F2FyFJkqSWcoqUJEmSpMoYMCRJkiRVxoBRgYg4NSI+ux3nnRkR\n54y9RkRMj4gzqq5TkiRJajXXYIxTREwBRjNztKprZuaHt7BrOnAGcHlV95IkSZImggEDiIi3AdMz\n86zy/VOBFcBVwAxgT+BZwIuBNVu4zJ4RcT3w+8DDwMmZ+ZOIOB+YlplvLa/9m/dj9zW4DJgREcuA\nBzNzXmUfts36+3vbXULbTObPXmf2pZ7sSz3Zl3qyL/U0mftiwCgsBO6PiHMzc4hi9OATwCPAC4E/\nyMyfb+MafwTMzMyMiHcDFwPbGwzOAi7IzFnbeX5tDQxMzudI9ff3TtrPXmf2pZ7sSz3Zl3qyL/XU\n7X2ZMqVnqz+L4BoMIDN/AVwPnBwRU4HTgQ+Vu28aR7gAuCMzs3z9EeBl1VcqSZIk1ZsB47f+DXg9\nMBd4IDO/V24f2sHrbuDx3/OuO3g9SZIkqbYMGKXMvBdYDVxEsQaiWS+JiOeUr08DbitfPwj8YURM\niYhe4BXjuNZainUfkiRJUkcxYDzeR4AR4MbtOPerwAURcT/F9Kizy+2fA34BPFC+vmcc11oBZETc\ntz2Pv5UkSZLaxUXejzcHuDQzRwAy8/zxnJSZVwJXbmHfo8Art7Dv/IbXv7lGZm5gfCMdkiRJUq0Y\nMICIeAbwJYrHy76pzeXssIXnHdHuEjZr/fCGdpcgSZKkFjNgAJn5UyC2dVxELOWJ39ldmXlmSwrb\nTqtXDzEyUtnvAUqSJEnjZsBoQjf+LoUkSZJUJRd5S5IkSaqMAUOSJElSZQwYkiRJkipjwJAkSZJU\nGQOGJEmSpMoYMCRJkiRVxoAhSZIkqTIGDEmSJEmVMWBIkiRJqoy/5N2F+vqm7dD564c3MLh2XUXV\nSJIkaTIxYHSh+QsWsWrN9geEGy6cy2CF9UiSJGnymNRTpCJiekScsYPXuCIivh0Rn66qrvK650fE\nzlVeU5IkSWq1SR0wgOnAdgWMiJgaEU8FXgUcmJmv3swxO+1Abe8GDBiSJEnqKB0/RSoi/gp4fmae\nFRGHAF8HDsnMuyPiQ8Ay4KVAALsADwKvzcw1wGXAjIhYBjyYmfMiIoCLgH0o/sC/KDOvKO81CrwH\n+DPgDuBIYDfgmxFxFbAGOAkYBJ4DnBQRQ8C/A/3ABuDvM/Pmhuu9A3gl0Ae8LTOvjYjLyo/3tYgY\nAQ7LzF+25AuUJEmSKtQNIxiLgZeXr18O3Dnm/WLg7MyclZkHAt8Gzi33nwXcn5kzy3AxFfgEcE5m\nHgz8EfD2iHhuw/3WZebBmXkOcDTwy/L8D5b7XwS8NTMPyMxlwDXAJzLz+RTh4+MR0d9wvbXlvU4G\nLgHIzLPKfYeW1zZcSJIkqSN0/AhGZj4YEU+OiH0pAsXfA++IiGuAXTLz+xHx5og4kWJEYnfgu1u4\n3P8G9gM+VQxkAMWox37Ad8r3V22jpDsy8/sAEdELzASuKGu9vxwteRFwQ3n8p8p/3wU8IyJ2zcz1\n4/z4LdPf39vuErqO32k92Zd6si/1ZF/qyb7U02TuS8cHjNJtwCuAp2bmkoi4lGIa020RMRt4PcVo\nwEBEvIYtr7voAX6emTO3cq+hbdSyrf1jrQfIzI1lqKlFTwYGfI5Ulfr7e/1Oa8i+1JN9qSf7Uk/2\npZ66vS9TpvRs9WcRumGKFBTToN4OfLV8/9Xy/WJgL+BXwOqI2AV4bcN5a4E9G94n8EhEnLxpQ0Q8\nNyL22J6iMnOQYg3IKeW19gMOohit2JbBMbVJkiRJtdctAeM24HcpAgXlv3+33H4z8H2KaVFfBr7Z\ncN4KICPivoj4bGZuAI4BToiIFRHxbeBD7NjTnE6kWOy9gmI9xsmZOTCO8y6kGIFZFhF77cD9JUmS\npAnTMzo62u4aVJ3pwENV/NBeNw/rtUO3D5V2KvtST/alnuxLPdmXeur2vjRMkZoBrHzC/okuSJIk\nSVL3qsWCYlVr4XlH7ND564c3VFSJJEmSJhsDRhdavXqIkRGnvkmSJGniOUVKkiRJUmUMGJIkSZIq\nY8CQJEmSVBkDhiRJkqTKGDAkSZIkVcaAIUmSJKkyBgxJkiRJlTFgSJIkSaqMAUOSJElSZZr6Je+I\n+BPgBOApmXlMRMwC9sjM21pSnSRJkqSOMu6AERFvBM4GPgLMKzevAy4BDq2+NG2vvr5p23Xe+uEN\nDK5dV3E1kiRJmkyaGcH4G+DlmbkyIs4tt30HiOrL0o6Yv2ARq9Y0HxRuuHAugy2oR5IkSZNHM2sw\neoEfla9Hy38/CXi00ookSZIkdaxmAsZXgLeP2fYm4EvVlVMPETErIq6ZoHsdFhFLJ+JekiRJUqs1\nM0XqjcANEXE60BsRCQwCr2hJZW2UmUuBE9tdhyRJktRpmgkYPwMOLv/5XYrpUt/IzJFWFDZRIuJo\n4H0Nm/YHjgPemZmzImI6sBS4CvgToAd4Q2beXp7/CuB8iuliI8ApmbkiIv4UeD+wEzAA/FVmPlie\ns4DiaVxrgCVj6jkFeANFb34FvD4zs/IPLkmSJLXAuAJGROwEDAF7ZeY3gG+0tKoJlJk3ATcBlKMz\npwHDYw7rA5Zn5lsi4jDgkxHxbIqg9RFgdmZ+LyJ2AXaOiKcAHwNempn3R8R84BrghRFxDHAsMJPi\nKVzXbbpJRMwGjgf+ODOHI+Io4KPAS1r08Z+gv793om416fjd1pN9qSf7Uk/2pZ7sSz1N5r6MK2Bk\n5saI+C7FH9o/bW1J7RERRwJvBmYDB4zZ/SjwcYDMXBIR6yienjUbuCkzv1fuGwaGyxCyPDPvL8+/\nAvhQRPQCc4BPZ+ZQed+FwHnlcccABwFfjwgoRkv2rv7TbtnAgM+RaoX+/l6/2xqyL/VkX+rJvtST\nfamnbu/LlCk9W/1ZhGamSF0D3BgRFwM/5rdPkqLTf2gvIg4CPgwcmZk/L/+4b4ce4KOZ+a52FSBJ\nkiTtiGaeIvV6iv+afj7FtKCF5T8fqb6siRMRzwSuBU7KzO9u4bCdgdeUx88GnkzxGyCLgKMj4jnl\nvl3KUYq7gIMi4rnl+acA38rMQeA24PiI2L2cenZaw31uAP4yIvYtr7dTRPxhhR9XkiRJaqlxj2Bk\n5oxWFtJGrwP6gcsaRi7OGXPMamBmRPwtxSjDX2Tmo8D3ynUbny7DwkaKRd73RsTJwCciYirFIu+T\nADLzxoh4MbCc3y7yfma57ysR8Q7g+vJ6OwOfAe5pzUeXJEmSqtXMFKmulJnvAd6zmV2zxhz31i2c\nfwPFyMPY7TcDN2/hnHcA79jCvmsopqNJkiRJHWfcASMifkTDuotGmfmsyirSDlt43hHbdd764Q0V\nVyJJkqTJppkRjJPGvH86cDbwqerKqZ/MXAns0+46mrF69RAjI5vNgpIkSVJLNbMG48tjt0XEEopp\nQBdXWJMkSZKkDtXMU6Q2Zxjo1sXfkiRJkprUzBqM947ZtBtwNPCFSiuSJEmS1LGaWYPxv8a8/zXw\nr8DHqitHkiRJUidrJmD8XWY+PHZjRDwNeMJ2SZIkSZNPM2swtvQr1/dXUYgkSZKkztdMwOgZuyEi\n9gBGqitHkiRJUifb5hSphh/Ye3JE/HDM7j7gk60oTJIkSVLnGc8ajJMoRi9uAk5u2D4K/CwzsxWF\nSZIkSeo82wwYm35gLyL2ycxHWl+SJEmSpE7VzC95PxIRM4HZwD40rMnIzHe1oDZtp76+aU2fs354\nA4Nr17WgGkmSJE0mzfzQ3hnAB4FFwFEUP7B3BPD/WlOattf8BYtYtaa5sHDDhXMZbFE9kiRJmjya\neYrU3wJ/mpmvBNaV/54HPNaSyiRJkiR1nGYCxlMy8/by9UhETMnMLwDHtKAuSZIkSR2omV/y/nFE\nTM/MlRQ/ujc3In4OPNqSyjpARCygGMUZoHjC1hGZefk2zjkVeEVmztvGcYcBO2fmomqqlSRJklqv\nmRGMfwb2K1+/F/g4cBvwnqqL6iBvAWZn5mxgOnBGhdc+jGKNiyRJktQxmnmK1JUNr78QEXtT/Bf2\noVYUNtEiYjfgKuB5FOtKMjOPL0cpTgDWAEuAOZk5KyJuB3YFFkfELcDRwIyIWAY8uK0Riob7nstv\nf1/kbuCNwAzgTGBKRBwOfCozP1DRR92i/v7eVt9iUvP7rSf7Uk/2pZ7sSz3Zl3qazH1pZooUEdFH\n8Yf00zPznyNin4jYKzN/3JryJtSRwB6ZuT9AROwdEccAxwIzgXXAdZsOzszZETEKHJqZQxHxeeCC\nzJw13htGxFEU4eJQYJAi4LwzM8+NiA8D0zLzrRV9vm0aGPA5Uq3S39/r91tD9qWe7Es92Zd6si/1\n1O19mTKlZ6s/izDuKVIR8VIggROBd5abnwP83x0psEaWA/tFxGURcRwwDMwBPp2ZQ5m5EVhY8T03\njU6szcxR4PJymyRJktSRmlmDcRHw6sz8U2BDue3rwCGVV9UGmfkDiulRX6T4I395eyuSJEmSOk8z\nAWN6Zi4uX4+W/36UJqdZ1VVE7AtszMzrgHOAfmAZcHxE7B4ROwGnbeUSa4E9m7ztrcCrI6I3InqA\n11EEnO29niRJktRWzQSM+yPiyDHbDgfurbCedjoQuDMilgPfAN6fmVcDN1KMZtxF8XjeLVkBZETc\nFxGfHc8Ny98R+ThwJ7/9HheU//4v4OCIWBYRb2/600iSJElt0DM6Orrto4CIeBHFH9ufB44Hrqb4\nkb25mXl3yyqskfK3KZpayASk29YAACAASURBVD3BpgMPbc+J64c3MLh2XbXV6De6fbFXp7Iv9WRf\n6sm+1JN9qadu70vDIu8ZwMqx+7c5vSkinpaZD2fmXRHxfOAk4KPAj4BDuuQJUl1l9eohRkbGFxwl\nSZKkKo1n/cR3gT0AMvOnEfGizPzz1pZVT5m5BBjX6EVELOWJ3+9dmXlm1XVJkiRJdTGegNEz5v1h\nLaij69R4GpUkSZLUMuNZ5O1cG0mSJEnjMp4RjKkRMYffjmSMfU9m3taK4iRJkiR1lvEEjFUUi7o3\nWT3m/Sjwe1UWJUmSJKkzbTNgZOb0CahDkiRJUhdo5of2JEmSJGmrDBiSJEmSKmPAkCRJklQZA4Yk\nSZKkyoznKVLqMH1905o6fv3wBgbXrmtRNZIkSZpMDBhdaP6CRaxaM/7AcMOFcxlsYT2SJEmaPJwi\nJUmSJKkyBgxJkiRJlZlUU6QiYgEwDxgATgaOyMzLd+B6VwJLM/PSaiqUJEmSOttkG8F4CzA7M2cD\n04Ez2luOJEmS1F06dgQjInYDrgKeBzwGZGYeX45SnACsAZYAczJzVkTcDuwKLI6IW4CjgRkRsQx4\nMDPnbeE+BwIfAnYvz788My9qOOSgiPgasA/wZeCszHw0Ip4KfBh4NtAD/EtmXh0RJwGvysxXltef\nCvwQeElmPhQR5wKvoujNT4DTM/PhSr60rejv7231LSY9v+N6si/1ZF/qyb7Uk32pp8ncl44NGMCR\nwB6ZuT9AROwdEccAxwIzgXXAdZsOzszZETEKHJqZQxHxeeCCzJy1jfusBA7PzOGImAZ8IyJuycwH\nyv0vBA4F1gM3UYyKXApcAtyXma+MiKcD90TEN4HPARdFxD6Z+XPgKOA7Zbg4iSKQvCgzRyLi9cCF\nwIk79lVt28CAz5Fqpf7+Xr/jGrIv9WRf6sm+1JN9qadu78uUKT1b/VmETp4itRzYLyIui4jjgGFg\nDvDpzBzKzI3AwgrusxuwMCLuBb4KPAM4qGH/pvttoBhReVm5/XDg3wEy838owseczHyEIvi8pjzu\nVODK8vWx5XnfLEdWzqKYyiVJkiR1hI4NGJn5A4rpUV+k+KN8eYtu9T7gYeAFmXkQ8A2KqVI74krg\nlIjoA14KfLbc3gMsyMyZ5T8HZOZLdvBekiRJ0oTp2IAREfsCGzPzOuAcoB9YBhwfEbtHxE7AaVu5\nxFpgz3Hcai/gR5m5ISIOAGaP2X9ceb+pFE+muq3cfitwelnr0yjWfNwGkJl3AHsA7weuK0c1AK4H\n3hARe5fn7RIRjaMlkiRJUq11bMAADgTujIjlFKMK78/Mq4EbKUYz7gK+u5XzVwAZEfdFxGe3ctwC\n4PSIWAGcD3xlzP67gUXAA8CPgE2PvX0TxQLwFRSjLG/PzG83nHcVRQC5ctOGzPwYcA3w5fK8ewBH\nMCRJktQxekZHR9tdQ8tExGGMbyF3t5gOPNTsSeuHNzC4dl311eg3un2xV6eyL/VkX+rJvtSTfamn\nbu9LwyLvGRQPRHqcTn6KlLZg9eohRka6NzhKkiSpvro6YGTmEmBcoxcRsZQnfh93ZeaZVdclSZIk\ndauuDhjNmETTqCRJkqSW6eRF3pIkSZJqxoAhSZIkqTIGDEmSJEmVMWBIkiRJqowBQ5IkSVJlDBiS\nJEmSKmPAkCRJklQZA4YkSZKkyvhDe12or2/auI5bP7yBwbXrWlyNJEmSJhMDRheav2ARq9ZsOzjc\ncOFcBiegHkmSJE0eTpGSJEmSVBkDxg6IiOkR8fPy9TMi4ksN+86PiJ0b3r83Il7djjolSZKkieIU\nqYpk5k+BOQ2b3g1cADxa7n9XO+qSJEmSJtKkCBgR8WLgX4DectPbgDXAJcDuwK+BN2Xm3RExHVgK\n/DtwNLAbMD8z7yivdRZwDrAW+HzDPaYDSzNzn4i4rNz8tYgYAQ4DLir3XxoR04B/Aw4uj7s6M/+5\nvM4S4G7gxcAzgP/MzLdX+X1IkiRJrdL1ASMifgf4L+DPM/NrEbETsA/FH/GnZebiiDgcuDYifr88\nrQ+4MzPfEREnAv8EvCQing+8A3hBZv4sIj60uXtm5lkR8Qbg0MwcKutoPOSdFNPTDqQIPXdGxL2Z\n+YVy/7OAPy73fT8iFmbm9yr6Sh6nv7932wepEn7X9WRf6sm+1JN9qSf7Uk+TuS9dHzAoRgLuz8yv\nAWTmxoh4CvBoZi4ut90aEY8CAQwCQ5l5Y3n+XcCF5evDgM9n5s/K95cDx29HTYcDZ2fmKLA2Ij5Z\nbtsUMD6TmSPAryLiAeDZQEsCxsCAz5GaCP39vX7XNWRf6sm+1JN9qSf7Uk/d3pcpU3q2+rMILvLe\nvOGG1xuZ+CC2vs33lyRJkrbLZAgYdwL7l+swKKdIrQJ2jog55baXAU8CchvXWgIcXY6AAMzfyrGD\nwJ5b2HcrMD8ieiKiFzgB+OI4PoskSZJUa10fMDLzF8CfA/8aESuAeyjWPrwKeF+57R+BeZn56Dau\ntQJ4H/DViLgH+OVWDr8QuC0ilkXEXmP2/QPQA9xLEYA+lpk3N//pJEmSpHrpGR0dbXcNqs504KFm\nfsm7m+cH1km3z8XsVPalnuxLPdmXerIv9dTtfWlYgzEDWDl2v3P7u9DC844Y13Hrhze0uBJJkiRN\nNgaMLrR69RAjI45MSZIkaeJ1/RoMSZIkSRPHgCFJkiSpMgYMSZIkSZUxYEiSJEmqjAFDkiRJUmUM\nGJIkSZIqY8CQJEmSVBkDhiRJkqTKGDAkSZIkVcaAIUmSJKkyU9tdgKrX1zdti/vWD29gcO26CaxG\nkiRJk4kBowvNX7CIVWs2HyJuuHAugxNcjyRJkiYPp0hJkiRJqowBQ5IkSVJlnCIFRMQCYB4wAJwM\nHJGZl2/jnFOBV2TmvG0cdxiwc2Yuath2DTAHeDrQm5lDDftGgXuBkXLTyZl5b7OfSZIkSWoHA0bh\nLcCzMnOgDARnAFsNGE04DJgGLGrYthA4B/jZFs45tDF0SJIkSZ2i6wJGROwGXAU8D3gMyMw8vhyl\nOAFYAywB5mTmrIi4HdgVWBwRtwBHAzMiYhnw4LZGKBruey7F6AfA3cAbgRnAmcCUiDgc+FRmfiAz\nbyvPqeQzN6u/v7ct953s/N7ryb7Uk32pJ/tST/alniZzX7ouYABHAntk5v4AEbF3RBwDHAvMBNYB\n1206ODNnl9OSDs3MoYj4PHBBZs4a7w0j4iiKcHEoMEgRcN6ZmedGxIeBaZn51iY+w5KImAp8ATg/\nM4ebOHebBgZ8jtRE6+/v9XuvIftST/alnuxLPdmXeur2vkyZ0rPVn0XoxkXey4H9IuKyiDgOGKZY\n7/DpzBzKzI0UU5SqtGl0Ym1mjlJMrzp8O6/1rDLc/DGwP/DOimqUJEmSWq7rAkZm/oBietQXKf7I\nX97eipqTmT8q/70W+AjwkvZWJEmSJI1f1wWMiNgX2JiZ11EspO4HlgHHR8TuEbETcNpWLrEW2LPJ\n294KvDoieiOiB3gdRcBp6nrldK4nl6+nUjzZalmTtUiSJElt03UBAzgQuDMilgPfAN6fmVcDN1KM\nZtwFfHcr568AMiLui4jPjueGmfkF4OPAnRSPmAVYUP77v4CDI2JZRLwdICI+FxE/3nR6ubgc4LnA\n18vaV1AsUneKlCRJkjpGz+joaLtrmHDlo2ibWsjdIaYDD23tgPXDGxhcu25iqtFvdPtir05lX+rJ\nvtSTfakn+1JP3d6XhkXeM4CVY/d341OkJr3Vq4cYGZl8wVGSJEntNykDRmYuAcY1ehERS3ni93RX\nZp5ZdV2SJElSp5uUAaMZXTiNSpIkSWqZblzkLUmSJKlNDBiSJEmSKmPAkCRJklQZA4YkSZKkyhgw\nJEmSJFXGgCFJkiSpMgYMSZIkSZUxYEiSJEmqjAFDkiRJUmX8Je8u1Nc37XHv1w9vYHDtujZVI0mS\npMnEgNGF5i9YxKo1vw0UN1w4l8E21iNJkqTJo6OnSEXEaERM2/aRjztnekScMWbbyog4oNrqJEmS\npMmnowPGdpoOnLGtgzYnIhzxkSRJkraiG/5gfltEzAWeDPx9Zl4LEBHXAAHsAjwIvDYz1wCXATMi\nYhnwYGbOK69zfET8B/B04ILMvLS8zkrgU8DLgHuB+RFxLnByed7dwBszc6gcTfk34OBy39WZ+c/l\ndZYA9wCHUISci4GfAG8EngG8LTM/ExG7AVcBzwMeAzIzj6/u65IkSZJapxtGMDZm5kzgWODyiHhK\nuf3szJyVmQcC3wbOLbefBdyfmTMbwgXAbpn5YuAw4ANjpl7tkZmHZOb8iDiKIlwcChwI7AS8szzu\nnRTf6YHl/lPK4zfZF3gp8ELgvcABmXkocDzwwfKYI8v77Z+ZBwF/tf1fjSRJkjSxumEEYyEU/5k/\nIr4JvAi4HvjLiDgR2BnYHfjuNq7zqfI6KyNiDUUY+E657+qG4w4HPpWZawEi4nKK0YhN+87OzFFg\nbUR8stz2hXL/ZzJzBPhpRKwG/qvcfg/wzIjYFVgO7BcRlwFLgM8382VsSX9/bxWX0Q6wB/VkX+rJ\nvtSTfakn+1JPk7kv3RAwniAiZgOvBw7NzIGIeA3bXnexvuH1Rh7/3QxVVNrYe6wHyMyNEQEwNTN/\nEBHPA14OHAW8LyIOzMz1T7haEwYGfI5UO/X399qDGrIv9WRf6sm+1JN9qadu78uUKT1P+FmEx+2f\nwFpa5TSAiHgO8ALgLmAv4FfA6ojYBXhtw/FrgT134H63Aq+OiN6I6AFeB3yxYd/8iOiJiF7ghIZ9\n4xIR+1JM+7oOOAfoB35nB+qVJEmSJkw3BIypEfEt4EbgrzJzFXAz8H2KaVFfBr7ZcPwKICPivoj4\nbLM3y8wvAB8H7qRY9A2woPz3PwA95fY7gY9l5s1N3uJA4M6IWA58A3h/Zv602TolSZKkdugZHR1t\ndw2qznTgoc390F43D9N1gm4fKu1U9qWe7Es92Zd6si/11O19aZgiNQNY+YT9E12QJEmSpO7VlYu8\nJ7uF5x3xuPfrhze0qRJJkiRNNgaMLrR69RAjI059kyRJ0sRzipQkSZKkyhgwJEmSJFXGgCFJkiSp\nMgYMSZIkSZUxYEiSJEmqjAFDkiRJUmUMGJIkSZIqY8CQJEmSVBkDhiRJkqTKGDAkSZIkVcaA0YX6\n+qbRu8eT212GJEmSJiEDRheav2ARu+4ytd1lSJIkaRIyYEiSJEmqjAGjxSLibyLiKdt57pUR8ddV\n1yRJkiS1SscEjIiYEhE94zx2p1bX04S/AbYrYEiSJEmdphYT9SPibcD0zDyrfP9UYAVwFTAD2BN4\nFvBiYM1mzj8VOAkYBJ4DnBQRPwP+rTzvycAnM/N95fErgauBPwGeDlyQmZeW+w4GLgF2B34NvCkz\n746IjwD3ZubF5XEHANcDzwb+Ajgb2Lks6a2ZuTgi3gE8A/hsRKwHXgM8CPwj8FJgl/Jzvj4zhyLi\nmWVdTwdWAiPb+51KkiRJ7VCLgAEsBO6PiHMzcwg4A/gE8AjwQuAPMvPn27jGi4CDMvP7ABHxReAf\nMvMrEbEzsDgi7s7ML5bH75aZL46I6cB9EXEl8ChwLXBaGRAOB66NiN8HrqQIHheX558GXJmZoxFx\nC0WAGY2IABYD+2bmP0bE6cC8zLyvrOs84FeZeUj5/p+AvwPeUV7/K5n5noj4PWA5cPN2faNAf3/v\n9p6qFrAf9WRf6sm+1JN9qSf7Uk+TuS+1CBiZ+YuIuB44OSL+AzgdeDlwInDTOMIFwB0N4WJ34DCg\nv/h7H4BeYD9gU8D4VHnvlRGxBtgXeBLwaGYuLvfdGhGPApGZd0REb0QcCDxAMWrx4vJazwY+WY5A\nPAY8LSKelpkPb6bOY4E9ImJe+X4XiiABMAd4U3nvH0TE4nF87i0aGBjckdNVof7+XvtRQ/alnuxL\nPdmXerIv9dTtfZkypYe+vmlb3F+LgFH6N+AaYBXwQGZ+rwwHQ+M8v/G4KcAocHBmPraF49c3vN7I\n+L6Lq4BTgSVljf9dbv8k8JbMvC4iplCMvOy6hWv0AG/IzNvGcT9JkiSpo9RmkXdm3gusBi4CLtvB\naw0CtwNv37QtIv5XRDxtW6cCO0fEnPKcl1GMamS5/2qKkYvXAVc0nLcX8FD5+rUUoxKbrKVYQ7LJ\n9cCbI+LJ5T16I2K/ct9tFFOviIgZFKM4kiRJUseoTcAofYRiYfONFVzrRGD/iLg3Iu4FPk0RBLYo\nMx8FXgW8LyJWUCzGnlduJzN/CNxPMf3qcw2n/g1wXUR8E/g9iqC0ySXAFRGxLCL2Bz5AMSXq7vIe\nd1BM3YJioficiLgfuJRipESSJEnqGD2jo6PtruE3yic1ZWb+S7tr6VDTgYfmL1jEwvOO6Oq5f52m\n2+didir7Uk/2pZ7sSz3Zl3rq9r40rMGYQfHk08epxRqMiHgG8CXgYcpFztp+C887gvXDG9pdhiRJ\nkiahWgSMzPwpENs6LiKW8sSa78rMM1tSWIdavXqIkZH6jExJkiRp8qhFwBivzJzV7hokSZIkbVnd\nFnlLkiRJ6mAGDEmSJEmVMWBIkiRJqowBQ5IkSVJlDBiSJEmSKmPAkCRJklQZA4YkSZKkyhgwJEmS\nJFXGgCFJkiSpMgaMLjRt2q7tLkGSJEmTlAGjC+2yy9R2lyBJkqRJyoAhSZIkqTIGDEmSJEmVqe1c\nmohYAMwDBoCTgSMy8/JtnHMq8IrMnNf6ClsrImYC/zsz/7PdtUiSJEnjVecRjLcAszNzNjAdOKO9\n5Uy4mcDx7S5CkiRJakbP6Ohoy28SEbsBVwHPAx4DMjOPL0cpTgDWAEuAOZk5KyJuB/4IuBe4BTga\nmAF8F3hwSyMU5QjGicA64PeBh4GTM/MnEXEg8CFgd2BX4PLMvKg87wzgHGCYInQdn5nfiYgALgL2\nAXYGLsrMK8pzRoHzgP8D9AGnA4cDfwo8CTguMx8ojz0FeAPFiNGvgNdnZpb1vqb8/AcAvwReVX5H\n3wL2AFYCX8nMN43jq54OPDSO4yRJkqQdNYPib9XHmagpUkcCe2Tm/gAR/7+9e4+Oqjz3OP6dSUgg\nIQglsV5QwQKPKCrWYiniBcvqaVmC1BtYLxWsl0X1eLRaW7EoxQqILut1GawWL61FS6uCteJpi4CI\nSqmClz61FcWiSKR4EqIkJpnzx+zggIFMkj2Zzczvs1bW7L3fPe9+9zxrZ+aZ9333WC8zGwOMJflN\n/SfAY807u/sxwQf44e6+xcyeBG5y96+kcawRwJDgA/y1wK0kh1q9DYxy9zoz6w68aGZPB0nAbOAg\nd3/fzIqBAjMrBH4NnBkkG2XASjN73t3/HhzrI3cfamanAY8DE9z9x2b2Q2AKcJaZHUOyJ+LY4Njf\nAu4Djg7qGAoc5u7vmtk9wCXuPsXMptKB4V5VVTXteZpkSEVFmWISQYpLNCku0aS4RJPiEk25Hpd4\nPEbv3t13Xt5J7XgFGGRmdwYfxuuAkcA8d9/i7o3AvSEda5m7e7D8C+CEYLkEuNfM1gDPAfsAhwdl\nfwbuN7NLgH3d/WNgIDAI+I2ZvQwsBYqDbc3mBY+rgIS7LwzW/0qyBwVgTHCcF4J6ZgL7pdTxnLu/\nGyyvAL7U7jMXEREREcmyTunBcPe3zOwQ4OvAt4AbgAWdcewUN5AcMnWuuzeY2SKSQ6UATibZk3AC\n8BczuwhYB3zo7kN2UefW4LGRZNJEynrzaxsD7nP3qa3UsePzRERERER2O53Sg2FmfYBGd3+M5FyH\nCuBl4HQzKzWzAmDiLqqoBvZI83BHm9mAYHkiyd4JgJ7Au0FyMRg4JmhbIXCgu7/o7jOBRcARgAMf\nm9nZKedxkJn1SLMdzRYA5wSvAWZWYGZHpvG8tpyziIiIiEgkdNYQqUOB583sFeBFYIa7PwAsJDl8\nagXJCdw7sxpwM3vVzH7byrGeA24ys9dJ9khcGmy/HjjfzFYD1wFLgu0FwFwzWxO0b2+g0t0bSA5v\nmmBmq83sNZKTxIvacuLuvoTkfIwngvpfBU5K46l/AkrN7BUzu60txxQRERERyZZOuYtUOszseNKf\nyC0t6wusratroLr6k2y3RVLk+mSv3ZXiEk2KSzQpLtGkuERTrsclZZJ3i3eRivLvYEg7bdmytfWd\nREREREQyIDITit19MZBW74WZreTzbV/h7heF3S4REREREUlfZBKMttAwKhERERGRaNIQKRERERER\nCY0SDBERERERCY0SDBERERERCY0SDBERERERCY0SDBERERERCY0SDBERERERCY0SDBERERERCY0S\nDBERERERCY0SDBERERERCY0SDBERERERCY0SDBERERERCU3OJRhmljCz7h2so6+ZfRhWm0RERERE\n8kXOJRiZZmaF2W6DiIiIiEhU5eqH5SvN7CSgG3C1u88HMLOvAjOBHsF+U939yaDs+8BlQDXwZHNF\nZtYXWAnMBU4A5pjZQ8DtwNBgtwfc/cZg//5AJVABNATH/2NQlgCuAcYBvYHzgVHAN4EuwGnu/oaZ\nWXC8EqAAmOvuN4X38oiIiIiIZEauJhiN7j4k+KC+3MyWAvXA3cBod3/fzPYGXjKzwcD+wBTgCHf/\nwMzu2qG+3sBL7n4FgJnNItn7cyhQBjxvZmvc/SngV8Acd7/XzA4GlpjZIHevCur6yN2HmtlpwOPA\nBHf/sZn9MGjDWcBk4Al3nxEcr1dbTr537w6NEJMMqagoy3YTpAWKSzQpLtGkuEST4hJN+RyXXE0w\n7gVwdzezVcAwkr0J/YCnknkHAAmgPzAceNLdPwi2zwFOT6lvK/BIyvoo4FJ3TwDVZvYwMMrMlgFD\ngF8Gx3/dzF4Ojr8geO684HEVkHD3hcH6X4GTg+UlwI1mVgL8JfhL26ZNW2hqSrTlKZJhFRVlVFXV\nZLsZsgPFJZoUl2hSXKJJcYmmXI9LPB7b5RfauZpgtCQGrHb3Y3csMLPhrTy3NkgmwrA1eGwE6lK2\nNxLEw93nm9nzwDeAHwGTSPZsiIiIiIhEWq5O8p4IYGYDgCOAFcByYICZjWzeycyGmlkMWAyMNrM9\ng6LzWqn/f4HzzCxmZmXABOAZd68BXga+G9Q/CDg8OH7agnkcG9x9LjANOKotzxcRERERyZZc7cEo\nNLO/kZwkfaG7bwQws7HAbDP7OVAEvAWMcffVZnYD8JyZVQN/aKX+6cAdwJpg/cHmidzAmUClmV1G\ncljW2SnzL9J1OnCmmdWTHMZ1aRufLyIiIiKSFbFEQmP1c0hfYK3mYERPro/F3F0pLtGkuEST4hJN\niks05XpcUuZg9APe/lx5ZzdIRERERERylxIMEREREREJjRIMEREREREJjRIMEREREREJjRIMERER\nEREJjRIMEREREREJTa7+DoakaGxsYPPmKhoa6rPdlLy1cWOcpqam7bYVFhbRq1cFBQW6DEVERCR3\n6JNNHti8uYquXUsoLd2LWCyW7ebkpcLCOA0NnyUYiUSC2tpqNm+uorx87yy2TERERCRcGiKVBxoa\n6ikt7aHkIkJisRilpT3UqyQiIiI5RwlGnlByET2KiYiIiOQiJRgiIiIiIhIazcHIU2U9utG1OPzw\nb61roKb6k1b3O/XUMdx44y0ceGD/0NvQmiVLFlNeXs7BBw/u9GOLiIiI5DolGHmqa3EhY37weOj1\nLrj5JGpCrzU8jY2NLF26mIMOGqQEQ0RERCQDlGBIVl188QWYDeKNN15jw4b3OfXUCVRUVDB//iN8\n+GEVkydfygknjAJgxIivMHHi+Sxd+ix1dVu58MLvc/zxXwdgxYrlVFbeQVNTEz179uLKK6+mT5/9\nWLVqJbfeehNmg/jHP5zzzruAZcuWsHLliyxY8Djjx3+Ho44axnXXTaG2tpb6+nqGDz+ayZMvBeDe\neytZt+4damu38N5769l33z5Mnz6Lrl278umnn1JZeScvvLCceLyAffbZlxkzbgLgoYfm8uyzf6ax\nsZHy8j2ZMuUn7LHHF7LzIouIiIh0IiUYknVVVRu54445/Oc/mxg/fhynn/4d7r77Pl5//VWmTPnh\ntgQDIB6PM3fur1m37m0uuug8Dj/8CACuv34qt98+h379DmThwseYNu0a7rnnfgDWrn2LK6+8msGD\nDwNgxIhkD8Ypp4wHoK6ujlmzbqGkpISGhgYuv/xiVqxYzrBhwwFwf4N77nmA7t27c/nlF7No0VOM\nHfttHnzwl7z33nruu+9XdOnShY8++giAp5/+A+vXr6eyci7xeJzf//633HrrLUydOr3TXlMRERGR\nbFGC0Q5mNg6YAWwFhgBl7r4lu63afY0c+XXi8Tjl5RXssUdPjjtuJABmg6iq2khdXR3FxcUAnHji\nSQDsv39fBg40XnttDRDjS18aSL9+BwIwevRYbr55Fh9/XAtAnz77bUsuWtLU1MRdd93KmjWrgQSb\nNm3izTf/sS3BOOqoYZSVlQFw8MGDWb/+3wAsX76Miy/+H7p06QJAz549AVi2bAl///sbTJp0FpD8\nocPu3cvCerlEREREIk0JRvtcCEx190fNLBFmxWZW4O6NYdYZdUVFxduW4/E4RUVFABQUFADJeRMd\n0a1byS7L5837FTU11cyZM5fi4mJmzfoZ9fV1O21fa+1JJBJ897uTtiVD8Pkf2hMRERHJVUow2sjM\nbgGOSS7a5B3KhgK3AaVALfDf7v5SUHYOcCWQAP4FXOjuG83sXOAsoAYYAJxlZicBZ5DsIUkAI939\no044vch78sknOPfc7/Huu+t4803nkEMOBWLMnPlT3nnnbQ44oC9PPbWQAQOMkpLSFusoLS1ly5bP\nOpxqamro3buc4uJiqqo2smzZs4wbd0qrbRk+fASPPPIwhxxy6LYhUj179mTEiGN59NHfcOyxI+nR\nowf19fWsXbuOfv06/45ZIiIiIp1NCUYbuftlZnYEcJO7L2zuwTCzImA+MNHd/2Rmo4D5ZtYfGAjM\nBI509/fNbDpwOzA+npGuAQAAB4RJREFUqHYYcLi7/8vMvgBcBuzt7p+YWRnQ+n1fU/Tu3X279Y0b\n4xQWbv+TJ1vrGlhw80mEbWtdw+eOtTMFBXFisRgFBbHtnlNQsH17Cws/W08kmpg06Uy2bt3KVVdd\nQ0VFOQDXXjudadOuobGxgV69ejFt2vUUFsaDY7BdfaNHn8j06deyePGfOOOMs5gw4QymTLmKc84Z\nz5577snQoUcRjyfbFI/Hti0D262fe+4k7rrrdiZO/A5dunShT5/9mDFjNieeOIaamv/jkksuCNqc\n4OSTT2PAgIGfew3i8TgVFRo+lU16/aNJcYkmxSWaFJdoyue4xBKJUEf45AUzW8z2CUYZ0A/4vbv3\nT9nvn8C3geNJJhDfC7b3AV5x995BD8YEd/9mUFYAvACsBRYBC939/TSb1hdYu2nTFpqaPovrhg3v\nsNdeB7T/hCNixIivsGjREkpKdj3kKYp2NkQqV2Kzu6qoKKOqKso3Vs5Piks0KS7RpLhEU67HJR6P\nNX+h3Q94+3Plnd0gadG28TrB/IthwB1AH+CvZrbzGcoiIiIiIhGiBCM8DhSZ2UgAMzsB6BJs/wsw\n2sz2CvY9H3impUqCIVEV7v6su18LvAroF+GAZctW7pa9FyIiIiL5RHMwQuLu9WZ2CnCbmTVP8j7V\n3euBV83sR8AzwZCqt0jeiaole5Ccu9GNZAK4Cvhd5s9ARERERKTjNAcjt/RlJ3MwvvjF/YnFYllr\nWL5raQ5GIpHggw/WaQ5GFuX6GNndleISTYpLNCku0ZTrcdEcDKGwsIja2mqUTEZHIpGgtraawsKi\nbDdFREREJFQaIpUHevWqYPPmKrZs0U9pZEs8HqepafsejMLCInr1qshSi0REREQyQwlGHigoKKS8\nfO9sNyOv5XpXqYiIiEgzDZESEREREZHQKMEQEREREZHQaIhUbimA5Mx+iR7FJZoUl2hSXKJJcYkm\nxSWacjkuKedW0FK5blObW0YAS7PdCBERERHJC8cAy3bcqAQjtxQDQ4H3gcYst0VEREREclMBsDfw\nElC3Y6ESDBERERERCY0meYuIiIiISGiUYIiIiIiISGiUYIiIiIiISGiUYIiIiIiISGiUYIiIiIiI\nSGiUYIiIiIiISGiUYIiIiIiISGiUYIiIiIiISGgKs90AaZ2ZDQTuB3oDm4Bz3P3NHfYpAG4Dvgkk\ngJnu/ovWyqT9QojLdcBk4L1g9+fc/fud0/rclWZcvgHcABwK3O7uV6SU6XrJkBBicx26ZkKXZlx+\nAkwAGoFPgavd/emgrAT4JXAk0ABc4e4LO+8MclMIcZkLjAI+DHZ/1N1/1jmtz11pxmUicBnQRPIX\nr+9x99uCsrx4j1EPxu7hbuBOdx8I3AlUtrDPmUB/YADwNeA6M+ubRpm0X0fjAvCAuw8J/vRBKRzp\nxOUt4HvA7BbKdL1kTkdjA7pmMiGduLwIDHX3w4BJwDwz6xaUXQFUu3t/YAzwCzPr3gntznUdjQsk\nP7w2Xy9KLsKRTlzmA4e7+xBgOPADMzssKMuL9xglGBFnZnsCXwYeDjY9DHzZzCp22HU8yQy5yd2r\ngMeA09Iok3YIKS4SsnTj4u7/dPeXSX7buiPFLANCio2ErA1xedrdPw5WVwMxkt/gQvKaqQz2exNY\nCXwrw03PaSHFRULWhrhUu3siWC0BupDsrYA8eY9RghF9+wHr3b0RIHh8L9iean/gnZT1dSn77KpM\n2ieMuABMMLPVZrbIzL6WyQbniXTjsiu6XjIjjNiArpmwtScu5wD/cvd/B+u6ZsIXRlwALjezNWb2\nmJkNylxz80bacTGzsWb2GslrY7a7rwmK8uJ6UYIhkj13A/2Cru3ZwONmpm+eRHZO10yWmdlxwHTg\njGy3RT6zk7hMAfq7+6HA74A/BuP/pRO4+xPufggwEDjbzCzbbepMSjCi711g3+Z/CsHjPsH2VOuA\nA1LW90/ZZ1dl0j4djou7b3D3T4PlZ4LtgzPc7lyXblx2RddLZnQ4NrpmMiLtuAQ9Rg8B49zdU4p0\nzYSvw3Fx9/Xu3hQsPwB0B/p0QttzWZv/j7n7OpJzZU4MNuXF9aIEI+LcfSPwMp99K3EG8Ldg3F6q\nR4HzzSwejAUcB/w2jTJphzDiYmb7Nu9kZkOAvoAj7daGuOyKrpcMCCM2umbCl25czGwoMA841d1X\n7VDNo8CFwX4DgKHAHzPZ7lwXRlx2uF7+i+SdptZnst25rg1xGZSyXA6MBJqHSOXFe4xuU7t7uAi4\n38ymAptJjrPEzP4ATHX3lcCDwFeB5lul/dTd1wbLuyqT9utoXG4wsyNJ/tOvB8529w2deQI5qtW4\nmNkI4DdADyBmZhOA84LbO+p6yZyOxkbXTGak87/sLqAbUJky0uPsYFz5bGCumf2TZGwucPeaTj6H\nXNTRuNxvZl8keavUamCsu+vmCR2XTlwuCG65/SnJifd3uPui4Pl58R4TSyQSre8lIiIiIiKSBg2R\nEhERERGR0CjBEBERERGR0CjBEBERERGR0CjBEBERERGR0CjBEBERERGR0CjBEBERERGR0CjBEBER\nERGR0Pw/Uj0U8hPo1jMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OBScjVVD44p_"
      },
      "source": [
        "# GBR modelling using pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:27.562630Z",
          "start_time": "2019-11-20T01:11:26.412550Z"
        },
        "colab_type": "code",
        "id": "J8nbaUjC44qA",
        "outputId": "2f3aba35-f3cb-4d57-e2bb-1d1a060102d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "pipe = Pipeline([ ('Scaler', StandardScaler()),\n",
        "                  ('GBR', GradientBoostingRegressor())\n",
        "                ])\n",
        "\n",
        "pipe.fit(Xtrain,ytrain)\n",
        "\n",
        "# model evaluation\n",
        "ypreds = pipe.predict(Xtest)\n",
        "\n",
        "rmse = np.sqrt(sklearn.metrics.mean_squared_error(ytest,ypreds))\n",
        "r2 = sklearn.metrics.r2_score(ytest, ypreds)\n",
        "ar2 = adjustedR2(r2, Xtest.shape[0], Xtest.shape[1])\n",
        "\n",
        "print(f'Test RMSE: {rmse}')\n",
        "print(f'r_squared: {r2} ')\n",
        "print(f'adjustedr2 = {ar2}')\n",
        "\n",
        "# pipeline does not give feature importance."
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test RMSE: 0.1854261704833592\n",
            "r_squared: 0.8773574849523254 \n",
            "adjustedr2 = 0.8768731823377353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNZTcVPwg7Nr",
        "colab_type": "text"
      },
      "source": [
        "# Cross Validation Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:27.575388Z",
          "start_time": "2019-11-20T01:11:27.565275Z"
        },
        "colab_type": "code",
        "id": "IbNSa3Wh44qH",
        "colab": {}
      },
      "source": [
        "df_cv = pd.DataFrame({'Model': [],\n",
        "                      '10-Fold Cross Validation Mean':[],\n",
        "                      '10-Fold Cross Validation Std':[]\n",
        "                     })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:37.520595Z",
          "start_time": "2019-11-20T01:11:27.585558Z"
        },
        "colab_type": "code",
        "id": "mpv8ZqYnindu",
        "outputId": "a2dbec4a-0d97-4200-c6f2-bcf1a2822acd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "%%time\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=10, random_state=RANDOM_STATE)\n",
        "cv_results = cross_val_score(model,Xtrain_scaled,ytrain,\n",
        "                             cv=kfold,\n",
        "                             scoring='neg_mean_squared_error'\n",
        "                             )\n",
        "\n",
        "df_cv.loc[0] = ['GBR', cv_results.mean(), cv_results.std() ]\n",
        "\n",
        "display(df_cv)\n",
        "\n",
        "# smallest rmse is best, largest negMSE is best."
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>10-Fold Cross Validation Mean</th>\n",
              "      <th>10-Fold Cross Validation Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GBR</td>\n",
              "      <td>-0.034178</td>\n",
              "      <td>0.001451</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Model  10-Fold Cross Validation Mean  10-Fold Cross Validation Std\n",
              "0   GBR                      -0.034178                      0.001451"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 13.2 s, sys: 6.48 ms, total: 13.2 s\n",
            "Wall time: 13.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q1zipoGI9ynJ"
      },
      "source": [
        "# HPO (Hyper Parameters Optimization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-4fWGs-P91Kf"
      },
      "source": [
        "## Grid Search for Gradient Boosting Regressor\n",
        "\n",
        "Reference: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html \n",
        "\n",
        "\n",
        "Grid search is extremely slow. It need to fit the model for all the values in the\n",
        "search space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:11:37.535096Z",
          "start_time": "2019-11-20T01:11:37.522510Z"
        },
        "id": "h_TC-geMg7Nv",
        "colab_type": "code",
        "outputId": "943c7b1e-c147-431e-c521-d972107269f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
              "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
              "                          max_features=None, max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                          n_iter_no_change=None, presort='auto',\n",
              "                          random_state=None, subsample=1.0, tol=0.0001,\n",
              "                          validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:12:13.030381Z",
          "start_time": "2019-11-20T01:12:13.027299Z"
        },
        "colab_type": "code",
        "id": "c-LiXDE1zBSW",
        "colab": {}
      },
      "source": [
        "# n_estimators is 100 make it 1200\n",
        "# there is no need to tune trees in forest always more is better.\n",
        "# we can tune only just not to take too much trees for overfitting."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:15:56.993204Z",
          "start_time": "2019-11-20T01:15:44.429260Z"
        },
        "id": "ap_cgyX2g7Ny",
        "colab_type": "code",
        "outputId": "83e1faa7-0b85-41c7-bf93-3f5616d09cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%%time\n",
        "model = GradientBoostingRegressor(alpha=0.9,\n",
        "                                  criterion='friedman_mse',\n",
        "                                  init=None,\n",
        "                                  learning_rate=0.1,\n",
        "                                  loss='ls',\n",
        "                                  max_depth=3,\n",
        "                                  max_features=None,\n",
        "                                  max_leaf_nodes=None,\n",
        "                                  min_impurity_decrease=0.0,\n",
        "                                  min_impurity_split=None,\n",
        "                                  min_samples_leaf=1,\n",
        "                                  min_samples_split=2,\n",
        "                                  min_weight_fraction_leaf=0.0,\n",
        "                                  n_estimators=1200,\n",
        "                                  n_iter_no_change=None,\n",
        "                                  presort='auto',\n",
        "                                  random_state=RANDOM_STATE,\n",
        "                                  subsample=1.0,\n",
        "                                  tol=0.0001,\n",
        "                                  validation_fraction=0.1,\n",
        "                                  verbose=0,\n",
        "                                  warm_start=False)\n",
        "\n",
        "model.fit(Xtrain_scaled,ytrain)\n",
        "\n",
        "# model evaluation\n",
        "ypreds = model.predict(Xtest_scaled)\n",
        "\n",
        "rmse = np.sqrt(sklearn.metrics.mean_squared_error(ytest,ypreds))\n",
        "r2 = sklearn.metrics.r2_score(ytest, ypreds)\n",
        "ar2 = adjustedR2(r2, Xtest.shape[0], Xtest.shape[1])\n",
        "\n",
        "print(f'Test RMSE: {rmse}')\n",
        "print(f'r_squared: {r2} ')\n",
        "print(f'adjustedr2 = {ar2}')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test RMSE: 0.16013998674273916\n",
            "r_squared: 0.9085258113198424 \n",
            "adjustedr2 = 0.9081645892042646\n",
            "CPU times: user 16.8 s, sys: 7.21 ms, total: 16.8 s\n",
            "Wall time: 16.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-20T01:48:29.818227Z",
          "start_time": "2019-11-20T01:42:25.040533Z"
        },
        "id": "VLRPbCsBg7N1",
        "colab_type": "code",
        "outputId": "6bd88eed-ffb2-4512-f6b0-df0ce4d7fe9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "%%time\n",
        "# tuning learning rates\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = dict(learning_rate= np.geomspace(0.05,0.5,10))\n",
        "\n",
        "model = GradientBoostingRegressor(n_estimators=1200,\n",
        "                                  verbose=1,\n",
        "                                  random_state=RANDOM_STATE\n",
        "                                 )\n",
        "\n",
        "\n",
        "kfold = KFold(n_splits=5, random_state=RANDOM_STATE)\n",
        "\n",
        "grid = GridSearchCV(estimator=model,\n",
        "                    param_grid=param_grid,\n",
        "                    n_jobs=-1,\n",
        "                    scoring='neg_mean_squared_error',\n",
        "                    cv=kfold)\n",
        "\n",
        "# grid_result = grid.fit(Xtrain_scaled, ytrain)\n",
        "# comment this after use."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.2471           22.18s\n",
            "         2           0.2218           21.76s\n",
            "         3           0.2004           21.32s\n",
            "         4           0.1817           21.55s\n",
            "         5           0.1657           21.62s\n",
            "         6           0.1521           21.46s\n",
            "         7           0.1399           21.53s\n",
            "         8           0.1295           21.41s\n",
            "         9           0.1205           21.38s\n",
            "        10           0.1123           21.44s\n",
            "        20           0.0682           21.30s\n",
            "        30           0.0525           20.45s\n",
            "        40           0.0448           20.42s\n",
            "        50           0.0406           20.47s\n",
            "        60           0.0378           20.10s\n",
            "        70           0.0361           19.22s\n",
            "        80           0.0349           18.54s\n",
            "        90           0.0339           17.96s\n",
            "       100           0.0331           17.49s\n",
            "       200           0.0279           14.88s\n",
            "       300           0.0256           13.06s\n",
            "       400           0.0240           11.57s\n",
            "       500           0.0229           10.06s\n",
            "       600           0.0219            8.62s\n",
            "       700           0.0211            7.15s\n",
            "       800           0.0204            5.72s\n",
            "       900           0.0197            4.29s\n",
            "      1000           0.0191            2.87s\n",
            "CPU times: user 17.5 s, sys: 85.9 ms, total: 17.6 s\n",
            "Wall time: 21min 55s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSf01TTsg7N3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show_method_attributes(grid_result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kbljvglnlUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grid_result.best_params_\n",
        "# {'learning_rate': 0.08340502686000295}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIX4kgkpnqgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learning_rate_best = grid_result.best_params_['learning_rate']\n",
        "\n",
        "learning_rate_best = 0.08340502686000295"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APQUrsfng7N5",
        "colab_type": "code",
        "outputId": "4719197b-fbd7-425e-c339-343acdd86037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "%%time\n",
        "# tuning max_depth\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = dict(max_depth= np.arange(2,10))\n",
        "\n",
        "model = GradientBoostingRegressor(n_estimators=1200,\n",
        "                                  learning_rate = learning_rate_best,\n",
        "                                  verbose=1,\n",
        "                                  random_state=RANDOM_STATE\n",
        "                                 )\n",
        "\n",
        "kfold = KFold(n_splits=5, random_state=RANDOM_STATE)\n",
        "\n",
        "grid = GridSearchCV(estimator=model,\n",
        "                    param_grid=param_grid,\n",
        "                    n_jobs=-1,\n",
        "                    scoring='neg_mean_squared_error',\n",
        "                    cv=kfold)\n",
        "\n",
        "grid_result = grid.fit(Xtrain_scaled, ytrain)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.2471           20.70s\n",
            "         2           0.2218           20.99s\n",
            "         3           0.2004           20.68s\n",
            "         4           0.1817           21.01s\n",
            "         5           0.1657           21.03s\n",
            "         6           0.1521           20.85s\n",
            "         7           0.1399           20.97s\n",
            "         8           0.1295           20.84s\n",
            "         9           0.1205           20.85s\n",
            "        10           0.1123           20.94s\n",
            "        20           0.0682           20.69s\n",
            "        30           0.0525           20.02s\n",
            "        40           0.0448           19.37s\n",
            "        50           0.0406           18.80s\n",
            "        60           0.0378           18.39s\n",
            "        70           0.0361           17.71s\n",
            "        80           0.0349           17.24s\n",
            "        90           0.0339           16.92s\n",
            "       100           0.0331           16.55s\n",
            "       200           0.0279           14.29s\n",
            "       300           0.0256           12.75s\n",
            "       400           0.0240           11.35s\n",
            "       500           0.0229            9.90s\n",
            "       600           0.0219            8.49s\n",
            "       700           0.0211            7.06s\n",
            "       800           0.0204            5.63s\n",
            "       900           0.0197            4.23s\n",
            "      1000           0.0191            2.82s\n",
            "CPU times: user 17.1 s, sys: 57.9 ms, total: 17.1 s\n",
            "Wall time: 21min 55s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjJaFmqNg7N7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bebd99b-f1ad-4f21-f304-f43938b78049"
      },
      "source": [
        "grid_result.best_params_"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNlUI9ylav2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7fbac70-e948-47a8-ed41-bc1e03095039"
      },
      "source": [
        "max_depth_best = grid_result.best_params_['max_depth']\n",
        "max_depth_best"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnrMhEIzg7N8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "a5b3b559-b7f5-40a3-beae-59173bcd82bf"
      },
      "source": [
        "%%time\n",
        "# tuning min_samples_split\n",
        "\n",
        "# minimum number of samples required to split an internal node\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = dict(min_samples_split= np.linspace(0.1, 1.0, 10, endpoint=True))\n",
        "\n",
        "model = GradientBoostingRegressor(n_estimators=1200,\n",
        "                                  learning_rate=learning_rate_best,\n",
        "                                  max_depth=max_depth_best,\n",
        "                                  verbose=1,\n",
        "                                  random_state=RANDOM_STATE\n",
        "                                 )\n",
        "\n",
        "\n",
        "kfold = KFold(n_splits=5, random_state=RANDOM_STATE)\n",
        "\n",
        "grid = GridSearchCV(estimator=model,\n",
        "                    param_grid=param_grid,\n",
        "                    n_jobs=-1,\n",
        "                    scoring='neg_mean_squared_error',\n",
        "                    cv=kfold)\n",
        "\n",
        "grid_result = grid.fit(Xtrain_scaled, ytrain)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.2474           20.57s\n",
            "         2           0.2224           20.44s\n",
            "         3           0.2012           20.21s\n",
            "         4           0.1826           20.69s\n",
            "         5           0.1671           20.46s\n",
            "         6           0.1534           20.37s\n",
            "         7           0.1415           20.44s\n",
            "         8           0.1313           20.26s\n",
            "         9           0.1219           20.37s\n",
            "        10           0.1140           20.50s\n",
            "        20           0.0703           20.15s\n",
            "        30           0.0550           18.98s\n",
            "        40           0.0473           18.16s\n",
            "        50           0.0428           17.47s\n",
            "        60           0.0399           16.99s\n",
            "        70           0.0378           16.49s\n",
            "        80           0.0364           15.96s\n",
            "        90           0.0356           15.43s\n",
            "       100           0.0349           15.06s\n",
            "       200           0.0305           12.86s\n",
            "       300           0.0280           11.77s\n",
            "       400           0.0268           10.38s\n",
            "       500           0.0259            9.08s\n",
            "       600           0.0248            7.86s\n",
            "       700           0.0239            6.62s\n",
            "       800           0.0234            5.28s\n",
            "       900           0.0229            3.96s\n",
            "      1000           0.0225            2.62s\n",
            "CPU times: user 15.9 s, sys: 45 ms, total: 15.9 s\n",
            "Wall time: 6min 31s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7Ni8Pd2g7N9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b06fc465-8795-47a4-ce94-cea4571a1ce8"
      },
      "source": [
        "grid_result.best_params_"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'min_samples_split': 0.1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr1lC75ObKKH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5774e23f-3a0f-4288-fa60-cfcdf53ab7d9"
      },
      "source": [
        "min_samples_split_best = grid_result.best_params_['min_samples_split']\n",
        "min_samples_split_best"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-GGLPS0g7N_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "e95bedf7-714f-4a7f-a487-dbe2256fa8ce"
      },
      "source": [
        "%%time\n",
        "# tuning min_samples_leaf\n",
        "\n",
        "# The minimum number of samples required to be at a leaf node.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = dict(min_samples_leaf= np.linspace(0.1, 0.5, 5, endpoint=True))\n",
        "\n",
        "model = GradientBoostingRegressor(n_estimators=1200,\n",
        "                                  learning_rate = learning_rate_best,\n",
        "                                  max_depth = max_depth_best,\n",
        "                                  min_samples_split = min_samples_split_best,\n",
        "                                  verbose=1,\n",
        "                                  random_state=RANDOM_STATE\n",
        "                                 )\n",
        "\n",
        "\n",
        "kfold = KFold(n_splits=5, random_state=RANDOM_STATE)\n",
        "\n",
        "grid = GridSearchCV(estimator=model,\n",
        "                    param_grid=param_grid,\n",
        "                    n_jobs=-1,\n",
        "                    scoring='neg_mean_squared_error',\n",
        "                    cv=kfold)\n",
        "\n",
        "grid_result = grid.fit(Xtrain_scaled, ytrain)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.2501           15.88s\n",
            "         2           0.2268           16.49s\n",
            "         3           0.2075           16.07s\n",
            "         4           0.1900           16.25s\n",
            "         5           0.1759           15.97s\n",
            "         6           0.1610           16.50s\n",
            "         7           0.1498           16.53s\n",
            "         8           0.1387           16.91s\n",
            "         9           0.1308           16.72s\n",
            "        10           0.1221           16.93s\n",
            "        20           0.0806           16.93s\n",
            "        30           0.0655           16.02s\n",
            "        40           0.0578           15.71s\n",
            "        50           0.0537           15.34s\n",
            "        60           0.0507           14.95s\n",
            "        70           0.0492           14.45s\n",
            "        80           0.0477           14.17s\n",
            "        90           0.0466           13.94s\n",
            "       100           0.0458           13.71s\n",
            "       200           0.0412           12.20s\n",
            "       300           0.0386           11.10s\n",
            "       400           0.0371            9.77s\n",
            "       500           0.0361            8.45s\n",
            "       600           0.0352            7.18s\n",
            "       700           0.0345            5.96s\n",
            "       800           0.0340            4.73s\n",
            "       900           0.0336            3.54s\n",
            "      1000           0.0332            2.35s\n",
            "CPU times: user 14.2 s, sys: 35 ms, total: 14.2 s\n",
            "Wall time: 2min 25s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMzy1SNofiw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6acb6e03-e75d-4aaa-d965-4f4b9578923a"
      },
      "source": [
        "grid_result.best_params_"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'min_samples_leaf': 0.1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkXbsudziyQq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9f5667d-facd-4200-9993-5aa6e4fad7f4"
      },
      "source": [
        "min_samples_leaf_best = grid_result.best_params_['min_samples_leaf']\n",
        "min_samples_leaf_best"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZAhdYHig7OC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "933fe4d6-ed18-4e86-bd28-ee70256e5c8a"
      },
      "source": [
        "%%time\n",
        "# tuning max_features\n",
        "\n",
        "# Number of columns to be used\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = dict(max_features= np.arange(5,Xtrain.shape[1]))\n",
        "\n",
        "model = GradientBoostingRegressor(n_estimators=1200,\n",
        "                                  learning_rate = learning_rate_best,\n",
        "                                  max_depth = max_depth_best,\n",
        "                                  min_samples_split = min_samples_split_best,\n",
        "                                  min_samples_leaf = min_samples_leaf_best,\n",
        "                                  verbose=1,\n",
        "                                  random_state=RANDOM_STATE\n",
        "                                 )\n",
        "\n",
        "\n",
        "kfold = KFold(n_splits=5, random_state=RANDOM_STATE)\n",
        "\n",
        "grid = GridSearchCV(estimator=model,\n",
        "                    param_grid=param_grid,\n",
        "                    n_jobs=-1,\n",
        "                    scoring='neg_mean_squared_error',\n",
        "                    cv=kfold)\n",
        "\n",
        "grid_result = grid.fit(Xtrain_scaled, ytrain)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.2501           13.78s\n",
            "         2           0.2284           13.42s\n",
            "         3           0.2091           13.62s\n",
            "         4           0.1916           13.72s\n",
            "         5           0.1762           13.91s\n",
            "         6           0.1635           13.77s\n",
            "         7           0.1506           14.14s\n",
            "         8           0.1397           14.39s\n",
            "         9           0.1307           14.46s\n",
            "        10           0.1232           14.40s\n",
            "        20           0.0811           14.19s\n",
            "        30           0.0658           13.59s\n",
            "        40           0.0583           13.16s\n",
            "        50           0.0538           12.84s\n",
            "        60           0.0513           12.55s\n",
            "        70           0.0493           12.21s\n",
            "        80           0.0478           11.94s\n",
            "        90           0.0467           11.86s\n",
            "       100           0.0458           11.66s\n",
            "       200           0.0409           10.42s\n",
            "       300           0.0386            9.38s\n",
            "       400           0.0372            8.28s\n",
            "       500           0.0363            7.17s\n",
            "       600           0.0355            6.12s\n",
            "       700           0.0348            5.07s\n",
            "       800           0.0342            4.03s\n",
            "       900           0.0338            3.01s\n",
            "      1000           0.0335            2.00s\n",
            "CPU times: user 12.3 s, sys: 48.1 ms, total: 12.4 s\n",
            "Wall time: 7min 5s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Qcoj1bMg7OE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f434e03b-48b7-4e15-d4cd-5695fb617a68"
      },
      "source": [
        "grid_result.best_params_"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_features': 15}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxEwKBY6uo7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43156fff-1136-428a-ed40-90a57877f17d"
      },
      "source": [
        "max_features_best = grid_result.best_params_['max_features']\n",
        "max_features_best"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47nVbsGbuyAa",
        "colab_type": "text"
      },
      "source": [
        "## Best Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td9EUkMpu1d6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "b0a9390b-7781-4b27-988b-f006cff9827c"
      },
      "source": [
        "%%time\n",
        "model = model = GradientBoostingRegressor(n_estimators=1200,\n",
        "                                  learning_rate = learning_rate_best,\n",
        "                                  max_depth = max_depth_best,\n",
        "                                  min_samples_split = min_samples_split_best,\n",
        "                                  min_samples_leaf = min_samples_leaf_best,\n",
        "                                  max_features = max_features_best,\n",
        "                                  verbose=1,\n",
        "                                  random_state=RANDOM_STATE\n",
        "                                 )\n",
        "\n",
        "model.fit(Xtrain_scaled,ytrain)\n",
        "\n",
        "# model evaluation\n",
        "ypreds = model.predict(Xtest_scaled)\n",
        "\n",
        "rmse = np.sqrt(sklearn.metrics.mean_squared_error(ytest,ypreds))\n",
        "r2 = sklearn.metrics.r2_score(ytest, ypreds)\n",
        "ar2 = adjustedR2(r2, Xtest.shape[0], Xtest.shape[1])\n",
        "\n",
        "print(f'Test RMSE: {rmse}')\n",
        "print(f'r_squared: {r2} ')\n",
        "print(f'adjustedr2 = {ar2}')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.2501           13.70s\n",
            "         2           0.2284           13.31s\n",
            "         3           0.2091           13.75s\n",
            "         4           0.1916           14.57s\n",
            "         5           0.1762           14.65s\n",
            "         6           0.1635           14.45s\n",
            "         7           0.1506           14.77s\n",
            "         8           0.1397           15.08s\n",
            "         9           0.1307           15.19s\n",
            "        10           0.1232           15.13s\n",
            "        20           0.0811           14.68s\n",
            "        30           0.0658           14.00s\n",
            "        40           0.0583           13.48s\n",
            "        50           0.0538           13.05s\n",
            "        60           0.0513           12.67s\n",
            "        70           0.0493           12.40s\n",
            "        80           0.0478           12.05s\n",
            "        90           0.0467           11.86s\n",
            "       100           0.0458           11.59s\n",
            "       200           0.0409           10.41s\n",
            "       300           0.0386            9.38s\n",
            "       400           0.0372            8.33s\n",
            "       500           0.0363            7.19s\n",
            "       600           0.0355            6.14s\n",
            "       700           0.0348            5.08s\n",
            "       800           0.0342            4.05s\n",
            "       900           0.0338            3.01s\n",
            "      1000           0.0335            2.01s\n",
            "Test RMSE: 0.1838960779696838\n",
            "r_squared: 0.8793731675714923 \n",
            "adjustedr2 = 0.8788968246792078\n",
            "CPU times: user 12.1 s, sys: 12.7 ms, total: 12.1 s\n",
            "Wall time: 12.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXs5DwDmvRIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I did a sequential grid search, I need to do all grid search at same time.\n",
        "# Also, it takes long time to fit grid search.\n",
        "# The baseline model gave me 0.9 but after grid search it gave me 0.87.\n",
        "# The grid search space needs to be increased."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odvd-SHLvvAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}