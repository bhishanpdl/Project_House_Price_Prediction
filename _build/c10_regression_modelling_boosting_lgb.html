---
redirect_from:
  - "c10-regression-modelling-boosting-lgb"
interact_link: content/c10_regression_modelling_boosting_lgb.ipynb
kernel_name: datasc
kernel_path: content
has_widgets: false
title: |-
  C10 Regression Modelling Boosting Lgb
pagenum: 20
prev_page:
  url: /d02_regression_modelling_using_pyspark_random_forest_tuning.html
next_page:
  url: /README.html
suffix: .ipynb
search: data toc span class id href modified item boosting numnbspnbsp lilispana gbm xgboost lightgbm using parameters transform tree log large split scaling modelling validation gradient algorithms values hpo hyper regressor tuning regularization after search hyperopt features com algorithm light description scripts train test gbr cross optimization parameter based model used value itemlispana imports important load pipeline results grid li ul sklearn hyperparameter without accuracy however faster vs www leaf fast memory uses shap l div spangbr spanhpo spanul num nbspnbsp scale dataset house includes price given github blob master raw weak learner learners boost generally not pruning random run iteration

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">C10 Regression Modelling Boosting Lgb</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><h1>Table of Contents<span class="tocSkip"></span></h1></p>
<div class="toc"><ul class="toc-item"><li><span><a href="#Data-Description" data-toc-modified-id="Data-Description-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>Data Description</a></span></li><li><span><a href="#Imports" data-toc-modified-id="Imports-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href="#Important-Scripts" data-toc-modified-id="Important-Scripts-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>Important Scripts</a></span></li><li><span><a href="#Load-the-data" data-toc-modified-id="Load-the-data-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>Load the data</a></span></li><li><span><a href="#Log-transform-large-values" data-toc-modified-id="Log-transform-large-values-5"><span class="toc-item-num">5&nbsp;&nbsp;</span>Log transform large values</a></span></li><li><span><a href="#Train-Test-split-after-log-transform" data-toc-modified-id="Train-Test-split-after-log-transform-6"><span class="toc-item-num">6&nbsp;&nbsp;</span>Train-Test split after log transform</a></span></li><li><span><a href="#Scaling-the-Data" data-toc-modified-id="Scaling-the-Data-7"><span class="toc-item-num">7&nbsp;&nbsp;</span>Scaling the Data</a></span></li><li><span><a href="#GBR-Modelling" data-toc-modified-id="GBR-Modelling-8"><span class="toc-item-num">8&nbsp;&nbsp;</span>GBR Modelling</a></span></li><li><span><a href="#GBR-modelling-using-pipeline" data-toc-modified-id="GBR-modelling-using-pipeline-9"><span class="toc-item-num">9&nbsp;&nbsp;</span>GBR modelling using pipeline</a></span></li><li><span><a href="#Cross-Validation-Results" data-toc-modified-id="Cross-Validation-Results-10"><span class="toc-item-num">10&nbsp;&nbsp;</span>Cross Validation Results</a></span></li><li><span><a href="#HPO-(Hyper-Parameters-Optimization)" data-toc-modified-id="HPO-(Hyper-Parameters-Optimization)-11"><span class="toc-item-num">11&nbsp;&nbsp;</span>HPO (Hyper Parameters Optimization)</a></span><ul class="toc-item"><li><span><a href="#Grid-Search-for-Gradient-Boosting-Regressor" data-toc-modified-id="Grid-Search-for-Gradient-Boosting-Regressor-11.1"><span class="toc-item-num">11.1&nbsp;&nbsp;</span>Grid Search for Gradient Boosting Regressor</a></span></li></ul></li><li><span><a href="#Hyper-Parameter-using-hyperopt-sklearn-for-Gradient-Boosting-Regressor" data-toc-modified-id="Hyper-Parameter-using-hyperopt-sklearn-for-Gradient-Boosting-Regressor-12"><span class="toc-item-num">12&nbsp;&nbsp;</span>Hyper Parameter using hyperopt-sklearn for Gradient Boosting Regressor</a></span></li><li><span><a href="#Scale-data-for-hyperparameter-tuning" data-toc-modified-id="Scale-data-for-hyperparameter-tuning-13"><span class="toc-item-num">13&nbsp;&nbsp;</span>Scale data for hyperparameter tuning</a></span><ul class="toc-item"><li><span><a href="#HPO-without-scaling-the-data" data-toc-modified-id="HPO-without-scaling-the-data-13.1"><span class="toc-item-num">13.1&nbsp;&nbsp;</span>HPO without scaling the data</a></span></li></ul></li></ul></div>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Data-Description">Data Description<a class="anchor-link" href="#Data-Description"> </a></h1><p>This dataset contains house sale prices for King County,
which includes Seattle.
It includes homes sold between May 2014 and May 2015.</p>
<ul>
<li>Dependent features: 1 (price)</li>
<li>Features : 19 home features</li>
<li>Id:  1 house ID</li>
</ul>
<p>Task: Try to estimate the price based on given features.</p>
<p><img src="https://github.com/bhishanpdl/Project_House_Price_Prediction/blob/master/data/raw/data_description.png?raw=1" alt=""></p>
<h2 id="Model-Introduction">Model Introduction<a class="anchor-link" href="#Model-Introduction"> </a></h2><p>The term <code>Boosting</code> refers to a family of algorithms which converts weak learner to strong learners.</p>
<p>There are many boosting algorithms which impart additional boost to model’s accuracy. In this tutorial, we’ll learn about the two most commonly used algorithms i.e. Gradient Boosting (GBM) and XGboost.</p>
<p>Generally XGboost is considered more advanced than gbm.</p>
<ul>
<li>xgboost supports regularization, however gbm does not.</li>
<li>xgboost is blazingley faster than gbm.</li>
<li>xgboost has built-in routine to handle missing values.</li>
<li>xgboost has tree pruning mechanisms,however gbm and random forest are greedy algorithms and do not have tree pruning.</li>
<li>In xgboost we can run cross-validation at each iteration of the boosting. But in gbm, we have to run grid search.</li>
</ul>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Imports">Imports<a class="anchor-link" href="#Imports"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="n">ENV_BHISHAN</span> <span class="o">=</span> <span class="s1">&#39;bhishan&#39;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span>

<span class="k">if</span> <span class="n">ENV_BHISHAN</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Environment: Personal environment&#39;</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">src</span>
    <span class="kn">import</span> <span class="nn">bhishan</span>
    <span class="o">%</span><span class="k">load_ext</span> autoreload
    <span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="n">ENV_COLAB</span> <span class="o">=</span> <span class="s1">&#39;google.colab&#39;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span>

<span class="k">if</span> <span class="n">ENV_COLAB</span><span class="p">:</span>
    <span class="c1">#!pip install hpsklearn</span>
    <span class="o">!</span>pip install shap # model evaluation

    <span class="c1"># set OMP_NUM_THREADS=1 for hpsklearn package</span>
    <span class="c1">#!export OMP_NUM_THREADS=1</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Environment: Google Colab&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting shap
  Downloading https://files.pythonhosted.org/packages/57/43/08f152a59a1d60f0328b476bdd58c791498989981ab9c6d595ec5448a86a/shap-0.32.1.tar.gz (259kB)
     |████████████████████████████████| 266kB 2.7MB/s 
Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from shap) (1.17.4)
Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from shap) (1.3.2)
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from shap) (0.21.3)
Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from shap) (0.25.3)
Requirement already satisfied: tqdm&gt;4.25.0 in /usr/local/lib/python3.6/dist-packages (from shap) (4.28.1)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn-&gt;shap) (0.14.0)
Requirement already satisfied: python-dateutil&gt;=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas-&gt;shap) (2.6.1)
Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas-&gt;shap) (2018.9)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil&gt;=2.6.1-&gt;pandas-&gt;shap) (1.12.0)
Building wheels for collected packages: shap
  Building wheel for shap (setup.py) ... done
  Created wheel for shap: filename=shap-0.32.1-cp36-cp36m-linux_x86_64.whl size=376814 sha256=3dcabfe5e8d6c799735e54b63295a87f91c2b4880ff2c8e24fa36a63198bcd2d
  Stored in directory: /root/.cache/pip/wheels/8e/b2/50/8fadb5a59789cb5bdeb01b800223be540651ae92915172050b
Successfully built shap
Installing collected packages: shap
Successfully installed shap-0.32.1
Environment: Google Colab
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">color_codes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># random state</span>
<span class="n">RANDOM_STATE</span><span class="o">=</span><span class="mi">100</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">RANDOM_STATE</span><span class="p">)</span> <span class="c1"># we need this in each cell</span>


<span class="c1"># Jupyter notebook settings for pandas</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="c1"># pd.set_option(&#39;display.float_format&#39;, &#39;{:,.4f}&#39;.format) # numbers sep by comma</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span> <span class="c1"># None for all the rows</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_colwidth&#39;</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>

<span class="nb">print</span><span class="p">([(</span><span class="n">x</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span><span class="n">x</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="n">np</span><span class="p">,</span> <span class="n">pd</span><span class="p">,</span><span class="n">sns</span><span class="p">,</span><span class="n">matplotlib</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[(&#39;numpy&#39;, &#39;1.17.4&#39;), (&#39;pandas&#39;, &#39;0.25.3&#39;), (&#39;seaborn&#39;, &#39;0.9.0&#39;), (&#39;matplotlib&#39;, &#39;3.1.1&#39;)]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="nx">javascript</span>
<span class="nx">IPython</span><span class="p">.</span><span class="nx">OutputArea</span><span class="p">.</span><span class="nx">auto_scroll_threshold</span> <span class="o">=</span> <span class="mi">9999</span><span class="p">;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">




<div id="22348317-cc0a-4400-a594-63ea07765815"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#22348317-cc0a-4400-a594-63ea07765815');
IPython.OutputArea.auto_scroll_threshold = 9999;
</script>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">import</span> <span class="nn">sklearn</span>

<span class="nb">print</span><span class="p">([(</span><span class="n">x</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span><span class="n">x</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="n">scipy</span><span class="p">,</span> <span class="n">sklearn</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[(&#39;scipy&#39;, &#39;1.3.2&#39;), (&#39;sklearn&#39;, &#39;0.21.3&#39;)]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># scale and split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="k">import</span> <span class="n">Pipeline</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># classifier</span>
<span class="kn">import</span> <span class="nn">lightgbm</span> <span class="k">as</span> <span class="nn">lgb</span>
<span class="kn">from</span> <span class="nn">lightgbm</span> <span class="k">import</span> <span class="n">LGBMRegressor</span>
<span class="n">lgb</span><span class="o">.</span><span class="n">__version__</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;2.2.3&#39;</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># six and pickle</span>
<span class="kn">import</span> <span class="nn">six</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">joblib</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># metrics</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">explained_variance_score</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># cross validation</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">cross_val_predict</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HPO</span>
<span class="kn">from</span> <span class="nn">hyperopt</span> <span class="k">import</span> <span class="n">fmin</span><span class="p">,</span> <span class="n">tpe</span><span class="p">,</span> <span class="n">hp</span><span class="p">,</span> <span class="n">STATUS_OK</span><span class="p">,</span> <span class="n">Trials</span>
<span class="kn">from</span> <span class="nn">hyperopt.pyll</span> <span class="k">import</span> <span class="n">scope</span>
<span class="kn">from</span> <span class="nn">hyperopt.pyll.stochastic</span> <span class="k">import</span> <span class="n">sample</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Important-Scripts">Important Scripts<a class="anchor-link" href="#Important-Scripts"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">show_method_attributes</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span><span class="n">start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inside</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Show all the attributes of a given method.</span>
<span class="sd">    Example:</span>
<span class="sd">    ========</span>
<span class="sd">    show_method_attributes(list)</span>
<span class="sd">     &quot;&quot;&quot;</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Object Type: {type(obj)}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">lst</span> <span class="o">=</span> <span class="p">[</span><span class="n">elem</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span> <span class="k">if</span> <span class="n">elem</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">!=</span><span class="s1">&#39;_&#39;</span> <span class="p">]</span>
    <span class="n">lst</span> <span class="o">=</span> <span class="p">[</span><span class="n">elem</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">lst</span> 
           <span class="k">if</span> <span class="n">elem</span> <span class="ow">not</span> <span class="ow">in</span> <span class="s1">&#39;os np pd sys time psycopg2&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="p">]</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">start</span><span class="p">,</span><span class="nb">str</span><span class="p">):</span>
        <span class="n">lst</span> <span class="o">=</span> <span class="p">[</span><span class="n">elem</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">lst</span> <span class="k">if</span> <span class="n">elem</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">start</span><span class="p">)]</span>
        
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">start</span><span class="p">,</span><span class="nb">tuple</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">start</span><span class="p">,</span><span class="nb">list</span><span class="p">):</span>
        <span class="n">lst</span> <span class="o">=</span> <span class="p">[</span><span class="n">elem</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">lst</span> <span class="k">for</span> <span class="n">start_elem</span> <span class="ow">in</span> <span class="n">start</span>
               <span class="k">if</span> <span class="n">elem</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">start_elem</span><span class="p">)]</span>
        
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inside</span><span class="p">,</span><span class="nb">str</span><span class="p">):</span>
        <span class="n">lst</span> <span class="o">=</span> <span class="p">[</span><span class="n">elem</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">lst</span> <span class="k">if</span> <span class="n">inside</span> <span class="ow">in</span> <span class="n">elem</span><span class="p">]</span>
        
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inside</span><span class="p">,</span><span class="nb">tuple</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inside</span><span class="p">,</span><span class="nb">list</span><span class="p">):</span>
        <span class="n">lst</span> <span class="o">=</span> <span class="p">[</span><span class="n">elem</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">lst</span> <span class="k">for</span> <span class="n">inside_elem</span> <span class="ow">in</span> <span class="n">inside</span>
               <span class="k">if</span> <span class="n">inside_elem</span> <span class="ow">in</span> <span class="n">elem</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">lst</span><span class="p">,</span><span class="n">ncols</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">adjustedR2</span><span class="p">(</span><span class="n">rsquared</span><span class="p">,</span><span class="n">nrows</span><span class="p">,</span><span class="n">kcols</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">rsquared</span><span class="o">-</span> <span class="p">(</span><span class="n">kcols</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">nrows</span><span class="o">-</span><span class="n">kcols</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">rsquared</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Load-the-data">Load the data<a class="anchor-link" href="#Load-the-data"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># df_clean = pd.read_csv(&#39;../data/processed/data_cleaned_encoded.csv&#39;)</span>
<span class="n">df_clean</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://github.com/bhishanpdl/Project_House_Price_Prediction/blob/master/src/data/processed/data_cleaned_encoded.csv?raw=true&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_clean</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">df_clean</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(21613, 92)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>date</th>
      <th>price</th>
      <th>bedrooms</th>
      <th>bathrooms</th>
      <th>sqft_living</th>
      <th>sqft_lot</th>
      <th>floors</th>
      <th>waterfront</th>
      <th>view</th>
      <th>condition</th>
      <th>grade</th>
      <th>sqft_above</th>
      <th>sqft_basement</th>
      <th>yr_built</th>
      <th>yr_renovated</th>
      <th>zipcode</th>
      <th>lat</th>
      <th>long</th>
      <th>sqft_living15</th>
      <th>sqft_lot15</th>
      <th>yr_sales</th>
      <th>age</th>
      <th>yr_renovated2</th>
      <th>age_after_renovation</th>
      <th>zipcode_top10</th>
      <th>zipcode_houses</th>
      <th>basement_bool</th>
      <th>renovation_bool</th>
      <th>age_cat</th>
      <th>age_after_renovation_cat</th>
      <th>waterfront_0</th>
      <th>waterfront_1</th>
      <th>view_0</th>
      <th>view_1</th>
      <th>view_2</th>
      <th>view_3</th>
      <th>view_4</th>
      <th>condition_1</th>
      <th>condition_2</th>
      <th>condition_3</th>
      <th>condition_4</th>
      <th>condition_5</th>
      <th>grade_1</th>
      <th>grade_10</th>
      <th>grade_11</th>
      <th>grade_12</th>
      <th>grade_13</th>
      <th>grade_3</th>
      <th>grade_4</th>
      <th>grade_5</th>
      <th>grade_6</th>
      <th>grade_7</th>
      <th>grade_8</th>
      <th>grade_9</th>
      <th>zipcode_top10_98004</th>
      <th>zipcode_top10_98006</th>
      <th>zipcode_top10_98033</th>
      <th>zipcode_top10_98039</th>
      <th>zipcode_top10_98040</th>
      <th>zipcode_top10_98102</th>
      <th>zipcode_top10_98105</th>
      <th>zipcode_top10_98155</th>
      <th>zipcode_top10_98177</th>
      <th>zipcode_top10_others</th>
      <th>age_cat_0</th>
      <th>age_cat_1</th>
      <th>age_cat_2</th>
      <th>age_cat_3</th>
      <th>age_cat_4</th>
      <th>age_cat_5</th>
      <th>age_cat_6</th>
      <th>age_cat_7</th>
      <th>age_cat_8</th>
      <th>age_cat_9</th>
      <th>age_after_renovation_cat_0</th>
      <th>age_after_renovation_cat_1</th>
      <th>age_after_renovation_cat_2</th>
      <th>age_after_renovation_cat_3</th>
      <th>age_after_renovation_cat_4</th>
      <th>age_after_renovation_cat_5</th>
      <th>age_after_renovation_cat_6</th>
      <th>age_after_renovation_cat_7</th>
      <th>age_after_renovation_cat_8</th>
      <th>age_after_renovation_cat_9</th>
      <th>log1p_price</th>
      <th>log1p_sqft_living</th>
      <th>log1p_sqft_lot</th>
      <th>log1p_sqft_above</th>
      <th>log1p_sqft_basement</th>
      <th>log1p_sqft_living15</th>
      <th>log1p_sqft_lot15</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7129300520</td>
      <td>2014-10-13</td>
      <td>221900.0</td>
      <td>3</td>
      <td>1.00</td>
      <td>1180</td>
      <td>5650</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1180</td>
      <td>0</td>
      <td>1955</td>
      <td>0</td>
      <td>98178</td>
      <td>47.5112</td>
      <td>-122.257</td>
      <td>1340</td>
      <td>5650</td>
      <td>2014</td>
      <td>59</td>
      <td>1955</td>
      <td>59</td>
      <td>others</td>
      <td>262</td>
      <td>0</td>
      <td>0</td>
      <td>5</td>
      <td>5</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>12.309987</td>
      <td>7.074117</td>
      <td>8.639588</td>
      <td>7.074117</td>
      <td>0.000000</td>
      <td>7.201171</td>
      <td>8.639588</td>
    </tr>
    <tr>
      <th>1</th>
      <td>6414100192</td>
      <td>2014-12-09</td>
      <td>538000.0</td>
      <td>3</td>
      <td>2.25</td>
      <td>2570</td>
      <td>7242</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>2170</td>
      <td>400</td>
      <td>1951</td>
      <td>1991</td>
      <td>98125</td>
      <td>47.7210</td>
      <td>-122.319</td>
      <td>1690</td>
      <td>7639</td>
      <td>2014</td>
      <td>63</td>
      <td>1991</td>
      <td>23</td>
      <td>others</td>
      <td>410</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>13.195616</td>
      <td>7.852050</td>
      <td>8.887791</td>
      <td>7.682943</td>
      <td>5.993961</td>
      <td>7.433075</td>
      <td>8.941153</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5631500400</td>
      <td>2015-02-25</td>
      <td>180000.0</td>
      <td>2</td>
      <td>1.00</td>
      <td>770</td>
      <td>10000</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>6</td>
      <td>770</td>
      <td>0</td>
      <td>1933</td>
      <td>0</td>
      <td>98028</td>
      <td>47.7379</td>
      <td>-122.233</td>
      <td>2720</td>
      <td>8062</td>
      <td>2015</td>
      <td>82</td>
      <td>1933</td>
      <td>82</td>
      <td>others</td>
      <td>283</td>
      <td>0</td>
      <td>0</td>
      <td>7</td>
      <td>7</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>12.100718</td>
      <td>6.647688</td>
      <td>9.210440</td>
      <td>6.647688</td>
      <td>0.000000</td>
      <td>7.908755</td>
      <td>8.995041</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2487200875</td>
      <td>2014-12-09</td>
      <td>604000.0</td>
      <td>4</td>
      <td>3.00</td>
      <td>1960</td>
      <td>5000</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>5</td>
      <td>7</td>
      <td>1050</td>
      <td>910</td>
      <td>1965</td>
      <td>0</td>
      <td>98136</td>
      <td>47.5208</td>
      <td>-122.393</td>
      <td>1360</td>
      <td>5000</td>
      <td>2014</td>
      <td>49</td>
      <td>1965</td>
      <td>49</td>
      <td>others</td>
      <td>263</td>
      <td>1</td>
      <td>0</td>
      <td>4</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>13.311331</td>
      <td>7.581210</td>
      <td>8.517393</td>
      <td>6.957497</td>
      <td>6.814543</td>
      <td>7.215975</td>
      <td>8.517393</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1954400510</td>
      <td>2015-02-18</td>
      <td>510000.0</td>
      <td>3</td>
      <td>2.00</td>
      <td>1680</td>
      <td>8080</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>8</td>
      <td>1680</td>
      <td>0</td>
      <td>1987</td>
      <td>0</td>
      <td>98074</td>
      <td>47.6168</td>
      <td>-122.045</td>
      <td>1800</td>
      <td>7503</td>
      <td>2015</td>
      <td>28</td>
      <td>1987</td>
      <td>28</td>
      <td>others</td>
      <td>441</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>13.142168</td>
      <td>7.427144</td>
      <td>8.997271</td>
      <td>7.427144</td>
      <td>0.000000</td>
      <td>7.496097</td>
      <td>8.923191</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># I will just take column names from this and will use cleaned data further.</span>
<span class="c1"># df_raw = pd.read_csv(&#39;../data/raw/kc_house_data.csv&#39;)</span>
<span class="n">df_raw</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://github.com/bhishanpdl/Project_House_Price_Prediction/blob/master/src/data/raw/kc_house_data.csv?raw=true&#39;</span><span class="p">,</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df_raw</span><span class="o">.</span><span class="n">columns</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Index([&#39;id&#39;, &#39;date&#39;, &#39;price&#39;, &#39;bedrooms&#39;, &#39;bathrooms&#39;, &#39;sqft_living&#39;,
       &#39;sqft_lot&#39;, &#39;floors&#39;, &#39;waterfront&#39;, &#39;view&#39;, &#39;condition&#39;, &#39;grade&#39;,
       &#39;sqft_above&#39;, &#39;sqft_basement&#39;, &#39;yr_built&#39;, &#39;yr_renovated&#39;, &#39;zipcode&#39;,
       &#39;lat&#39;, &#39;long&#39;, &#39;sqft_living15&#39;, &#39;sqft_lot15&#39;],
      dtype=&#39;object&#39;)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">features_raw_all</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;bathrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;sqft_living&#39;</span><span class="p">,</span>
       <span class="s1">&#39;sqft_lot&#39;</span><span class="p">,</span> <span class="s1">&#39;floors&#39;</span><span class="p">,</span> <span class="s1">&#39;waterfront&#39;</span><span class="p">,</span> <span class="s1">&#39;view&#39;</span><span class="p">,</span> <span class="s1">&#39;condition&#39;</span><span class="p">,</span> <span class="s1">&#39;grade&#39;</span><span class="p">,</span>
       <span class="s1">&#39;sqft_above&#39;</span><span class="p">,</span> <span class="s1">&#39;sqft_basement&#39;</span><span class="p">,</span> <span class="s1">&#39;yr_built&#39;</span><span class="p">,</span> <span class="s1">&#39;yr_renovated&#39;</span><span class="p">,</span> <span class="s1">&#39;zipcode&#39;</span><span class="p">,</span>
       <span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="s1">&#39;long&#39;</span><span class="p">,</span> <span class="s1">&#39;sqft_living15&#39;</span><span class="p">,</span> <span class="s1">&#39;sqft_lot15&#39;</span><span class="p">]</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df_clean</span><span class="p">[</span><span class="n">features_raw_all</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]]</span>


<span class="n">dict_features</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">features_raw_all</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dict_features</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{0: &#39;bedrooms&#39;, 1: &#39;bathrooms&#39;, 2: &#39;sqft_living&#39;, 3: &#39;sqft_lot&#39;, 4: &#39;floors&#39;, 5: &#39;waterfront&#39;, 6: &#39;view&#39;, 7: &#39;condition&#39;, 8: &#39;grade&#39;, 9: &#39;sqft_above&#39;, 10: &#39;sqft_basement&#39;, 11: &#39;yr_built&#39;, 12: &#39;yr_renovated&#39;, 13: &#39;zipcode&#39;, 14: &#39;lat&#39;, 15: &#39;long&#39;, 16: &#39;sqft_living15&#39;, 17: &#39;sqft_lot15&#39;}
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Log-transform-large-values">Log transform large values<a class="anchor-link" href="#Log-transform-large-values"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">log_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">,</span><span class="s1">&#39;sqft_living&#39;</span><span class="p">,</span><span class="s1">&#39;sqft_living15&#39;</span><span class="p">,</span><span class="s1">&#39;sqft_lot&#39;</span><span class="p">,</span><span class="s1">&#39;sqft_lot15&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">log_cols</span><span class="p">:</span>
    <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  after removing the cwd from sys.path.
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Train-Test-split-after-log-transform">Train-Test split after log transform<a class="anchor-link" href="#Train-Test-split-after-log-transform"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">features_raw_all</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">train_test_split</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.20</span><span class="p">,</span>
                                                 <span class="n">random_state</span><span class="o">=</span><span class="n">RANDOM_STATE</span><span class="p">)</span>

<span class="n">Xtrain</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">ytrain</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Xtest</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">ytest</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Xtrain</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">2</span><span class="p">],</span> <span class="n">Xtest</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">2</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((17290, 18),
 (17290,),
 (4323, 18),
 (4323,),
 array([3.  , 1.75]),
 array([3. , 2.5]))</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Train-Validation-Split">Train-Validation Split<a class="anchor-link" href="#Train-Validation-Split"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># train validation split</span>
<span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xvalid</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">yvalid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">RANDOM_STATE</span><span class="p">)</span>

<span class="n">Xtrain</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Xtest</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Xvalid</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((13832, 18), (4323, 18), (3458, 18))</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Scaling-the-Data">Scaling the Data<a class="anchor-link" href="#Scaling-the-Data"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">StandardScaler</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">)</span>

<span class="n">Xtrain_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">)</span>
<span class="n">Xtest_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
<span class="n">Xvalid_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xvalid</span><span class="p">)</span>

<span class="n">Xtrain_scaled</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">2</span><span class="p">],</span> <span class="n">Xtest_scaled</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">2</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(array([1.73814209, 1.166196  ]), array([-0.38121452,  0.51397123]))</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_Xtrain_scaled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">Xtrain_scaled</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">features_raw_all</span><span class="p">)</span>
<span class="n">df_Xvalid_scaled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">Xvalid_scaled</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">features_raw_all</span><span class="p">)</span>
<span class="n">df_Xtest_scaled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">Xtest_scaled</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">features_raw_all</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Modelling-lightgbm">Modelling lightgbm<a class="anchor-link" href="#Modelling-lightgbm"> </a></h1><p>References:</p>
<ul>
<li><a href="https://lightgbm.readthedocs.io/en/latest/Parameters.html">LightGBM Parameters</a></li>
<li><a href="https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html">LightGBM Parameters Tuning</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/">analytics vidhya: Which algorithm takes the crown: Light GBM vs XGBOOST?</a></li>
<li><a href="https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/plot_example.py">lightgbm plotting official</a></li>
</ul>
<p><strong>Light GBM</strong></p>
<p>This is based on decision tree and it splits the tree leaf with best fit instead of splitting the level-wise (depth-wise).
<img src="images/xgboost_split" alt="">
<img src="images/lightgbm_split" alt=""></p>
<ul>
<li><p><strong>Fast</strong>: Light GBM is fast as light, it is much faster than other boosting algorithms such as AdaBoost and XGboost.</p>
</li>
<li><p><strong>Low Memory</strong>: It uses lower memory than other boosting algorithms since it uses discrete bins instead of continuous variables.</p>
</li>
<li><strong>Better Accuracy</strong>: It gives better accuracy then other boosting algorithms. However, as for all other machine learning techniques it needs hyperparamter tuning.</li>
<li><strong>Scaling for large data</strong>: Since this algorithm is lighting
fast we can use this algorithm for large datasets.</li>
<li><strong>Parallelism Supported</strong>: Boosting algoriths are generally sequential. They need to boost the weak learner in each iteration. But this implementation uses some clever tricks to use parallel processing. </li>
<li><strong>GPU Support</strong>: This algorithm also support gpu for faster training.</li>
</ul>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">lightgbm</span> <span class="k">as</span> <span class="nn">lgb</span>

<span class="n">show_method_attributes</span><span class="p">(</span><span class="n">lgb</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Object Type: &lt;class &#39;module&#39;&gt;

</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Booster</td>
      <td>LGBMRanker</td>
      <td>callback</td>
      <td>dir_path</td>
      <td>plot_importance</td>
      <td>print_evaluation</td>
      <td>system</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Dataset</td>
      <td>LGBMRegressor</td>
      <td>compat</td>
      <td>early_stopping</td>
      <td>plot_metric</td>
      <td>record_evaluation</td>
      <td>train</td>
    </tr>
    <tr>
      <th>2</th>
      <td>LGBMClassifier</td>
      <td>absolute_import</td>
      <td>create_tree_digraph</td>
      <td>engine</td>
      <td>plot_tree</td>
      <td>reset_parameter</td>
      <td>warnings</td>
    </tr>
    <tr>
      <th>3</th>
      <td>LGBMModel</td>
      <td>basic</td>
      <td>cv</td>
      <td>libpath</td>
      <td>plotting</td>
      <td>sklearn</td>
      <td></td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">lightgbm</span> <span class="k">as</span> <span class="nn">lgb</span>
<span class="kn">from</span> <span class="nn">lightgbm</span> <span class="k">import</span> <span class="n">LGBMRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">cross_val_predict</span>


<span class="c1"># model fit</span>
<span class="n">model_lgb</span> <span class="o">=</span> <span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">RANDOM_STATE</span><span class="p">)</span>

<span class="n">model_lgb</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>LGBMRegressor(boosting_type=&#39;gbdt&#39;, class_weight=None, colsample_bytree=1.0,
              importance_type=&#39;split&#39;, learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=100, reg_alpha=0.0, reg_lambda=0.0, silent=True,
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># model fit</span>
<span class="n">model_lgb</span> <span class="o">=</span> <span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">RANDOM_STATE</span><span class="p">)</span>
<span class="n">model_lgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain_scaled</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>

<span class="c1"># cross validation score</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">RANDOM_STATE</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model_lgb</span><span class="p">,</span> <span class="n">Xtrain_scaled</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> 
                         <span class="n">scoring</span> <span class="o">=</span> <span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">)</span>
<span class="c1"># sklearn.metrics.SCORERS.keys()</span>
<span class="n">train_neg_mse</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train Negative MSE CV: &#39;</span><span class="p">,</span> <span class="n">train_neg_mse</span><span class="p">)</span>

<span class="c1"># save the model</span>
<span class="c1"># joblib.dump(model_lgb, &#39;model_lgb.pkl&#39;)</span>
<span class="c1"># model_lgb = joblib.load(&#39;model_xgb.pkl&#39;)</span>

<span class="c1"># predictions</span>
<span class="n">ypreds_cv</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">model_lgb</span><span class="p">,</span> <span class="n">Xtest_scaled</span><span class="p">,</span> <span class="n">ytest</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">)</span>
<span class="n">ypreds</span> <span class="o">=</span> <span class="n">ypreds_cv</span>

<span class="c1"># rmse</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypreds</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test RMSE: </span><span class="si">{rmse}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># explained variance score</span>
<span class="n">evs</span> <span class="o">=</span> <span class="n">explained_variance_score</span><span class="p">(</span><span class="n">ypreds</span><span class="p">,</span> <span class="n">ytest</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Explained Variance Score: &#39;</span><span class="p">,</span> <span class="n">evs</span><span class="p">)</span>

<span class="c1"># r-squared values</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">ypreds</span><span class="p">)</span>
<span class="n">ar2</span> <span class="o">=</span> <span class="n">adjustedR2</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span> <span class="n">Xtest_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Xtest_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;r_squared: &#39;</span><span class="p">,</span> <span class="n">r2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;adjustedr2: &#39;</span><span class="p">,</span> <span class="n">ar2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Train Negative MSE CV:  -0.028574683314057103
Test RMSE: 0.17382963792331269
Explained Variance Score:  0.8776172174227181
r_squared:  0.8922179000234329
adjustedr2:  0.8917922796518646
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">show_method_attributes</span><span class="p">(</span><span class="n">model_lgb</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Object Type: &lt;class &#39;lightgbm.sklearn.LGBMRegressor&#39;&gt;

</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>best_iteration_</td>
      <td>colsample_bytree</td>
      <td>importance_type</td>
      <td>min_split_gain</td>
      <td>objective</td>
      <td>reg_alpha</td>
      <td>silent</td>
    </tr>
    <tr>
      <th>1</th>
      <td>best_score_</td>
      <td>evals_result_</td>
      <td>learning_rate</td>
      <td>n_estimators</td>
      <td>objective_</td>
      <td>reg_lambda</td>
      <td>subsample</td>
    </tr>
    <tr>
      <th>2</th>
      <td>booster_</td>
      <td>feature_importances_</td>
      <td>max_depth</td>
      <td>n_features_</td>
      <td>predict</td>
      <td>score</td>
      <td>subsample_for_bin</td>
    </tr>
    <tr>
      <th>3</th>
      <td>boosting_type</td>
      <td>fit</td>
      <td>min_child_samples</td>
      <td>n_jobs</td>
      <td>random_state</td>
      <td>set_params</td>
      <td>subsample_freq</td>
    </tr>
    <tr>
      <th>4</th>
      <td>class_weight</td>
      <td>get_params</td>
      <td>min_child_weight</td>
      <td>num_leaves</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># feature importance</span>
<span class="n">df_imp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">features_raw_all</span><span class="p">,</span>
                       <span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="n">model_lgb</span><span class="o">.</span><span class="n">feature_importances_</span>
                       <span class="p">})</span> 

<span class="n">df_imp</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;Importance&#39;</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">background_gradient</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<style  type="text/css" >
    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row0_col1 {
            background-color:  #023858;
            color:  #f1f1f1;
        }    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row1_col1 {
            background-color:  #045d92;
            color:  #f1f1f1;
        }    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row2_col1 {
            background-color:  #76aad0;
            color:  #000000;
        }    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row3_col1 {
            background-color:  #80aed2;
            color:  #000000;
        }    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row4_col1 {
            background-color:  #84b0d3;
            color:  #000000;
        }    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row5_col1 {
            background-color:  #b1c2de;
            color:  #000000;
        }    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row6_col1 {
            background-color:  #b9c6e0;
            color:  #000000;
        }    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row7_col1 {
            background-color:  #c9cee4;
            color:  #000000;
        }    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row8_col1 {
            background-color:  #d2d2e7;
            color:  #000000;
        }    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row9_col1 {
            background-color:  #dbdaeb;
            color:  #000000;
        }    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row10_col1 {
            background-color:  #e0deed;
            color:  #000000;
        }    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row11_col1 {
            background-color:  #eae6f1;
            color:  #000000;
        }    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row12_col1 {
            background-color:  #ede8f3;
            color:  #000000;
        }    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row13_col1 {
            background-color:  #f2ecf5;
            color:  #000000;
        }    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row14_col1 {
            background-color:  #f6eff7;
            color:  #000000;
        }    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row15_col1 {
            background-color:  #f8f1f8;
            color:  #000000;
        }    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row16_col1 {
            background-color:  #faf2f8;
            color:  #000000;
        }    #T_a6090aec_0c6b_11ea_8696_0242ac1c0002row17_col1 {
            background-color:  #fff7fb;
            color:  #000000;
        }</style><table id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002" ><thead>    <tr>        <th class="blank level0" ></th>        <th class="col_heading level0 col0" >Feature</th>        <th class="col_heading level0 col1" >Importance</th>    </tr></thead><tbody>
                <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row0" class="row_heading level0 row0" >14</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row0_col0" class="data row0 col0" >lat</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row0_col1" class="data row0 col1" >521</td>
            </tr>
            <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row1" class="row_heading level0 row1" >15</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row1_col0" class="data row1 col0" >long</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row1_col1" class="data row1 col1" >450</td>
            </tr>
            <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row2" class="row_heading level0 row2" >11</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row2_col0" class="data row2 col0" >yr_built</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row2_col1" class="data row2 col1" >266</td>
            </tr>
            <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row3" class="row_heading level0 row3" >3</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row3_col0" class="data row3 col0" >sqft_lot</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row3_col1" class="data row3 col1" >255</td>
            </tr>
            <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row4" class="row_heading level0 row4" >2</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row4_col0" class="data row4 col0" >sqft_living</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row4_col1" class="data row4 col1" >248</td>
            </tr>
            <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row5" class="row_heading level0 row5" >13</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row5_col0" class="data row5 col0" >zipcode</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row5_col1" class="data row5 col1" >190</td>
            </tr>
            <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row6" class="row_heading level0 row6" >16</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row6_col0" class="data row6 col0" >sqft_living15</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row6_col1" class="data row6 col1" >179</td>
            </tr>
            <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row7" class="row_heading level0 row7" >17</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row7_col0" class="data row7 col0" >sqft_lot15</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row7_col1" class="data row7 col1" >154</td>
            </tr>
            <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row8" class="row_heading level0 row8" >9</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row8_col0" class="data row8 col0" >sqft_above</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row8_col1" class="data row8 col1" >141</td>
            </tr>
            <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row9" class="row_heading level0 row9" >8</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row9_col0" class="data row9 col0" >grade</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row9_col1" class="data row9 col1" >119</td>
            </tr>
            <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row10" class="row_heading level0 row10" >7</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row10_col0" class="data row10 col0" >condition</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row10_col1" class="data row10 col1" >108</td>
            </tr>
            <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row11" class="row_heading level0 row11" >6</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row11_col0" class="data row11 col0" >view</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row11_col1" class="data row11 col1" >85</td>
            </tr>
            <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row12" class="row_heading level0 row12" >10</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row12_col0" class="data row12 col0" >sqft_basement</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row12_col1" class="data row12 col1" >77</td>
            </tr>
            <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row13" class="row_heading level0 row13" >1</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row13_col0" class="data row13 col0" >bathrooms</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row13_col1" class="data row13 col1" >62</td>
            </tr>
            <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row14" class="row_heading level0 row14" >12</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row14_col0" class="data row14 col0" >yr_renovated</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row14_col1" class="data row14 col1" >48</td>
            </tr>
            <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row15" class="row_heading level0 row15" >5</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row15_col0" class="data row15 col0" >waterfront</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row15_col1" class="data row15 col1" >42</td>
            </tr>
            <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row16" class="row_heading level0 row16" >0</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row16_col0" class="data row16 col0" >bedrooms</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row16_col1" class="data row16 col1" >37</td>
            </tr>
            <tr>
                        <th id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002level0_row17" class="row_heading level0 row17" >4</th>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row17_col0" class="data row17 col0" >floors</td>
                        <td id="T_a6090aec_0c6b_11ea_8696_0242ac1c0002row17_col1" class="data row17 col1" >18</td>
            </tr>
    </tbody></table>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_imp</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;Importance&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;Feature&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;Importance&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1b82a57828&gt;</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c10_regression_modelling_boosting_lgb_37_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">axsub</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">model_lgb</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">features_raw_all</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dict_features</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;bedrooms&#39;, &#39;bathrooms&#39;, &#39;sqft_living&#39;, &#39;sqft_lot&#39;, &#39;floors&#39;, &#39;waterfront&#39;, &#39;view&#39;, &#39;condition&#39;, &#39;grade&#39;, &#39;sqft_above&#39;, &#39;sqft_basement&#39;, &#39;yr_built&#39;, &#39;yr_renovated&#39;, &#39;zipcode&#39;, &#39;lat&#39;, &#39;long&#39;, &#39;sqft_living15&#39;, &#39;sqft_lot15&#39;]
{0: &#39;bedrooms&#39;, 1: &#39;bathrooms&#39;, 2: &#39;sqft_living&#39;, 3: &#39;sqft_lot&#39;, 4: &#39;floors&#39;, 5: &#39;waterfront&#39;, 6: &#39;view&#39;, 7: &#39;condition&#39;, 8: &#39;grade&#39;, 9: &#39;sqft_above&#39;, 10: &#39;sqft_basement&#39;, 11: &#39;yr_built&#39;, 12: &#39;yr_renovated&#39;, 13: &#39;zipcode&#39;, 14: &#39;lat&#39;, 15: &#39;long&#39;, 16: &#39;sqft_living15&#39;, 17: &#39;sqft_lot15&#39;}
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c10_regression_modelling_boosting_lgb_38_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">axsub</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">model_lgb</span><span class="p">)</span>

<span class="n">Text_yticklabels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">axsub</span><span class="o">.</span><span class="n">get_yticklabels</span><span class="p">())</span>
<span class="n">dict_features</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">features_raw_all</span><span class="p">))</span>
<span class="n">lst_yticklabels</span> <span class="o">=</span> <span class="p">[</span> <span class="n">Text_yticklabels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span><span class="o">.</span><span class="n">lstrip</span><span class="p">(</span><span class="s1">&#39;Column_&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Text_yticklabels</span><span class="p">))]</span>
<span class="n">lst_yticklabels</span> <span class="o">=</span> <span class="p">[</span> <span class="n">dict_features</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">lst_yticklabels</span><span class="p">]</span>

<span class="n">axsub</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">lst_yticklabels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dict_features</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{0: &#39;bedrooms&#39;, 1: &#39;bathrooms&#39;, 2: &#39;sqft_living&#39;, 3: &#39;sqft_lot&#39;, 4: &#39;floors&#39;, 5: &#39;waterfront&#39;, 6: &#39;view&#39;, 7: &#39;condition&#39;, 8: &#39;grade&#39;, 9: &#39;sqft_above&#39;, 10: &#39;sqft_basement&#39;, 11: &#39;yr_built&#39;, 12: &#39;yr_renovated&#39;, 13: &#39;zipcode&#39;, 14: &#39;lat&#39;, 15: &#39;long&#39;, 16: &#39;sqft_living15&#39;, 17: &#39;sqft_lot15&#39;}
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c10_regression_modelling_boosting_lgb_39_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="LightGBM-using-Dataset-(Memory-Reducing-data-container)">LightGBM using Dataset (Memory Reducing data container)<a class="anchor-link" href="#LightGBM-using-Dataset-(Memory-Reducing-data-container)"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">categorical_feature</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;view&#39;</span><span class="p">,</span><span class="s1">&#39;grade&#39;</span><span class="p">]</span>
<span class="n">dtrain</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">Xtrain_scaled</span><span class="p">,</span><span class="n">ytrain</span><span class="p">,</span>
                     <span class="n">free_raw_data</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                     <span class="n">feature_name</span><span class="o">=</span><span class="n">features_raw_all</span><span class="p">,</span>
                     <span class="n">categorical_feature</span><span class="o">=</span><span class="n">categorical_feature</span>
                     <span class="p">)</span> 

<span class="n">dvalid</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">Xvalid_scaled</span><span class="p">,</span><span class="n">yvalid</span><span class="p">,</span>
                     <span class="n">free_raw_data</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                     <span class="n">feature_name</span><span class="o">=</span><span class="n">features_raw_all</span><span class="p">,</span>
                     <span class="n">categorical_feature</span><span class="o">=</span><span class="n">categorical_feature</span>
                     <span class="p">)</span>
<span class="nb">type</span><span class="p">(</span><span class="n">dtrain</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>lightgbm.basic.Dataset</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># params</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;objective&#39;</span> <span class="p">:</span> <span class="s1">&#39;regression&#39;</span><span class="p">,</span> <span class="c1"># regression binary etc</span>
    <span class="s1">&#39;metric&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span><span class="s1">&#39;rmse&#39;</span><span class="p">,</span><span class="s1">&#39;mape&#39;</span><span class="p">],</span>
    <span class="s1">&#39;num_leaves&#39;</span> <span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span>
    <span class="s1">&#39;learning_rate&#39;</span> <span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
    <span class="s1">&#39;feature_fraction&#39;</span> <span class="p">:</span> <span class="mf">0.6</span><span class="p">,</span>
    <span class="s1">&#39;verbosity&#39;</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span>
<span class="p">}</span>
<span class="n">num_boost_round</span> <span class="o">=</span> <span class="mi">500_000</span>
<span class="n">evals_result</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># to record eval results for plotting</span>
<span class="n">model_lgb</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span><span class="n">dtrain</span><span class="p">,</span><span class="n">num_boost_round</span><span class="o">=</span><span class="n">num_boost_round</span><span class="p">,</span>
    <span class="n">valid_sets</span><span class="o">=</span><span class="p">[</span><span class="n">dtrain</span><span class="p">,</span> <span class="n">dvalid</span><span class="p">],</span>
    <span class="n">valid_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;valid&quot;</span><span class="p">],</span>
    <span class="n">evals_result</span><span class="o">=</span><span class="n">evals_result</span><span class="p">,</span>
    <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="c1"># choose num_boost_round much larger than this</span>
    <span class="n">verbose_eval</span><span class="o">=</span><span class="mi">500</span> <span class="c1"># print every nth interval</span>
<span class="p">)</span>

<span class="c1"># test the model</span>
<span class="n">ypreds</span> <span class="o">=</span> <span class="n">model_lgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtest_scaled</span><span class="p">)</span>


<span class="c1"># rmse</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypreds</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test RMSE: </span><span class="si">{rmse}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># explained variance score</span>
<span class="n">evs</span> <span class="o">=</span> <span class="n">explained_variance_score</span><span class="p">(</span><span class="n">ypreds</span><span class="p">,</span> <span class="n">ytest</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Explained Variance Score: &#39;</span><span class="p">,</span> <span class="n">evs</span><span class="p">)</span>

<span class="c1"># r-squared values</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">ypreds</span><span class="p">)</span>
<span class="n">ar2</span> <span class="o">=</span> <span class="n">adjustedR2</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span> <span class="n">Xtest_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Xtest_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;r_squared: &#39;</span><span class="p">,</span> <span class="n">r2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;adjustedr2: &#39;</span><span class="p">,</span> <span class="n">ar2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.
  warnings.warn(&#39;Using categorical_feature in Dataset.&#39;)
/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:762: UserWarning: categorical_feature in param dict is overridden.
  warnings.warn(&#39;categorical_feature in param dict is overridden.&#39;)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Training until validation scores don&#39;t improve for 500 rounds.
[500]	train&#39;s mape: 0.00643455	train&#39;s rmse: 0.115779	train&#39;s l2: 0.0134049	train&#39;s l1: 0.0834248	valid&#39;s mape: 0.00909496	valid&#39;s rmse: 0.167545	valid&#39;s l2: 0.0280714	valid&#39;s l1: 0.118542
[1000]	train&#39;s mape: 0.0050704	train&#39;s rmse: 0.0914841	train&#39;s l2: 0.00836935	train&#39;s l1: 0.0656333	valid&#39;s mape: 0.0088955	valid&#39;s rmse: 0.164841	valid&#39;s l2: 0.0271727	valid&#39;s l1: 0.115882
[1500]	train&#39;s mape: 0.00430104	train&#39;s rmse: 0.0783976	train&#39;s l2: 0.00614618	train&#39;s l1: 0.0556356	valid&#39;s mape: 0.00888584	valid&#39;s rmse: 0.164888	valid&#39;s l2: 0.0271881	valid&#39;s l1: 0.115734
Early stopping, best iteration is:
[1201]	train&#39;s mape: 0.00471743	train&#39;s rmse: 0.0854446	train&#39;s l2: 0.00730078	train&#39;s l1: 0.061043	valid&#39;s mape: 0.00888527	valid&#39;s rmse: 0.164773	valid&#39;s l2: 0.02715	valid&#39;s l1: 0.115737
Test RMSE: 0.1645677933019571
Explained Variance Score:  0.8905012050338257
r_squared:  0.9033974298345553
adjustedr2:  0.9030159562706035
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">evals_result</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>train</th>
      <th>valid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>mape</th>
      <td>[0.03138427455091259, 0.031142267382655783, 0.03088415454574578, 0.03061809112844684, 0.03035537153030712, 0.030130052572900298, 0.029867586098882144, 0.029674333342703897, 0.029477174570082535, 0...</td>
      <td>[0.031115612276712855, 0.030879903326551578, 0.030626120860143016, 0.030366326795805153, 0.030108849751448872, 0.029889771138481375, 0.029634607172652656, 0.02945475813393384, 0.029268187218783877...</td>
    </tr>
    <tr>
      <th>rmse</th>
      <td>[0.5222055830189195, 0.5182009640171444, 0.5140695486266327, 0.5098141418233337, 0.5055851163399969, 0.5018375587966158, 0.4975995898724016, 0.4943052771611014, 0.4909485823620535, 0.4869053716439...</td>
      <td>[0.5225338204405761, 0.5185610803565348, 0.5145247981323307, 0.5103849454171109, 0.5062310053314425, 0.5025539554958461, 0.49841141506855013, 0.49526604670395014, 0.4920363761519843, 0.48811352681...</td>
    </tr>
    <tr>
      <th>l2</th>
      <td>[0.2726986709361296, 0.2685322391082979, 0.2642675008251899, 0.25991045920306227, 0.2556163098645282, 0.2518409354189469, 0.24760535184118226, 0.24433770702931326, 0.24103051052331004, 0.237076840...</td>
      <td>[0.27304159350422413, 0.26890559406053655, 0.2647357678931156, 0.2604927925084272, 0.256269830758883, 0.25256047818452093, 0.24841393867063455, 0.24528845701775934, 0.24209979545677698, 0.23825481...</td>
    </tr>
    <tr>
      <th>l1</th>
      <td>[0.4099976775970142, 0.40683272629140743, 0.4034598961700856, 0.39998237520630475, 0.39654850354908533, 0.39360019119790085, 0.3901685255666731, 0.3876344276715699, 0.3850491560525147, 0.381772496...</td>
      <td>[0.40794391361911103, 0.4048492567002095, 0.4015246814403818, 0.3981201855291414, 0.3947447194912141, 0.3918667154087543, 0.3885208584847097, 0.3861518679077619, 0.38369293910011854, 0.38048205844...</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Plotting metrics recorded during training...&#39;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">plot_metric</span><span class="p">(</span><span class="n">evals_result</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;rmse&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Plotting metrics recorded during training...
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c10_regression_modelling_boosting_lgb_44_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Plotting metrics recorded during training...&#39;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">plot_metric</span><span class="p">(</span><span class="n">evals_result</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Plotting metrics recorded during training...
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c10_regression_modelling_boosting_lgb_45_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Plotting feature importances...&#39;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">model_lgb</span><span class="p">,</span> <span class="n">max_num_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Plotting feature importances...
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c10_regression_modelling_boosting_lgb_46_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Plotting 54th tree...&#39;</span><span class="p">)</span>  <span class="c1"># one tree use categorical feature to split</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">model_lgb</span><span class="p">,</span> <span class="n">tree_index</span><span class="o">=</span><span class="mi">53</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">),</span> <span class="n">show_info</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;split_gain&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Plotting 54th tree...
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.810904 to fit
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c10_regression_modelling_boosting_lgb_47_2.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Plotting 54th tree with graphviz...&#39;</span><span class="p">)</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">create_tree_digraph</span><span class="p">(</span><span class="n">model_lgb</span><span class="p">,</span> <span class="n">tree_index</span><span class="o">=</span><span class="mi">53</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Tree54&#39;</span><span class="p">)</span>
<span class="n">graph</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">view</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Plotting 54th tree with graphviz...
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;Tree54.gv.pdf&#39;</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lgb</span><span class="o">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">model_lgb</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1b8229bd30&gt;</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c10_regression_modelling_boosting_lgb_49_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fe</span> <span class="o">=</span> <span class="n">model_lgb</span><span class="o">.</span><span class="n">feature_importance</span><span class="p">()</span>

<span class="n">df_imp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">fe</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">features_raw_all</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Feature_Importance&#39;</span><span class="p">])</span>

<span class="n">df_imp</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;Feature_Importance&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1b8242cbe0&gt;</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c10_regression_modelling_boosting_lgb_50_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lgb</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">model_lgb</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1b821da5c0&gt;</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c10_regression_modelling_boosting_lgb_51_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Cross-Validation">Cross Validation<a class="anchor-link" href="#Cross-Validation"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># # params</span>
<span class="c1"># params_small = {&#39;num_leaves&#39;:300,</span>
<span class="c1">#           &#39;objective&#39;:&#39;regression&#39;, # use binary for classification</span>
<span class="c1">#           &#39;max_depth&#39;:7,</span>
<span class="c1">#           &#39;learning_rate&#39;:.05,</span>
<span class="c1">#           &#39;max_bin&#39;:200,</span>
<span class="c1">#           &#39;min_data_in_leaf&#39;: 10,</span>
<span class="c1">#           &#39;random_state&#39;: RANDOM_STATE,</span>
<span class="c1">#           &#39;metric&#39;: [&#39;rmse&#39;, &#39;mae&#39;,&#39;mape&#39;,&#39;auc&#39;]</span>
<span class="c1">#           }</span>


<span class="c1"># num_boost_round = 10_000</span>
<span class="c1"># n_folds = 5</span>
<span class="c1"># cv_results = lgb.cv(params_small, </span>
<span class="c1">#                     dtrain,</span>
<span class="c1">#                     num_boost_round=num_boost_round,</span>
<span class="c1">#                     nfold = n_folds,</span>
<span class="c1">#                     early_stopping_rounds = 100, </span>
<span class="c1">#                     metrics = &#39;rmse&#39;, </span>
<span class="c1">#                     seed = RANDOM_STATE)</span>


<span class="c1"># ValueError: Supported target types are: (&#39;binary&#39;, &#39;multiclass&#39;). Got &#39;continuous&#39; instead.</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Model-Evaluation-of-lightgbm-using-Shap">Model Evaluation of lightgbm using Shap<a class="anchor-link" href="#Model-Evaluation-of-lightgbm-using-Shap"> </a></h1><p>References:</p>
<ul>
<li><a href="https://www.kaggle.com/cast42/lightgbm-model-explained-by-shap">https://www.kaggle.com/cast42/lightgbm-model-explained-by-shap</a></li>
<li><a href="https://www.kaggle.com/wrosinski/shap-feature-importance-with-feature-engineering">https://www.kaggle.com/wrosinski/shap-feature-importance-with-feature-engineering</a></li>
</ul>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">shap</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">show_method_attributes</span><span class="p">(</span><span class="n">shap</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Object Type: &lt;class &#39;module&#39;&gt;

</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>BruteForceExplainer</td>
      <td>PartitionExplainer</td>
      <td>bar_plot</td>
      <td>embedding_plot</td>
      <td>image_plot</td>
      <td>multioutput_decision_plot</td>
      <td>save_html</td>
    </tr>
    <tr>
      <th>1</th>
      <td>DeepExplainer</td>
      <td>SamplingExplainer</td>
      <td>common</td>
      <td>explainers</td>
      <td>initjs</td>
      <td>other</td>
      <td>summary_plot</td>
    </tr>
    <tr>
      <th>2</th>
      <td>GradientExplainer</td>
      <td>Tree</td>
      <td>datasets</td>
      <td>force_plot</td>
      <td>kmeans</td>
      <td>partial_dependence_plot</td>
      <td>unsupported</td>
    </tr>
    <tr>
      <th>3</th>
      <td>KernelExplainer</td>
      <td>TreeExplainer</td>
      <td>decision_plot</td>
      <td>have_matplotlib</td>
      <td>matplotlib</td>
      <td>plots</td>
      <td>warnings</td>
    </tr>
    <tr>
      <th>4</th>
      <td>LinearExplainer</td>
      <td>approximate_interactions</td>
      <td>dependence_plot</td>
      <td>hclust_ordering</td>
      <td>monitoring_plot</td>
      <td>sample</td>
      <td></td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">time</span> shap_values = shap.TreeExplainer(model_lgb).shap_values(df_Xvalid_scaled)
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 6min 33s, sys: 471 ms, total: 6min 33s
Wall time: 3min 20s
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">shap</span><span class="o">.</span><span class="n">summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">df_Xvalid_scaled</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c10_regression_modelling_boosting_lgb_58_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">shap</span><span class="o">.</span><span class="n">summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">df_Xvalid_scaled</span><span class="p">,</span> <span class="n">plot_type</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c10_regression_modelling_boosting_lgb_59_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">shap</span><span class="o">.</span><span class="n">dependence_plot</span><span class="p">(</span><span class="s2">&quot;sqft_living&quot;</span><span class="p">,</span> <span class="n">shap_values</span><span class="p">,</span> <span class="n">df_Xvalid_scaled</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c10_regression_modelling_boosting_lgb_60_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">shap</span><span class="o">.</span><span class="n">dependence_plot</span><span class="p">(</span><span class="s2">&quot;grade&quot;</span><span class="p">,</span> <span class="n">shap_values</span><span class="p">,</span> <span class="n">df_Xvalid_scaled</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c10_regression_modelling_boosting_lgb_61_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="HPO-(Hyper-Parameter-Optimization)">HPO (Hyper Parameter Optimization)<a class="anchor-link" href="#HPO-(Hyper-Parameter-Optimization)"> </a></h1><p>Parameters:</p>
<ul>
<li>learning_rate: step size shrinkage used to prevent overfitting. Range is [0,1]</li>
<li>max_depth: determines how deeply each tree is allowed to grow during any boosting round.</li>
<li>subsample: percentage of samples used per tree. Low value can lead to underfitting.</li>
<li>colsample_bytree: percentage of features used per tree. High value can lead to overfitting.</li>
<li>n_estimators: number of trees you want to build.</li>
</ul>
<p>Regularization parameters:</p>
<ul>
<li>gamma: controls whether a given node will split based on the expected reduction in loss after the split. A higher value leads to fewer splits. Supported only for tree-based learners.</li>
<li>alpha: L1 regularization on leaf weights. A large value leads to more regularization.</li>
<li>lambda: L2 regularization on leaf weights and is smoother than L1 regularization.</li>
</ul>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">hyperopt</span> <span class="k">import</span> <span class="n">fmin</span><span class="p">,</span> <span class="n">tpe</span><span class="p">,</span> <span class="n">hp</span><span class="p">,</span> <span class="n">STATUS_OK</span><span class="p">,</span> <span class="n">Trials</span>
<span class="kn">from</span> <span class="nn">hyperopt.pyll</span> <span class="k">import</span> <span class="n">scope</span>
<span class="kn">from</span> <span class="nn">hyperopt.pyll.stochastic</span> <span class="k">import</span> <span class="n">sample</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">RandomizedSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">cross_val_score</span>

<span class="k">def</span> <span class="nf">hpo_search</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytest</span><span class="p">,</span>
           <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;grid_search&#39;</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
           <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_squared_error&#39;</span><span class="p">):</span>
    
    <span class="sd">&quot;&quot;&quot;Hyper Parameter Optimazation using Grid Search and Random Search.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - df_results : Pandas Dataframe of results</span>
<span class="sd">    - best_estimator: Best estimator found</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">time_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> 
    
    <span class="k">if</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="s1">&#39;grid_search&#39;</span><span class="p">:</span>
        <span class="n">grid_obj</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">pipe</span><span class="p">,</span>
                                <span class="n">param_grid</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
                                <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
                                <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                                <span class="n">return_train_score</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
                               <span class="p">)</span>
        <span class="n">grid_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,)</span>
    
    <span class="k">elif</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="s1">&#39;random_search&#39;</span><span class="p">:</span>
        <span class="n">grid_obj</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">pipe</span><span class="p">,</span>
                            <span class="n">param_distributions</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
                            <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
                            <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span>
                            <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">return_train_score</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
                            <span class="n">random_state</span><span class="o">=</span><span class="n">RANDOM_STATE</span><span class="p">)</span>
        <span class="n">grid_obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,)</span>
    
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;enter search method&#39;</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="n">best_estimator</span> <span class="o">=</span> <span class="n">grid_obj</span><span class="o">.</span><span class="n">best_estimator_</span>
    <span class="n">cvs</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">best_estimator</span><span class="p">,</span> <span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">)</span>
    
    <span class="n">df_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">grid_obj</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>

    <span class="n">time_taken</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">time_start</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Results</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Time taken: </span><span class="si">{:.0f}</span><span class="s1"> min </span><span class="si">{:.0f}</span><span class="s1"> secs&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="nb">divmod</span><span class="p">(</span><span class="n">time_taken</span><span class="p">,</span><span class="mi">60</span><span class="p">)))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of parameter combinations tested: &quot;</span><span class="p">,</span> <span class="n">df_results</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation Score                 : </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cvs</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train Score Best                       : </span><span class="si">{:.4f}</span><span class="s2"> &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_obj</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Score                             : </span><span class="si">{:.4f}</span><span class="s2"> &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_estimator</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">ytest</span><span class="p">)))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters: &quot;</span><span class="p">,</span> <span class="n">grid_obj</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
   
    <span class="k">return</span> <span class="n">df_results</span><span class="p">,</span> <span class="n">best_estimator</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;clf&#39;</span><span class="p">,</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">RANDOM_STATE</span><span class="p">))</span>
    <span class="p">])</span>

<span class="n">param_gridsearch</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;clf__learning_rate&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="s1">&#39;clf__max_depth&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span>
    <span class="s1">&#39;clf__n_estimators&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span> 
    <span class="s1">&#39;clf__num_leaves&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span>
    <span class="s1">&#39;clf__boosting_type&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;gbdt&#39;</span><span class="p">,</span> <span class="s1">&#39;dart&#39;</span><span class="p">],</span>
    <span class="s1">&#39;clf__colsample_bytree&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="s1">&#39;clf__reg_lambda&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">param_random</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;clf__learning_rate&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">num</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="n">base</span><span class="o">=</span><span class="mi">3</span><span class="p">)),</span>
    <span class="s1">&#39;clf__max_depth&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">)),</span>
    <span class="s1">&#39;clf__n_estimators&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span><span class="mi">50</span><span class="p">)),</span>
    <span class="s1">&#39;clf__num_leaves&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">)),</span>
    <span class="s1">&#39;clf__boosting_type&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;gbdt&#39;</span><span class="p">,</span> <span class="s1">&#39;dart&#39;</span><span class="p">],</span>
    <span class="s1">&#39;clf__colsample_bytree&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">500</span><span class="p">)),</span>
    <span class="s1">&#39;clf__reg_lambda&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">500</span><span class="p">)),</span>
<span class="p">}</span>

<span class="n">param_hyperopt</span><span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span>
    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">scope</span><span class="o">.</span><span class="n">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;max_depth&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="n">scope</span><span class="o">.</span><span class="n">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">50</span><span class="p">)),</span>
    <span class="s1">&#39;num_leaves&#39;</span><span class="p">:</span> <span class="n">scope</span><span class="o">.</span><span class="n">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;num_leaves&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="s1">&#39;boosting_type&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;boosting_type&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;gbdt&#39;</span><span class="p">,</span> <span class="s1">&#39;dart&#39;</span><span class="p">]),</span>
    <span class="s1">&#39;colsample_bytree&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s1">&#39;colsample_by_tree&#39;</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s1">&#39;reg_lambda&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#results_grid, estimator_grid = search(pipe, param_gridsearch,</span>
<span class="c1">#  Xtrain_scaled, ytrain, Xtest_scaled, ytest, &#39;grid_search&#39;)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;clf&#39;</span><span class="p">,</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">RANDOM_STATE</span><span class="p">))</span>
    <span class="p">])</span>

<span class="n">num_eval</span> <span class="o">=</span><span class="mi">75</span>
<span class="n">param_random</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;clf__learning_rate&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">num</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="n">base</span><span class="o">=</span><span class="mi">3</span><span class="p">)),</span>
    <span class="s1">&#39;clf__max_depth&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">)),</span>
    <span class="s1">&#39;clf__n_estimators&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span><span class="mi">50</span><span class="p">)),</span>
    <span class="s1">&#39;clf__num_leaves&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">)),</span>
    <span class="s1">&#39;clf__boosting_type&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;gbdt&#39;</span><span class="p">,</span> <span class="s1">&#39;dart&#39;</span><span class="p">],</span>
    <span class="s1">&#39;clf__colsample_bytree&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">500</span><span class="p">)),</span>
    <span class="s1">&#39;clf__reg_lambda&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">500</span><span class="p">)),</span>
<span class="p">}</span>
<span class="n">results_random</span><span class="p">,</span> <span class="n">estimator_random</span> <span class="o">=</span> <span class="n">hpo_search</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_random</span><span class="p">,</span>
                                          <span class="n">Xtrain_scaled</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span>
                                          <span class="n">Xtest_scaled</span><span class="p">,</span> <span class="n">ytest</span><span class="p">,</span>
                                          <span class="s1">&#39;random_search&#39;</span><span class="p">,</span> <span class="n">num_eval</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>##### Results
Score best parameters:  -0.02755828689069191
Best parameters:  {&#39;clf__reg_lambda&#39;: 0.19839679358717432, &#39;clf__num_leaves&#39;: 37, &#39;clf__n_estimators&#39;: 250, &#39;clf__max_depth&#39;: 6, &#39;clf__learning_rate&#39;: 0.4398821013590871, &#39;clf__colsample_bytree&#39;: 0.8733466933867735, &#39;clf__boosting_type&#39;: &#39;dart&#39;}
Cross-validation Score:  0.9003256840304427
Test Score:  0.9112034357611716
Time elapsed:  287.8319971561432
Parameter combinations evaluated:  75
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="HPO-Using-hyperopt">HPO Using hyperopt<a class="anchor-link" href="#HPO-Using-hyperopt"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">hpo_hyperopt</span><span class="p">(</span><span class="n">param_space</span><span class="p">,</span> <span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytest</span><span class="p">,</span> <span class="n">num_eval</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    
    <span class="n">time_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">objective_function</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMRegressor</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="o">-</span><span class="n">score</span><span class="p">,</span> <span class="s1">&#39;status&#39;</span><span class="p">:</span> <span class="n">STATUS_OK</span><span class="p">}</span>

    <span class="n">trials</span> <span class="o">=</span> <span class="n">Trials</span><span class="p">()</span>
    <span class="n">best_param</span> <span class="o">=</span> <span class="n">fmin</span><span class="p">(</span><span class="n">objective_function</span><span class="p">,</span> 
                      <span class="n">param_space</span><span class="p">,</span> 
                      <span class="n">algo</span><span class="o">=</span><span class="n">tpe</span><span class="o">.</span><span class="n">suggest</span><span class="p">,</span> 
                      <span class="n">max_evals</span><span class="o">=</span><span class="n">num_eval</span><span class="p">,</span> 
                      <span class="n">trials</span><span class="o">=</span><span class="n">trials</span><span class="p">,</span>
                      <span class="n">rstate</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">RANDOM_STATE</span><span class="p">))</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;result&#39;</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">trials</span><span class="o">.</span><span class="n">trials</span><span class="p">]</span>
    
    <span class="n">best_param_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">best_param</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>

    <span class="k">if</span> <span class="n">best_param_values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">boosting_type</span> <span class="o">=</span> <span class="s1">&#39;gbdt&#39;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">boosting_type</span><span class="o">=</span> <span class="s1">&#39;dart&#39;</span>
    
    <span class="n">model_best</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">best_param_values</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                                  <span class="n">num_leaves</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">best_param_values</span><span class="p">[</span><span class="mi">5</span><span class="p">]),</span>
                                  <span class="n">max_depth</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">best_param_values</span><span class="p">[</span><span class="mi">3</span><span class="p">]),</span>
                                  <span class="n">n_estimators</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">best_param_values</span><span class="p">[</span><span class="mi">4</span><span class="p">]),</span>
                                  <span class="n">boosting_type</span><span class="o">=</span><span class="n">boosting_type</span><span class="p">,</span>
                                  <span class="n">colsample_bytree</span><span class="o">=</span><span class="n">best_param_values</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                  <span class="n">reg_lambda</span><span class="o">=</span><span class="n">best_param_values</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span>
                                 <span class="p">)</span>
                                  
    <span class="n">model_best</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>

    <span class="n">time_taken</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">time_start</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Results</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Time taken: </span><span class="si">{:.0f}</span><span class="s1"> min </span><span class="si">{:.0f}</span><span class="s1"> secs&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="nb">divmod</span><span class="p">(</span><span class="n">time_taken</span><span class="p">,</span><span class="mi">60</span><span class="p">)))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of parameter combinations tested: &quot;</span><span class="p">,</span> <span class="n">num_eval</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train Score Best                       : </span><span class="si">{:.4f}</span><span class="s2"> &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">*-</span><span class="mi">1</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Score                             : </span><span class="si">{:.4f}</span><span class="s2"> &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model_best</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">ytest</span><span class="p">)))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters: &quot;</span><span class="p">,</span> <span class="n">best_param</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">trials</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_eval</span> <span class="o">=</span> <span class="mi">75</span> <span class="c1"># keep it same as random search for further plots</span>
<span class="n">param_hyperopt</span><span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span>
    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">scope</span><span class="o">.</span><span class="n">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;max_depth&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="n">scope</span><span class="o">.</span><span class="n">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">50</span><span class="p">)),</span>
    <span class="s1">&#39;num_leaves&#39;</span><span class="p">:</span> <span class="n">scope</span><span class="o">.</span><span class="n">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;num_leaves&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="s1">&#39;boosting_type&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;boosting_type&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;gbdt&#39;</span><span class="p">,</span> <span class="s1">&#39;dart&#39;</span><span class="p">]),</span>
    <span class="s1">&#39;colsample_bytree&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s1">&#39;colsample_by_tree&#39;</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s1">&#39;reg_lambda&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
<span class="p">}</span>


<span class="n">result_trials</span> <span class="o">=</span> <span class="n">hpo_hyperopt</span><span class="p">(</span><span class="n">param_hyperopt</span><span class="p">,</span> <span class="n">Xtrain_scaled</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span>
                                <span class="n">Xtest_scaled</span><span class="p">,</span> <span class="n">ytest</span><span class="p">,</span> <span class="n">num_eval</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>100%|██████████| 75/75 [04:53&lt;00:00,  3.13s/it, best loss: -0.9001741101396777]

Results
==================================================
Time taken: 4 min 55 secs
Number of parameter combinations tested:  75
Train Score Best                       : 0.9002 
Test Score                             : 0.9091 
Best parameters:  {&#39;boosting_type&#39;: 0, &#39;colsample_by_tree&#39;: 0.6924450244000107, &#39;learning_rate&#39;: 0.026476268132746204, &#39;max_depth&#39;: 10.0, &#39;n_estimators&#39;: 400.0, &#39;num_leaves&#39;: 46.0, &#39;reg_lambda&#39;: 0.44732535692405184}
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Plot-top-validation-scores-over-time-for-GridSearch-and-Random-Search">Plot top validation scores over time for GridSearch and Random Search<a class="anchor-link" href="#Plot-top-validation-scores-over-time-for-GridSearch-and-Random-Search"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Retrieve Hyperopt scores</span>
<span class="n">hyperopt_scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">trial</span><span class="p">[</span><span class="s1">&#39;result&#39;</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">*-</span><span class="mi">1</span> <span class="k">for</span> <span class="n">trial</span> <span class="ow">in</span> <span class="n">results_hyperopt</span><span class="o">.</span><span class="n">trials</span><span class="p">]</span>
<span class="n">hyperopt_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="o">.</span><span class="n">accumulate</span><span class="p">(</span><span class="n">hyperopt_scores</span><span class="p">)</span>

<span class="c1"># Retrieve Random Search scores</span>
<span class="n">random_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="o">.</span><span class="n">accumulate</span><span class="p">(</span><span class="n">results_random</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Plot evaluation scores of each method over time</span>

<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_palette</span><span class="p">(</span><span class="s2">&quot;husl&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_eval</span><span class="p">)],</span> <span class="n">y</span><span class="o">=</span><span class="n">random_scores</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_eval</span><span class="p">)],</span> <span class="n">y</span><span class="o">=</span><span class="n">hyperopt_scores</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Finding the optimum&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Cross-Validation Score (accuracy, %)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Random Search&#39;</span><span class="p">,</span> <span class="s1">&#39;Hyperopt&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">setp</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">get_legend</span><span class="p">()</span><span class="o">.</span><span class="n">get_texts</span><span class="p">(),</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;12&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c10_regression_modelling_boosting_lgb_73_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Plot-learning-rate-&amp;-num_leaves-sampling-distribution-vs.-distribution-of-values-sampled-by-Hyperopt">Plot learning rate &amp; num_leaves sampling distribution vs. distribution of values sampled by Hyperopt<a class="anchor-link" href="#Plot-learning-rate-&amp;-num_leaves-sampling-distribution-vs.-distribution-of-values-sampled-by-Hyperopt"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Randomly sample from learning rate and num_leaves distribution</span>

<span class="n">learning_rate_space</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> 
                       <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="p">))}</span>

<span class="n">num_leaves_space</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;num_leaves&#39;</span><span class="p">:</span> 
                    <span class="n">scope</span><span class="o">.</span><span class="n">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;num_leaves&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">1</span><span class="p">))}</span>

<span class="n">learning_rate_dist</span> <span class="o">=</span> <span class="p">[</span><span class="n">sample</span><span class="p">(</span><span class="n">learning_rate_space</span><span class="p">)[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]</span> 
                      <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)]</span>
                
<span class="n">num_leaves_dist</span> <span class="o">=</span> <span class="p">[</span><span class="n">sample</span><span class="p">(</span><span class="n">num_leaves_space</span><span class="p">)[</span><span class="s1">&#39;num_leaves&#39;</span><span class="p">]</span> 
                   <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)]</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Retrieve learning rates and num_leaves&#39; used by Hyperopt</span>

<span class="n">learning_rate_hp</span> <span class="o">=</span> <span class="p">[</span><span class="n">trial</span><span class="p">[</span><span class="s1">&#39;misc&#39;</span><span class="p">][</span><span class="s1">&#39;vals&#39;</span><span class="p">][</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">trial</span> <span class="ow">in</span> <span class="n">results_hyperopt</span><span class="o">.</span><span class="n">trials</span><span class="p">]</span>
<span class="n">num_leaves_hp</span> <span class="o">=</span> <span class="p">[</span><span class="n">trial</span><span class="p">[</span><span class="s1">&#39;misc&#39;</span><span class="p">][</span><span class="s1">&#39;vals&#39;</span><span class="p">][</span><span class="s1">&#39;num_leaves&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">trial</span> <span class="ow">in</span> <span class="n">results_hyperopt</span><span class="o">.</span><span class="n">trials</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Plot learning rate sampling distribution vs. values used by Hyperopt</span>

<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_palette</span><span class="p">(</span><span class="s2">&quot;husl&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">learning_rate_dist</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Sampling Distribution&#39;</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">learning_rate_hp</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Hyperopt&#39;</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Learning Rate&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Learning Rate&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">setp</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">get_legend</span><span class="p">()</span><span class="o">.</span><span class="n">get_texts</span><span class="p">(),</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;12&#39;</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c10_regression_modelling_boosting_lgb_77_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Plot num_leaves sampling distribution vs. values used by Hyperopt</span>

<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_palette</span><span class="p">(</span><span class="s2">&quot;husl&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">num_leaves_dist</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Sampling Distribution&#39;</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">num_leaves_hp</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Hyperopt&#39;</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Number of leaves&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of leaves&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">setp</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">get_legend</span><span class="p">()</span><span class="o">.</span><span class="n">get_texts</span><span class="p">(),</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;12&#39;</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c10_regression_modelling_boosting_lgb_78_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Best-Model-Found">Best Model Found<a class="anchor-link" href="#Best-Model-Found"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># baseline model</span>
<span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">RANDOM_STATE</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>LGBMRegressor(boosting_type=&#39;gbdt&#39;, class_weight=None, colsample_bytree=1.0,
              importance_type=&#39;split&#39;, learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=100, reg_alpha=0.0, reg_lambda=0.0, silent=True,
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># model fit</span>
<span class="n">model_lgb</span> <span class="o">=</span> <span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">RANDOM_STATE</span><span class="p">)</span>
<span class="n">model_lgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain_scaled</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>

<span class="c1"># cross validation score</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">RANDOM_STATE</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model_lgb</span><span class="p">,</span> <span class="n">Xtrain_scaled</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> 
                         <span class="n">scoring</span> <span class="o">=</span> <span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">)</span>
<span class="c1"># sklearn.metrics.SCORERS.keys()</span>
<span class="n">train_neg_mse</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train Negative MSE CV: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_neg_mse</span><span class="p">))</span>

<span class="c1"># save the model</span>
<span class="c1"># joblib.dump(model_lgb, &#39;model_lgb.pkl&#39;)</span>
<span class="c1"># model_lgb = joblib.load(&#39;model_xgb.pkl&#39;)</span>

<span class="c1"># predictions</span>
<span class="n">ypreds_cv</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">model_lgb</span><span class="p">,</span> <span class="n">Xtest_scaled</span><span class="p">,</span> <span class="n">ytest</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">)</span>
<span class="n">ypreds</span> <span class="o">=</span> <span class="n">ypreds_cv</span>

<span class="c1"># rmse</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypreds</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test RMSE: </span><span class="si">{rmse:.4f}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># explained variance score</span>
<span class="n">evs</span> <span class="o">=</span> <span class="n">explained_variance_score</span><span class="p">(</span><span class="n">ypreds</span><span class="p">,</span> <span class="n">ytest</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Explained Variance Score: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span> <span class="n">evs</span><span class="p">))</span>

<span class="c1"># r-squared values</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">ypreds</span><span class="p">)</span>
<span class="n">ar2</span> <span class="o">=</span> <span class="n">adjustedR2</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span> <span class="n">Xtest_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Xtest_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;r_squared : </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;adjustedr2: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ar2</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Train Negative MSE CV: -0.0286
Test RMSE: 0.1738
Explained Variance Score: 0.8776
r_squared : 0.8922
adjustedr2: 0.8918
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># the result of best param</span>
<span class="c1"># clean this result and use it.</span>
<span class="n">best_parameters</span><span class="p">:</span>  <span class="p">{</span><span class="s1">&#39;boosting_type&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># 0 means &#39;gbdt&#39;</span>
                   <span class="s1">&#39;colsample_by_tree&#39;</span><span class="p">:</span> <span class="mf">0.6924450244000107</span><span class="p">,</span> 
                   <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.026476268132746204</span><span class="p">,</span> 
                   <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="mf">10.0</span><span class="p">,</span> 
                   <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mf">400.0</span><span class="p">,</span>  <span class="c1"># make integer</span>
                   <span class="s1">&#39;num_leaves&#39;</span><span class="p">:</span> <span class="mf">46.0</span><span class="p">,</span>  <span class="c1"># make integer</span>
                   <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="mf">0.44732535692405184</span><span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># best params so far</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;boosting_type&#39;</span><span class="p">:</span> <span class="s1">&#39;gbdt&#39;</span><span class="p">,</span> <span class="c1"># 0 means gbdt in this case</span>
               <span class="s1">&#39;colsample_by_tree&#39;</span><span class="p">:</span> <span class="mf">0.692</span><span class="p">,</span>
               <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.026</span><span class="p">,</span>
               <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
               <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">400</span><span class="p">,</span>
               <span class="s1">&#39;num_leaves&#39;</span><span class="p">:</span> <span class="mi">46</span><span class="p">,</span>
               <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="mf">0.447</span><span class="p">}</span>
<span class="c1"># model fit</span>
<span class="n">model_lgb</span> <span class="o">=</span> <span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">RANDOM_STATE</span><span class="p">,</span> <span class="o">**</span><span class="n">best_params</span><span class="p">)</span>
<span class="n">model_lgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain_scaled</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>

<span class="c1"># cross validation score</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">RANDOM_STATE</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model_lgb</span><span class="p">,</span> <span class="n">Xtrain_scaled</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">)</span>
<span class="c1"># sklearn.metrics.SCORERS.keys()</span>
<span class="n">train_neg_mse</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train Negative MSE CV: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_neg_mse</span><span class="p">))</span>

<span class="c1"># save the model</span>
<span class="c1"># joblib.dump(model_lgb, &#39;model_lgb.pkl&#39;)</span>
<span class="c1"># model_lgb = joblib.load(&#39;model_xgb.pkl&#39;)</span>

<span class="c1"># predictions</span>
<span class="n">ypreds_cv</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">model_lgb</span><span class="p">,</span> <span class="n">Xtest_scaled</span><span class="p">,</span> <span class="n">ytest</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">)</span>
<span class="n">ypreds</span> <span class="o">=</span> <span class="n">ypreds_cv</span>

<span class="c1"># rmse</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypreds</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test RMSE: </span><span class="si">{rmse:.4f}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># explained variance score</span>
<span class="n">evs</span> <span class="o">=</span> <span class="n">explained_variance_score</span><span class="p">(</span><span class="n">ypreds</span><span class="p">,</span> <span class="n">ytest</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Explained Variance Score: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span> <span class="n">evs</span><span class="p">))</span>

<span class="c1"># r-squared values</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">ypreds</span><span class="p">)</span>
<span class="n">ar2</span> <span class="o">=</span> <span class="n">adjustedR2</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span> <span class="n">Xtest_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Xtest_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;r_squared : </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;adjustedr2: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ar2</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Train Negative MSE CV: -0.0280
Test RMSE: 0.1735
Explained Variance Score: 0.8789
r_squared : 0.8927
adjustedr2: 0.8922
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># adjusted r-squared increased little bit.</span>
<span class="c1"># default: 0.8914 (100 esitmators)</span>
<span class="c1"># to     : 0.8922 (400 estimators)</span>

<span class="c1"># this is still less than xgboost result with 400 estimators.</span>
<span class="c1"># where I got 0.90</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># n_estimators found in max, i need to increase this</span>
<span class="c1"># also take more evals.</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_eval</span> <span class="o">=</span> <span class="mi">500</span> <span class="c1"># now we can increate this for hpo</span>
<span class="n">param_hyperopt</span><span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span>
    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">scope</span><span class="o">.</span><span class="n">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;max_depth&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="n">scope</span><span class="o">.</span><span class="n">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">,</span> <span class="mi">400</span><span class="p">,</span> <span class="mi">900</span><span class="p">,</span> <span class="mi">50</span><span class="p">)),</span>
    <span class="s1">&#39;num_leaves&#39;</span><span class="p">:</span> <span class="n">scope</span><span class="o">.</span><span class="n">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s1">&#39;num_leaves&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="s1">&#39;boosting_type&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="s1">&#39;boosting_type&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;gbdt&#39;</span><span class="p">,</span> <span class="s1">&#39;dart&#39;</span><span class="p">]),</span>
    <span class="s1">&#39;colsample_bytree&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s1">&#39;colsample_by_tree&#39;</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s1">&#39;reg_lambda&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
<span class="p">}</span>


<span class="n">result_trials</span> <span class="o">=</span> <span class="n">hpo_hyperopt</span><span class="p">(</span><span class="n">param_hyperopt</span><span class="p">,</span> <span class="n">Xtrain_scaled</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span>
                                <span class="n">Xtest_scaled</span><span class="p">,</span> <span class="n">ytest</span><span class="p">,</span> <span class="n">num_eval</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>100%|██████████| 500/500 [1:19:44&lt;00:00,  7.30s/it, best loss: -0.9011140102450362]

Results
==================================================
Time taken: 79 min 47 secs
Number of parameter combinations tested:  500
Train Score Best                       : 0.9011 
Test Score                             : 0.9104 
Best parameters:  {&#39;boosting_type&#39;: 0, &#39;colsample_by_tree&#39;: 0.6721100286327935, &#39;learning_rate&#39;: 0.02169457166783478, &#39;max_depth&#39;: 15.0, &#39;n_estimators&#39;: 750.0, &#39;num_leaves&#39;: 38.0, &#39;reg_lambda&#39;: 0.6041667606825525}
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># best params so far</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;boosting_type&#39;</span><span class="p">:</span> <span class="s1">&#39;gbdt&#39;</span><span class="p">,</span> <span class="c1"># 0 means gbdt in this case</span>
               <span class="s1">&#39;colsample_by_tree&#39;</span><span class="p">:</span> <span class="mf">0.67211</span><span class="p">,</span>
               <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.02169</span><span class="p">,</span>
               <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span>
               <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">750</span><span class="p">,</span>
               <span class="s1">&#39;num_leaves&#39;</span><span class="p">:</span> <span class="mi">38</span><span class="p">,</span>
               <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="mf">0.604</span><span class="p">}</span>
<span class="c1"># model fit</span>
<span class="n">model_lgb</span> <span class="o">=</span> <span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">RANDOM_STATE</span><span class="p">,</span> <span class="o">**</span><span class="n">best_params</span><span class="p">)</span>
<span class="n">model_lgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain_scaled</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>

<span class="c1"># cross validation score</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">RANDOM_STATE</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model_lgb</span><span class="p">,</span> <span class="n">Xtrain_scaled</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">)</span>
<span class="c1"># sklearn.metrics.SCORERS.keys()</span>
<span class="n">train_neg_mse</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train Negative MSE CV: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_neg_mse</span><span class="p">))</span>

<span class="c1"># save the model</span>
<span class="c1"># joblib.dump(model_lgb, &#39;model_lgb.pkl&#39;)</span>
<span class="c1"># model_lgb = joblib.load(&#39;model_xgb.pkl&#39;)</span>

<span class="c1"># predictions</span>
<span class="n">ypreds_cv</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">model_lgb</span><span class="p">,</span> <span class="n">Xtest_scaled</span><span class="p">,</span> <span class="n">ytest</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">)</span>
<span class="n">ypreds</span> <span class="o">=</span> <span class="n">ypreds_cv</span>

<span class="c1"># rmse</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypreds</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test RMSE: </span><span class="si">{rmse:.4f}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># explained variance score</span>
<span class="n">evs</span> <span class="o">=</span> <span class="n">explained_variance_score</span><span class="p">(</span><span class="n">ypreds</span><span class="p">,</span> <span class="n">ytest</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Explained Variance Score: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span> <span class="n">evs</span><span class="p">))</span>

<span class="c1"># r-squared values</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">ypreds</span><span class="p">)</span>
<span class="n">ar2</span> <span class="o">=</span> <span class="n">adjustedR2</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span> <span class="n">Xtest_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Xtest_scaled</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;r_squared : </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;adjustedr2: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ar2</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Train Negative MSE CV: -0.0279
Test RMSE: 0.1734
Explained Variance Score: 0.8794
r_squared : 0.8928
adjustedr2: 0.8923
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># adjustedr2: 0.8922</span>
<span class="c1"># adjustedr2: 0.8923</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

 


    </main>
    