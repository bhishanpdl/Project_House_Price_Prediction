---
redirect_from:
  - "c02-regression-modelling-linear-ols-statsmodels"
interact_link: content/c02_regression_modelling_linear_ols_statsmodels.ipynb
kernel_name: datasc
kernel_path: content
has_widgets: false
title: |-
  C02 Regression Modelling Linear Ols Statsmodels
pagenum: 9
prev_page:
  url: /c03_regression_modelling_sklearn_methods.html
next_page:
  url: /c07_regression_modelling_select_kbest.html
suffix: .ipynb
search: toc span data class regression id href modified item linear lilispana numnbspnbsp using num nbspnbsp simple model confidence interval price description test split statsmodels questions score coefficient determination r training predictions after adding bias term plots fit line regplot transformation ols formula between features itemlispana imports load train modelling statistics residual best seaborn li ul assumptions log multiple polynomial relationship predictor response associated div spanul spanmodel house includes increase sqftliving positive predicted htable contentsspan tocskip h tocul spandata spanimports spanload spantrain spansimple spanmodelling spanstatistics spanresidual spanbest spanseaborn spanassumptions spanlog spanmultiple spanpolynomial dataset contains sale prices king county seattle homes sold

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">C02 Regression Modelling Linear Ols Statsmodels</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><h1>Table of Contents<span class="tocSkip"></span></h1></p>
<div class="toc"><ul class="toc-item"><li><span><a href="#Data-Description" data-toc-modified-id="Data-Description-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>Data Description</a></span></li><li><span><a href="#Imports" data-toc-modified-id="Imports-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href="#Load-the-data" data-toc-modified-id="Load-the-data-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>Load the data</a></span></li><li><span><a href="#Train-test-split" data-toc-modified-id="Train-test-split-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>Train test split</a></span></li><li><span><a href="#Simple-Linear-Regression" data-toc-modified-id="Simple-Linear-Regression-5"><span class="toc-item-num">5&nbsp;&nbsp;</span>Simple Linear Regression</a></span><ul class="toc-item"><li><span><a href="#Modelling-Simple-Linear-Regression-Using-statsmodels" data-toc-modified-id="Modelling-Simple-Linear-Regression-Using-statsmodels-5.1"><span class="toc-item-num">5.1&nbsp;&nbsp;</span>Modelling Simple Linear Regression Using statsmodels</a></span></li><li><span><a href="#Statistics-Questions" data-toc-modified-id="Statistics-Questions-5.2"><span class="toc-item-num">5.2&nbsp;&nbsp;</span>Statistics Questions</a></span></li><li><span><a href="#Model-score-(coefficient-of-determination-R^2)-for-training" data-toc-modified-id="Model-score-(coefficient-of-determination-R^2)-for-training-5.3"><span class="toc-item-num">5.3&nbsp;&nbsp;</span>Model score (coefficient of determination R^2) for training</a></span></li><li><span><a href="#Model-Predictions-after-adding-bias-term" data-toc-modified-id="Model-Predictions-after-adding-bias-term-5.4"><span class="toc-item-num">5.4&nbsp;&nbsp;</span>Model Predictions after adding bias term</a></span></li><li><span><a href="#Residual-Plots" data-toc-modified-id="Residual-Plots-5.5"><span class="toc-item-num">5.5&nbsp;&nbsp;</span>Residual Plots</a></span></li><li><span><a href="#Best-fit-line-with-confidence-interval" data-toc-modified-id="Best-fit-line-with-confidence-interval-5.6"><span class="toc-item-num">5.6&nbsp;&nbsp;</span>Best fit line with confidence interval</a></span></li><li><span><a href="#Seaborn-regplot" data-toc-modified-id="Seaborn-regplot-5.7"><span class="toc-item-num">5.7&nbsp;&nbsp;</span>Seaborn regplot</a></span></li></ul></li><li><span><a href="#Assumptions-of-Linear-Regression" data-toc-modified-id="Assumptions-of-Linear-Regression-6"><span class="toc-item-num">6&nbsp;&nbsp;</span>Assumptions of Linear Regression</a></span><ul class="toc-item"><li><span><a href="#log-transformation-using-ols-formula" data-toc-modified-id="log-transformation-using-ols-formula-6.1"><span class="toc-item-num">6.1&nbsp;&nbsp;</span>log transformation using ols formula</a></span></li></ul></li><li><span><a href="#Multiple-Linear-Regression" data-toc-modified-id="Multiple-Linear-Regression-7"><span class="toc-item-num">7&nbsp;&nbsp;</span>Multiple Linear Regression</a></span></li><li><span><a href="#Polynomial-Regression" data-toc-modified-id="Polynomial-Regression-8"><span class="toc-item-num">8&nbsp;&nbsp;</span>Polynomial Regression</a></span></li></ul></div>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Data-Description">Data Description<a class="anchor-link" href="#Data-Description"> </a></h1><p>This dataset contains house sale prices for King County,
which includes Seattle.
It includes homes sold between May 2014 and May 2015.</p>
<ul>
<li>Dependent features: 1 (price)</li>
<li>Features : 19 home features</li>
<li>Id:  1 house ID</li>
</ul>
<p>Task: Try to estimate the price based on given features.
<img src="../data/raw/data_description.png" alt=""></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Imports">Imports<a class="anchor-link" href="#Imports"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># my custom module</span>
<span class="kn">import</span> <span class="nn">bhishan</span>
<span class="kn">import</span> <span class="nn">src</span>

<span class="kn">from</span> <span class="nn">bhishan.util_statsmodels</span> <span class="k">import</span> <span class="n">print_statsmodels_summary</span>
<span class="kn">from</span> <span class="nn">bhishan.util_statsmodels</span> <span class="k">import</span> <span class="n">regression_residual_plots</span>
<span class="kn">from</span> <span class="nn">bhishan.util_statsmodels</span> <span class="k">import</span> <span class="n">lm_plot</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">color_codes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># random state</span>
<span class="n">random_state</span><span class="o">=</span><span class="mi">100</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span> <span class="c1"># we need this in each cell</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_state</span><span class="o">=</span><span class="n">random_state</span>

<span class="c1"># Jupyter notebook settings for pandas</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="c1">#pd.set_option(&#39;display.float_format&#39;, &#39;{:,.2g}&#39;.format) # numbers sep by comma</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span> <span class="c1"># None for all the rows</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_colwidth&#39;</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">IPython</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="k">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span><span class="p">,</span> <span class="n">Image</span>

<span class="nb">print</span><span class="p">([(</span><span class="n">x</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="n">pd</span><span class="p">,</span><span class="n">np</span><span class="p">,</span><span class="n">sns</span><span class="p">,</span><span class="n">matplotlib</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[(&#39;pandas&#39;, &#39;0.25.0&#39;), (&#39;numpy&#39;, &#39;1.16.4&#39;), (&#39;seaborn&#39;, &#39;0.9.0&#39;), (&#39;matplotlib&#39;, &#39;3.1.1&#39;)]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">scipy</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># _, ci_low, ci_high = wls_prediction_std(results)</span>
<span class="kn">from</span> <span class="nn">statsmodels.sandbox.regression.predstd</span> <span class="k">import</span> <span class="n">wls_prediction_std</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">linear_model</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="nx">javascript</span>
<span class="nx">IPython</span><span class="p">.</span><span class="nx">OutputArea</span><span class="p">.</span><span class="nx">auto_scroll_threshold</span> <span class="o">=</span> <span class="mi">9999</span><span class="p">;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">




<div id="693fa84f-c713-4c73-a121-07640d985716"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#693fa84f-c713-4c73-a121-07640d985716');
IPython.OutputArea.auto_scroll_threshold = 9999;
</script>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">show_method_attributes</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Show all the attributes of a given method.</span>
<span class="sd">    Example:</span>
<span class="sd">    ========</span>
<span class="sd">    show_method_attributes(list)</span>
<span class="sd">     &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">I</span> <span class="k">for</span> <span class="n">I</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">method</span><span class="p">)</span> <span class="k">if</span> <span class="n">I</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">islower</span><span class="p">()]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">I</span> <span class="k">for</span> <span class="n">I</span> <span class="ow">in</span> <span class="n">x</span> <span class="k">if</span> <span class="n">I</span> <span class="ow">not</span> <span class="ow">in</span> <span class="s1">&#39;os np pd sys time psycopg2&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>

    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">ncols</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Load-the-data">Load the data<a class="anchor-link" href="#Load-the-data"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/raw/kc_house_data.csv&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(21613, 21)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>date</th>
      <th>price</th>
      <th>bedrooms</th>
      <th>bathrooms</th>
      <th>sqft_living</th>
      <th>sqft_lot</th>
      <th>floors</th>
      <th>waterfront</th>
      <th>view</th>
      <th>condition</th>
      <th>grade</th>
      <th>sqft_above</th>
      <th>sqft_basement</th>
      <th>yr_built</th>
      <th>yr_renovated</th>
      <th>zipcode</th>
      <th>lat</th>
      <th>long</th>
      <th>sqft_living15</th>
      <th>sqft_lot15</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7129300520</td>
      <td>20141013T000000</td>
      <td>221900.0</td>
      <td>3</td>
      <td>1.00</td>
      <td>1180</td>
      <td>5650</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1180</td>
      <td>0</td>
      <td>1955</td>
      <td>0</td>
      <td>98178</td>
      <td>47.5112</td>
      <td>-122.257</td>
      <td>1340</td>
      <td>5650</td>
    </tr>
    <tr>
      <th>1</th>
      <td>6414100192</td>
      <td>20141209T000000</td>
      <td>538000.0</td>
      <td>3</td>
      <td>2.25</td>
      <td>2570</td>
      <td>7242</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>2170</td>
      <td>400</td>
      <td>1951</td>
      <td>1991</td>
      <td>98125</td>
      <td>47.7210</td>
      <td>-122.319</td>
      <td>1690</td>
      <td>7639</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5631500400</td>
      <td>20150225T000000</td>
      <td>180000.0</td>
      <td>2</td>
      <td>1.00</td>
      <td>770</td>
      <td>10000</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>6</td>
      <td>770</td>
      <td>0</td>
      <td>1933</td>
      <td>0</td>
      <td>98028</td>
      <td>47.7379</td>
      <td>-122.233</td>
      <td>2720</td>
      <td>8062</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2487200875</td>
      <td>20141209T000000</td>
      <td>604000.0</td>
      <td>4</td>
      <td>3.00</td>
      <td>1960</td>
      <td>5000</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>5</td>
      <td>7</td>
      <td>1050</td>
      <td>910</td>
      <td>1965</td>
      <td>0</td>
      <td>98136</td>
      <td>47.5208</td>
      <td>-122.393</td>
      <td>1360</td>
      <td>5000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1954400510</td>
      <td>20150218T000000</td>
      <td>510000.0</td>
      <td>3</td>
      <td>2.00</td>
      <td>1680</td>
      <td>8080</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>8</td>
      <td>1680</td>
      <td>0</td>
      <td>1987</td>
      <td>0</td>
      <td>98074</td>
      <td>47.6168</td>
      <td>-122.045</td>
      <td>1800</td>
      <td>7503</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Train-test-split">Train test split<a class="anchor-link" href="#Train-test-split"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">df_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">df_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">df_train</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(21613, 21) (17290, 21) (4323, 21)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>date</th>
      <th>price</th>
      <th>bedrooms</th>
      <th>bathrooms</th>
      <th>sqft_living</th>
      <th>sqft_lot</th>
      <th>floors</th>
      <th>waterfront</th>
      <th>view</th>
      <th>condition</th>
      <th>grade</th>
      <th>sqft_above</th>
      <th>sqft_basement</th>
      <th>yr_built</th>
      <th>yr_renovated</th>
      <th>zipcode</th>
      <th>lat</th>
      <th>long</th>
      <th>sqft_living15</th>
      <th>sqft_lot15</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>16000</th>
      <td>2561340020</td>
      <td>20140804T000000</td>
      <td>325000.0</td>
      <td>3</td>
      <td>1.75</td>
      <td>1780</td>
      <td>11096</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1210</td>
      <td>570</td>
      <td>1979</td>
      <td>0</td>
      <td>98074</td>
      <td>47.6170</td>
      <td>-122.051</td>
      <td>1780</td>
      <td>10640</td>
    </tr>
    <tr>
      <th>11286</th>
      <td>8598200070</td>
      <td>20141208T000000</td>
      <td>278000.0</td>
      <td>2</td>
      <td>2.50</td>
      <td>1420</td>
      <td>2229</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1420</td>
      <td>0</td>
      <td>2004</td>
      <td>0</td>
      <td>98059</td>
      <td>47.4871</td>
      <td>-122.165</td>
      <td>1500</td>
      <td>2230</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Simple-Linear-Regression">Simple Linear Regression<a class="anchor-link" href="#Simple-Linear-Regression"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Modelling-Simple-Linear-Regression-Using-statsmodels">Modelling Simple Linear Regression Using statsmodels<a class="anchor-link" href="#Modelling-Simple-Linear-Regression-Using-statsmodels"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># using sm</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sqft_living&#39;</span><span class="p">]</span>
<span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span>

<span class="n">df_Xtrain</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">df_ytrain</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>

<span class="n">df_Xtest</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">df_ytest</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>

<span class="n">df_X1train</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">df_Xtrain</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">df_ytrain</span><span class="p">,</span> <span class="n">df_X1train</span> <span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="n">summary</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="n">print_statsmodels_summary</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/poudel/miniconda3/envs/dataSc/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.
  return ptp(axis=axis, out=out, **kwargs)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.487</td>  
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th style="background-color:#aec7e8;">  Adj. R-squared:    </th>  <td>   0.487</td>  
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th style="background-color:#c7e9c0;">  F-statistic:       </th>  <td>1.642e+04</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Fri, 18 Oct 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   
</tr>
<tr>
  <th>Time:</th>                 <td>21:22:01</td>     <th>  Log-Likelihood:    </th> <td>-2.4030e+05</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td> 17290</td>      <th style="background-color:#bcbddc;">  AIC:               </th>  <td>4.806e+05</td> 
</tr>
<tr>
  <th>Df Residuals:</th>          <td> 17288</td>      <th style="background-color:#ffe699;">  BIC:               </th>  <td>4.806e+05</td> 
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>     
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     
</tr>
</table>
<table class="simpletable">
<tr>
       <td></td>          <th style="background-color:#808080;">coef</th>     <th style="background-color:#ccccff;">std err</th>      <th>t</th>      <th style="background-color:#ffd9b3;">P>|t|</th>  <th style="background-color:#ff9896;">[0.025</th>    <th style="background-color:#ff9896;">0.975]</th>  
</tr>
<tr>
  <th>const</th>       <td>-4.263e+04</td> <td> 4963.377</td> <td>   -8.589</td> <td> 0.000</td> <td>-5.24e+04</td> <td>-3.29e+04</td>
</tr>
<tr>
  <th>sqft_living</th> <td>  280.6854</td> <td>    2.190</td> <td>  128.149</td> <td> 0.000</td> <td>  276.392</td> <td>  284.979</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>11909.901</td> <th>  Durbin-Watson:     </th>  <td>   2.018</td> 
</tr>
<tr>
  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>419310.893</td>
</tr>
<tr>
  <th>Skew:</th>           <td> 2.854</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> 
</tr>
<tr>
  <th>Kurtosis:</th>       <td>26.441</td>   <th>  Cond. No.          </th>  <td>5.62e+03</td> 
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.62e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># using smf</span>
<span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;price ~ sqft_living&#39;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_Xtrain</span><span class="p">,</span><span class="n">df_ytrain</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="n">summary</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">show_method_attributes</span><span class="p">(</span><span class="n">results</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>aic</td>
      <td>conf_int_el</td>
      <td>df_resid</td>
      <td>get_influence</td>
      <td>mse_resid</td>
      <td>resid</td>
      <td>t_test</td>
    </tr>
    <tr>
      <th>1</th>
      <td>bic</td>
      <td>cov_HC0</td>
      <td>diagn</td>
      <td>get_prediction</td>
      <td>mse_total</td>
      <td>resid_pearson</td>
      <td>t_test_pairwise</td>
    </tr>
    <tr>
      <th>2</th>
      <td>bse</td>
      <td>cov_HC1</td>
      <td>eigenvals</td>
      <td>get_robustcov_results</td>
      <td>nobs</td>
      <td>rsquared</td>
      <td>tvalues</td>
    </tr>
    <tr>
      <th>3</th>
      <td>centered_tss</td>
      <td>cov_HC2</td>
      <td>el_test</td>
      <td>initialize</td>
      <td>normalized_cov_params</td>
      <td>rsquared_adj</td>
      <td>uncentered_tss</td>
    </tr>
    <tr>
      <th>4</th>
      <td>compare_f_test</td>
      <td>cov_HC3</td>
      <td>ess</td>
      <td>k_constant</td>
      <td>outlier_test</td>
      <td>save</td>
      <td>use_t</td>
    </tr>
    <tr>
      <th>5</th>
      <td>compare_lm_test</td>
      <td>cov_kwds</td>
      <td>f_pvalue</td>
      <td>llf</td>
      <td>params</td>
      <td>scale</td>
      <td>wald_test</td>
    </tr>
    <tr>
      <th>6</th>
      <td>compare_lr_test</td>
      <td>cov_params</td>
      <td>f_test</td>
      <td>load</td>
      <td>predict</td>
      <td>ssr</td>
      <td>wald_test_terms</td>
    </tr>
    <tr>
      <th>7</th>
      <td>condition_number</td>
      <td>cov_type</td>
      <td>fittedvalues</td>
      <td>model</td>
      <td>pvalues</td>
      <td>summary</td>
      <td>wresid</td>
    </tr>
    <tr>
      <th>8</th>
      <td>conf_int</td>
      <td>df_model</td>
      <td>fvalue</td>
      <td>mse_model</td>
      <td>remove_data</td>
      <td>summary2</td>
      <td></td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.487</td>  
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.487</td>  
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.642e+04</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Fri, 18 Oct 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   
</tr>
<tr>
  <th>Time:</th>                 <td>21:22:02</td>     <th>  Log-Likelihood:    </th> <td>-2.4030e+05</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td> 17290</td>      <th>  AIC:               </th>  <td>4.806e+05</td> 
</tr>
<tr>
  <th>Df Residuals:</th>          <td> 17288</td>      <th>  BIC:               </th>  <td>4.806e+05</td> 
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>     
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     
</tr>
</table>
<table class="simpletable">
<tr>
       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>   <td>-4.263e+04</td> <td> 4963.377</td> <td>   -8.589</td> <td> 0.000</td> <td>-5.24e+04</td> <td>-3.29e+04</td>
</tr>
<tr>
  <th>sqft_living</th> <td>  280.6854</td> <td>    2.190</td> <td>  128.149</td> <td> 0.000</td> <td>  276.392</td> <td>  284.979</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>11909.901</td> <th>  Durbin-Watson:     </th>  <td>   2.018</td> 
</tr>
<tr>
  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>419310.893</td>
</tr>
<tr>
  <th>Skew:</th>           <td> 2.854</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> 
</tr>
<tr>
  <th>Kurtosis:</th>       <td>26.441</td>   <th>  Cond. No.          </th>  <td>5.62e+03</td> 
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.62e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Statistics-Questions">Statistics Questions<a class="anchor-link" href="#Statistics-Questions"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>i. Is there a relationship between the predictor and the response?</li>
</ul>
<blockquote><p>Yes, the low P-value associated with the t-statistic for feature suggests so.</p>
</blockquote>
<ul>
<li>ii. How strong is the relationship between the predictor and the response?</li>
</ul>
<blockquote><p>For a unit increase in sqft_living, our model predicts price will
  increase by 280.6854</p>
</blockquote>
<ul>
<li>iii. Is the relationship between the predictor and the response positive or negative?</li>
</ul>
<blockquote><p>Positive</p>
</blockquote>
<ul>
<li>iv. What is the predicted price associated with a sqft_living of 2000? What are the associated 95 % confidence and prediction intervals?</li>
</ul>
<blockquote><p>predicted price is <code>518741.86</code> and confidence interval is <code>[500426.67775749206, 537057.0363632903]</code></p>
</blockquote>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">params</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Intercept     -42628.976515
sqft_living      280.685417
dtype: float64</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">value</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">ans</span> <span class="o">=</span> <span class="o">-</span><span class="mf">42628.976515</span> <span class="o">+</span> <span class="mf">280.685417</span> <span class="o">*</span> <span class="n">value</span>
<span class="nb">round</span><span class="p">(</span><span class="n">ans</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>518741.86</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span><span class="s1">&#39;sqft_living&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0    1180
1    2570
2     770
Name: sqft_living, dtype: int64</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot; y = </span><span class="si">{:.2f}</span><span class="s2"> x + (</span><span class="si">{:.2f}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">values</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">text</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39; y = 280.69 x + (-42628.98)&#39;</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">value</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">X1_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">value</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">X1_test</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2,)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span><span class="n">X1</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">params</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X1</span>

<span class="k">def</span> <span class="nf">get_confidence_interval</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">results</span><span class="p">):</span>
    <span class="n">ci_min</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">conf_int</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ci_max</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">conf_int</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">confidence_interval</span> <span class="o">=</span> <span class="p">[</span><span class="n">predict</span><span class="p">(</span><span class="n">ci_min</span><span class="p">,</span> <span class="n">X1</span><span class="p">),</span> <span class="n">predict</span><span class="p">(</span><span class="n">ci_max</span><span class="p">,</span> <span class="n">X1</span><span class="p">)]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">confidence_interval</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;price ~ sqft_living&#39;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_Xtrain</span><span class="p">,</span><span class="n">df_ytrain</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="n">get_confidence_interval</span><span class="p">(</span><span class="n">X1_test</span><span class="p">,</span><span class="n">results</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[-104715118.95658985, -65800225.73295514]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-score-(coefficient-of-determination-R^2)-for-training">Model score (coefficient of determination R^2) for training<a class="anchor-link" href="#Model-score-(coefficient-of-determination-R^2)-for-training"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">rsquared</span><span class="p">,</span> <span class="n">results</span><span class="o">.</span><span class="n">rsquared_adj</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(0.4871565982411399, 0.48712693353719727)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-Predictions-after-adding-bias-term">Model Predictions after adding bias term<a class="anchor-link" href="#Model-Predictions-after-adding-bias-term"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_Xtest</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(4323, 1)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_X1test</span> <span class="o">=</span> <span class="n">df_Xtest</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df_X1test</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sqft_living</th>
      <th>const</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>19836</th>
      <td>2437</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10442</th>
      <td>1560</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_ypreds</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df_X1test</span><span class="p">)</span>
<span class="n">df_ypreds</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">df_ytest</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((4323,), (4323, 1))</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_ypreds</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>19836    641401.384197
10442    395240.273674
dtype: float64</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_ytrain</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">df_ytest</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((17290, 1), (4323, 1))</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_ytest</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>19836</th>
      <td>285000.0</td>
    </tr>
    <tr>
      <th>10442</th>
      <td>239950.0</td>
    </tr>
    <tr>
      <th>20548</th>
      <td>460000.0</td>
    </tr>
    <tr>
      <th>11014</th>
      <td>397500.0</td>
    </tr>
    <tr>
      <th>4138</th>
      <td>545000.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_comparison</span> <span class="o">=</span> <span class="n">df_ytest</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df_comparison</span><span class="p">[</span><span class="s1">&#39;ypred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_ypreds</span>
<span class="n">df_comparison</span><span class="p">[</span><span class="s1">&#39;error&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_comparison</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">df_comparison</span><span class="p">[</span><span class="s1">&#39;ypred&#39;</span><span class="p">]</span>
<span class="n">df_comparison</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>ypred</th>
      <th>error</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>19836</th>
      <td>285000.0</td>
      <td>641401.384197</td>
      <td>-356401.384197</td>
    </tr>
    <tr>
      <th>10442</th>
      <td>239950.0</td>
      <td>395240.273674</td>
      <td>-155290.273674</td>
    </tr>
    <tr>
      <th>20548</th>
      <td>460000.0</td>
      <td>628209.169608</td>
      <td>-168209.169608</td>
    </tr>
    <tr>
      <th>11014</th>
      <td>397500.0</td>
      <td>372785.440331</td>
      <td>24714.559669</td>
    </tr>
    <tr>
      <th>4138</th>
      <td>545000.0</td>
      <td>485059.607046</td>
      <td>59940.392954</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mse</span> <span class="o">=</span> <span class="n">df_comparison</span><span class="p">[</span><span class="s1">&#39;error&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">mse</span> <span class="c1"># this is too high.</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>65286065304.1562</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df_comparison</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">df_comparison</span><span class="p">[</span><span class="s1">&#39;ypred&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">7_000_000</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">7_000_000</span><span class="p">],</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&lt;matplotlib.lines.Line2D at 0x1180a9630&gt;]</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c02_regression_modelling_linear_ols_statsmodels_42_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">bhishan.util_statsmodels</span> <span class="k">import</span> <span class="n">lm_plot</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_ypreds_train</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df_X1train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lm_plot</span><span class="p">(</span><span class="n">df_X1train</span><span class="p">,</span> <span class="n">df_ytrain</span><span class="p">,</span> <span class="n">df_ypreds_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
    1. Externally Studentised Residual Plot (Outliers Test):
    - The horizontal red dashed lines are studentised t values t = ± 3
    - The points outside t = ± 3 may be considered outliers.
    - If we see U-shaped fitted solid blue line, our data is non-linear.
      We might need to transoform features or include polynomial features.

    2. Normal Q-Q Plot (Test of Normality)
    - If fitted points align with 45 degree line,
      the assumption of normality is likey to hold true.

    3. Scale-Location Plot (Test of Constant Variance, homoskedasticity)
    - Small residuals on y-axis is better.
    - If we see conical shape, data is heteroskedastic.
    - If data points are clustered at left or right, we observe heteroskedasticity.
    - If we see few outliers with high y-values,
       we have high variance residual outliers.

    4. Residuals vs Leverage Plot (Outliers Test)
    - Studentised residual larger than 3 are potential outliers.
    - High leverage points are potential outliers.
    
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c02_regression_modelling_linear_ols_statsmodels_45_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">bhishan.util_statsmodels</span> <span class="k">import</span> <span class="n">regression_residual_plots</span>

<span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;price ~ sqft_living&#39;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df_train</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="n">regression_residual_plots</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">dependent_var</span><span class="o">=</span><span class="s2">&quot;price&quot;</span><span class="p">,</span>
                          <span class="n">data</span><span class="o">=</span><span class="n">df_train</span><span class="p">[[</span><span class="s1">&#39;sqft_living&#39;</span><span class="p">,</span><span class="s1">&#39;price&#39;</span><span class="p">]],</span>
                          <span class="n">annotate_outliers</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c02_regression_modelling_linear_ols_statsmodels_46_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Residual-Plots">Residual Plots<a class="anchor-link" href="#Residual-Plots"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">feature</span> <span class="o">=</span> <span class="s1">&#39;sqft_living&#39;</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">graphics</span><span class="o">.</span><span class="n">plot_regress_exog</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">feature</span><span class="p">,</span> <span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c02_regression_modelling_linear_ols_statsmodels_48_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Best-fit-line-with-confidence-interval">Best fit line with confidence interval<a class="anchor-link" href="#Best-fit-line-with-confidence-interval"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">statsmodels.sandbox.regression.predstd</span> <span class="k">import</span> <span class="n">wls_prediction_std</span>

<span class="c1"># data</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">df_Xtrain</span><span class="p">[[</span><span class="s1">&#39;sqft_living&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_ytrain</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">best_fit</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">fittedvalues</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>


<span class="c1"># figure</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>

<span class="c1"># text</span>
<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot; y = </span><span class="si">{:.2f}</span><span class="s2"> x + (</span><span class="si">{:.2f}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">values</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">7000_000</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>


<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">best_fit</span><span class="p">,</span> <span class="s1">&#39;g--.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;OLS&quot;</span><span class="p">)</span>

<span class="c1"># confidence intervals</span>
<span class="n">_</span><span class="p">,</span> <span class="n">ci_low</span><span class="p">,</span> <span class="n">ci_high</span> <span class="o">=</span> <span class="n">wls_prediction_std</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ci_high</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ci_low</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">)</span>

<span class="c1"># plot legend</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c02_regression_modelling_linear_ols_statsmodels_50_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Seaborn-regplot">Seaborn regplot<a class="anchor-link" href="#Seaborn-regplot"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_Xtrain</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">df_ytrain</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((17290, 1), (17290, 1))</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sns_regression_plot</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;sqft_living&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;price&#39;</span><span class="p">,</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">Xtrain</span><span class="p">,</span><span class="n">ytrain</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                    <span class="n">line_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;color&#39;</span><span class="p">:</span> <span class="s1">&#39;g&#39;</span><span class="p">})</span>
    <span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">r_value</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">std_err</span> <span class="o">=</span> \
    <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">get_lines</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_xdata</span><span class="p">(),</span>
                           <span class="n">y</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">get_lines</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_ydata</span><span class="p">())</span>

    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;y = </span><span class="si">{:.2f}</span><span class="s1"> x + (</span><span class="si">{:.2f}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">7000_000</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Assumptions-of-Linear-Regression">Assumptions of Linear Regression<a class="anchor-link" href="#Assumptions-of-Linear-Regression"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">bhishan.util_statsmodels</span> <span class="k">import</span> <span class="n">regression_residual_plots</span>

<span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;price ~ sqft_living&#39;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="n">regression_residual_plots</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">dependent_var</span><span class="o">=</span><span class="s2">&quot;price&quot;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sqft_living&#39;</span><span class="p">,</span><span class="s1">&#39;price&#39;</span><span class="p">]])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
    1. Residuals vs Fitted Plot (Test of linearity):
    - If solid red line is along y=0, assumption of linearity may hold true.

    2. Normal Q-Q plot (Test of Normality)
    - If fitted points align with 45 degree line, assumption of normality may hold true.

    3. Scale-Location Plot (Test of Constant Variance, homoskedasticity)
    - Small residuals on y-axis is better.
    - If data points are clustered at left or right, we observe heteroskedasticity.
    - If we see few outliers with high y-values, we have high variance residual outliers.

    4. Residual vs Leverage Plot (Cook&#39;s test of outliers)
    - Solid red line is leverage best fit line.
    - Dashed red line is Cook&#39;s distance for 0.5 * p * (1-x) /x
    - Dotted red line is Cook&#39;s distance for 1 * p * (1-x) /x
    - p is number of model parameters. x is plot values: np.linspace(0.001, 0.200, 50).
    - If the values exceeds the farthest dotted red line,
      it has high leverage on the dataset and may be considered outlier.

    
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c02_regression_modelling_linear_ols_statsmodels_55_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>date</th>
      <th>price</th>
      <th>bedrooms</th>
      <th>bathrooms</th>
      <th>sqft_living</th>
      <th>sqft_lot</th>
      <th>floors</th>
      <th>waterfront</th>
      <th>view</th>
      <th>condition</th>
      <th>grade</th>
      <th>sqft_above</th>
      <th>sqft_basement</th>
      <th>yr_built</th>
      <th>yr_renovated</th>
      <th>zipcode</th>
      <th>lat</th>
      <th>long</th>
      <th>sqft_living15</th>
      <th>sqft_lot15</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>16000</th>
      <td>2561340020</td>
      <td>20140804T000000</td>
      <td>325000.0</td>
      <td>3</td>
      <td>1.75</td>
      <td>1780</td>
      <td>11096</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1210</td>
      <td>570</td>
      <td>1979</td>
      <td>0</td>
      <td>98074</td>
      <td>47.6170</td>
      <td>-122.051</td>
      <td>1780</td>
      <td>10640</td>
    </tr>
    <tr>
      <th>11286</th>
      <td>8598200070</td>
      <td>20141208T000000</td>
      <td>278000.0</td>
      <td>2</td>
      <td>2.50</td>
      <td>1420</td>
      <td>2229</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1420</td>
      <td>0</td>
      <td>2004</td>
      <td>0</td>
      <td>98059</td>
      <td>47.4871</td>
      <td>-122.165</td>
      <td>1500</td>
      <td>2230</td>
    </tr>
    <tr>
      <th>3201</th>
      <td>6788200931</td>
      <td>20140520T000000</td>
      <td>710000.0</td>
      <td>2</td>
      <td>1.00</td>
      <td>1790</td>
      <td>4000</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>7</td>
      <td>1040</td>
      <td>750</td>
      <td>1923</td>
      <td>0</td>
      <td>98112</td>
      <td>47.6405</td>
      <td>-122.301</td>
      <td>1310</td>
      <td>4000</td>
    </tr>
    <tr>
      <th>11049</th>
      <td>3023059012</td>
      <td>20140910T000000</td>
      <td>389900.0</td>
      <td>4</td>
      <td>1.00</td>
      <td>1710</td>
      <td>117176</td>
      <td>1.5</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>6</td>
      <td>1710</td>
      <td>0</td>
      <td>1942</td>
      <td>0</td>
      <td>98055</td>
      <td>47.4497</td>
      <td>-122.212</td>
      <td>1940</td>
      <td>12223</td>
    </tr>
    <tr>
      <th>9716</th>
      <td>5683500030</td>
      <td>20150320T000000</td>
      <td>489000.0</td>
      <td>4</td>
      <td>1.00</td>
      <td>1150</td>
      <td>5217</td>
      <td>1.5</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1150</td>
      <td>0</td>
      <td>1951</td>
      <td>0</td>
      <td>98115</td>
      <td>47.6806</td>
      <td>-122.287</td>
      <td>1220</td>
      <td>5217</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_fit</span> <span class="o">=</span> <span class="n">results</span>

<span class="n">model_norm_residuals</span> <span class="o">=</span> <span class="n">model_fit</span><span class="o">.</span><span class="n">get_influence</span><span class="p">()</span><span class="o">.</span><span class="n">resid_studentized_internal</span>

<span class="c1"># Annotations of Outliers</span>
<span class="n">abs_norm_resid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">model_norm_residuals</span><span class="p">)),</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">abs_norm_resid_top_3</span> <span class="o">=</span> <span class="n">abs_norm_resid</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">abs_norm_resid_top_3</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>7252
3914
9254
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">bhishan.util_statsmodels</span> <span class="k">import</span> <span class="n">regression_residual_plots</span>

<span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;price ~ sqft_living&#39;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df_train</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="n">regression_residual_plots</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">dependent_var</span><span class="o">=</span><span class="s2">&quot;price&quot;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">df_train</span><span class="p">[[</span><span class="s1">&#39;sqft_living&#39;</span><span class="p">,</span><span class="s1">&#39;price&#39;</span><span class="p">]],</span><span class="n">annotate_outliers</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
    1. Residuals vs Fitted Plot (Test of linearity):
    - If solid red line is along y=0, assumption of linearity may hold true.

    2. Normal Q-Q plot (Test of Normality)
    - If fitted points align with 45 degree line, assumption of normality may hold true.

    3. Scale-Location Plot (Test of Constant Variance, homoskedasticity)
    - Small residuals on y-axis is better.
    - If data points are clustered at left or right, we observe heteroskedasticity.
    - If we see few outliers with high y-values, we have high variance residual outliers.

    4. Residual vs Leverage Plot (Cook&#39;s test of outliers)
    - Solid red line is leverage best fit line.
    - Dashed red line is Cook&#39;s distance for 0.5 * p * (1-x) /x
    - Dotted red line is Cook&#39;s distance for 1 * p * (1-x) /x
    - p is number of model parameters. x is plot values: np.linspace(0.001, 0.200, 50).
    - If the values exceeds the farthest dotted red line,
      it has high leverage on the dataset and may be considered outlier.

    
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c02_regression_modelling_linear_ols_statsmodels_58_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># lets try log transformation and plot again</span>
<span class="n">df_train</span><span class="p">[</span><span class="s1">&#39;log_sqft_living&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s1">&#39;sqft_living&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;log_sqft_living&#39;</span><span class="p">]</span>
<span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span>
<span class="n">df_X</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">df_y</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>

<span class="n">df_X1</span> <span class="o">=</span> <span class="n">df_X</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">df_y</span><span class="p">,</span> <span class="n">df_X1</span> <span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="kn">from</span> <span class="nn">bhishan.util_statsmodels</span> <span class="k">import</span> <span class="n">regression_residual_plots</span>
<span class="n">regression_residual_plots</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">dependent_var</span><span class="o">=</span><span class="s2">&quot;price&quot;</span><span class="p">,</span>
                          <span class="n">data</span><span class="o">=</span> <span class="n">df_train</span><span class="p">[[</span><span class="s1">&#39;log_sqft_living&#39;</span><span class="p">,</span><span class="s1">&#39;price&#39;</span><span class="p">]],</span>
                          <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                         <span class="n">annotate_outliers</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                         <span class="n">ofile</span><span class="o">=</span><span class="s1">&#39;../reports/figures/regression_residual_plots.png&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/poudel/miniconda3/envs/dataSc/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c02_regression_modelling_linear_ols_statsmodels_59_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="log-transformation-using-ols-formula">log transformation using ols formula<a class="anchor-link" href="#log-transformation-using-ols-formula"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Here, we do not need to give intercept term.</span>
<span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;price ~ np.log(sqft_living)&#39;</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df_train</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  price   R-squared:                       0.369
Model:                            OLS   Adj. R-squared:                  0.369
Method:                 Least Squares   F-statistic:                 1.012e+04
Date:                Fri, 18 Oct 2019   Prob (F-statistic):               0.00
Time:                        22:27:32   Log-Likelihood:            -2.4210e+05
No. Observations:               17290   AIC:                         4.842e+05
Df Residuals:                   17288   BIC:                         4.842e+05
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
=======================================================================================
                          coef    std err          t      P&gt;|t|      [0.025      0.975]
---------------------------------------------------------------------------------------
Intercept           -3.427e+06   3.95e+04    -86.762      0.000    -3.5e+06   -3.35e+06
np.log(sqft_living)  5.255e+05   5224.766    100.580      0.000    5.15e+05    5.36e+05
==============================================================================
Omnibus:                    15529.189   Durbin-Watson:                   2.014
Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1270840.426
Skew:                           3.994   Prob(JB):                         0.00
Kurtosis:                      44.234   Cond. No.                         137.
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_train</span><span class="p">[</span><span class="s1">&#39;log_sqft_living&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s1">&#39;sqft_living&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;log_sqft_living&#39;</span><span class="p">]</span>
<span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span>

<span class="n">df_X</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">df_y</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>

<span class="n">df_X1</span> <span class="o">=</span> <span class="n">df_X</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">const</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">df_y</span><span class="p">,</span> <span class="n">df_X1</span> <span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  price   R-squared:                       0.369
Model:                            OLS   Adj. R-squared:                  0.369
Method:                 Least Squares   F-statistic:                 1.012e+04
Date:                Fri, 18 Oct 2019   Prob (F-statistic):               0.00
Time:                        22:25:20   Log-Likelihood:            -2.4210e+05
No. Observations:               17290   AIC:                         4.842e+05
Df Residuals:                   17288   BIC:                         4.842e+05
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
===================================================================================
                      coef    std err          t      P&gt;|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
log_sqft_living  5.255e+05   5224.766    100.580      0.000    5.15e+05    5.36e+05
const           -3.427e+06   3.95e+04    -86.762      0.000    -3.5e+06   -3.35e+06
==============================================================================
Omnibus:                    15529.189   Durbin-Watson:                   2.014
Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1270840.426
Skew:                           3.994   Prob(JB):                         0.00
Kurtosis:                      44.234   Cond. No.                         137.
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/poudel/miniconda3/envs/dataSc/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  &#34;&#34;&#34;Entry point for launching an IPython kernel.
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># linearity does not hold much</span>
<span class="c1"># normality does not hold much</span>
<span class="c1"># heteroskedasticity is little bit improved</span>
<span class="c1"># there are no outlier leverage points</span>

<span class="c1"># we may need to include more than one features to estimate price</span>
<span class="c1"># rather than only log of living area.</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">bhishan.util_statsmodels</span> <span class="k">import</span> <span class="n">lm_residual_corr_plot</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lm_residual_corr_plot</span><span class="p">(</span><span class="n">df_X1train</span><span class="p">,</span> <span class="n">df_ytrain</span><span class="p">,</span> <span class="n">df_ypreds_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
    1. Correlation of Error Terms (Collinearity Test):
    - If the magnitude of errors increase/decrease as we go along x-axis,
      the error terms may be correlated.
    - This could mean that our estimated standard errors underestimate
      the true standard errors.
    - Our confidence and prediction intervals may be
      narrower than they should be.
    
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/c02_regression_modelling_linear_ols_statsmodels_65_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Multiple-Linear-Regression">Multiple Linear Regression<a class="anchor-link" href="#Multiple-Linear-Regression"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>date</th>
      <th>price</th>
      <th>bedrooms</th>
      <th>bathrooms</th>
      <th>sqft_living</th>
      <th>sqft_lot</th>
      <th>floors</th>
      <th>waterfront</th>
      <th>view</th>
      <th>condition</th>
      <th>grade</th>
      <th>sqft_above</th>
      <th>sqft_basement</th>
      <th>yr_built</th>
      <th>yr_renovated</th>
      <th>zipcode</th>
      <th>lat</th>
      <th>long</th>
      <th>sqft_living15</th>
      <th>sqft_lot15</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7129300520</td>
      <td>20141013T000000</td>
      <td>221900.0</td>
      <td>3</td>
      <td>1.00</td>
      <td>1180</td>
      <td>5650</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1180</td>
      <td>0</td>
      <td>1955</td>
      <td>0</td>
      <td>98178</td>
      <td>47.5112</td>
      <td>-122.257</td>
      <td>1340</td>
      <td>5650</td>
    </tr>
    <tr>
      <th>1</th>
      <td>6414100192</td>
      <td>20141209T000000</td>
      <td>538000.0</td>
      <td>3</td>
      <td>2.25</td>
      <td>2570</td>
      <td>7242</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>2170</td>
      <td>400</td>
      <td>1951</td>
      <td>1991</td>
      <td>98125</td>
      <td>47.7210</td>
      <td>-122.319</td>
      <td>1690</td>
      <td>7639</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Index([&#39;id&#39;, &#39;date&#39;, &#39;price&#39;, &#39;bedrooms&#39;, &#39;bathrooms&#39;, &#39;sqft_living&#39;,
       &#39;sqft_lot&#39;, &#39;floors&#39;, &#39;waterfront&#39;, &#39;view&#39;, &#39;condition&#39;, &#39;grade&#39;,
       &#39;sqft_above&#39;, &#39;sqft_basement&#39;, &#39;yr_built&#39;, &#39;yr_renovated&#39;, &#39;zipcode&#39;,
       &#39;lat&#39;, &#39;long&#39;, &#39;sqft_living15&#39;, &#39;sqft_lot15&#39;],
      dtype=&#39;object&#39;)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;bathrooms&#39;</span><span class="p">,</span> 
            <span class="s1">&#39;sqft_living&#39;</span><span class="p">,</span><span class="s1">&#39;sqft_lot&#39;</span><span class="p">,</span> <span class="s1">&#39;sqft_above&#39;</span><span class="p">,</span>
            <span class="s1">&#39;sqft_living15&#39;</span><span class="p">,</span> <span class="s1">&#39;sqft_lot15&#39;</span><span class="p">,</span>
            <span class="s1">&#39;floors&#39;</span><span class="p">,</span> <span class="s1">&#39;waterfront&#39;</span><span class="p">,</span> <span class="s1">&#39;view&#39;</span><span class="p">,</span> <span class="s1">&#39;condition&#39;</span><span class="p">,</span> <span class="s1">&#39;grade&#39;</span><span class="p">,</span>
           <span class="s1">&#39;yr_built&#39;</span><span class="p">,</span> <span class="s1">&#39;yr_renovated&#39;</span><span class="p">,</span> <span class="s1">&#39;zipcode&#39;</span><span class="p">,</span>
           <span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="s1">&#39;long&#39;</span> <span class="p">]</span>

<span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;price ~ &#39;</span> <span class="o">+</span> <span class="s1">&#39; + &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="n">formula</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;price ~ bedrooms + bathrooms + sqft_living + sqft_lot + sqft_above + sqft_living15 + sqft_lot15 + floors + waterfront + view + condition + grade + yr_built + yr_renovated + zipcode + lat + long&#39;</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;price ~ &#39;</span> <span class="o">+</span> <span class="s1">&#39; + &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df_train</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">print_statsmodels_summary</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
    1. R-squared (Coefficient of Determination):
    https://www.wikiwand.com/en/Coefficient_of_determination
    - R-squared = 1 - (SS_res / SS_tot)
      SS_res = sum (y_i - f_i)**2  = sum(e_i **2)
      SS_tot = sum (y_i - y_bar)**2
    - If R2 = 0.49, then, 49% of the variability of the dependent
      variable has been accounted for, and the remaining 51% of the
      variability is still unaccounted for.

    2. Adjusted R2 (R bar squared):
    - R_bar_squared = 1 - (1-R2) * (n-1) / (n-p-1)
    - The adjusted R2 can be negative.
    - It will always be less than or equal to that of R2.
    - Adjusted R2 can be interpreted as an unbiased
     (or less biased) estimator of the population R2.
    - R2 is a positively biased estimate of the population value.
      When p increases, R2 increases, but R_bar_squared may not increase.

    3. F-statistic
    https://www.wikiwand.com/en/F-test
    -  the one-way ANOVA F-test statistic is
         F = explained variance
             --------------------
             unexplained variance
    - When there are only two groups for the one-way ANOVA F-test,
      F = t**2, where t is the Student&#39;s t statistic.
    - For two models 1 and 2,
      F = (RSS1 - RSS2) / (p2-p1)
          ---------------------------
          (RSS2) / (n-p2)

    4. AIC
    https://www.wikiwand.com/en/Akaike_information_criterion
    - Akaike Information Criterion.
    - AIC = 2k - 2 ln L  where k is the number of model parameters, 
      L is log likelihood.
    - Adjusts the log-likelihood based on the number of observations
      and the complexity of the model.
    - Penalizes the model selection metrics when more independent
      variables are added.

    5. BIC
    https://www.wikiwand.com/en/Bayesian_information_criterion
    - Bayesian Information Criterion.
    - BIC = ln(n) * k - 2 ln L  where k is the number of model parameters, 
      L is log likelihood.
    - Similar to the AIC, but has a higher penalty for models with more parameters.
    - Penalizes the model selection metrics when more independent variables are added.
    -  BIC is only valid for sample size n much larger than
       the number k of parameters in the model.

    6. P &gt; |t|:
    https://www.wikiwand.com/en/P-value
    - p-value means probability value.
    - p-value means that the null-hypothesis model parameter = 0 is true.
    - If it is less than the confidence level, often 0.05,
      it indicates that there is a statistically significant
      relationship between the predictor and the response.

    7. Skewness:
    https://www.wikiwand.com/en/Skewness
    - A measure of the symmetry of the data about the mean.
    - Normally-distributed errors should be symmetrically distributed about the mean.
    - The normal distribution has 0 skew.

    8. Kurtosis:
    https://www.wikiwand.com/en/Kurtosis
    - A measure of the shape of the distribution.
    - The normal distribution has a Kurtosis of 3.
    - If kurtosis is greater than 3, curve is tall and peaked.

    9. Omnibus D’Angostino’s test:
    https://www.wikiwand.com/en/D%27Agostino%27s_K-squared_test
    - It provides a combined statistical test for the presence of skewness and kurtosis.
    - This is a goodness-of-fit measure of departure from normality,
      that is the test aims to establish whether or not the given sample
      comes from a normally distributed population.
    - The test is based on transformations of the sample kurtosis and skewness,
      and has power only against the alternatives that the
      distribution is skewed and/or kurtic.

    10. Jarque-Bera:
    https://www.wikiwand.com/en/Jarque%E2%80%93Bera_test
    - A different test of the skewness and kurtosis.
    - In statistics, the Jarque–Bera test is a goodness-of-fit test of
      whether sample data have the skewness and kurtosis
      matching a normal distribution.
    - The test is named after Carlos Jarque and Anil K. Bera.
    - The test statistic is always nonnegative.
    - If it is far from zero, it signals the data do not have a normal distribution.

    11. Durbin-Watson:
    https://www.wikiwand.com/en/Durbin%E2%80%93Watson_statistic
    - In statistics, the Durbin–Watson statistic is a test statistic
      used to detect the presence of autocorrelation at lag 1 in the residuals
    - Often important in time-series analysis.
    - A similar assessment can be also carried out with the
      Breusch–Godfrey test and the Ljung–Box test.

    12. Cond. No:
    https://www.wikiwand.com/en/Condition_number
    - The condition number of a function measures how much the output value
     of the function can change for a small change in the input argument.
    - This is used to measure how sensitive a function is to changes
      or errors in the input
    - In linear regression the condition number of the moment matrix
       can be used as a diagnostic for multicollinearity.
    - A problem with a low condition number is said to be well-conditioned.
    - A problem with a high condition number is said to be ill-conditioned.
    
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.699</td>  
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th style="background-color:#aec7e8;">  Adj. R-squared:    </th>  <td>   0.698</td>  
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th style="background-color:#c7e9c0;">  F-statistic:       </th>  <td>   2356.</td>  
</tr>
<tr>
  <th>Date:</th>             <td>Fri, 18 Oct 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   
</tr>
<tr>
  <th>Time:</th>                 <td>23:37:09</td>     <th>  Log-Likelihood:    </th> <td>-2.3571e+05</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td> 17290</td>      <th style="background-color:#bcbddc;">  AIC:               </th>  <td>4.714e+05</td> 
</tr>
<tr>
  <th>Df Residuals:</th>          <td> 17272</td>      <th style="background-color:#ffe699;">  BIC:               </th>  <td>4.716e+05</td> 
</tr>
<tr>
  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>      <td> </td>     
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     
</tr>
</table>
<table class="simpletable">
<tr>
        <td></td>           <th style="background-color:#808080;">coef</th>     <th style="background-color:#ccccff;">std err</th>      <th>t</th>      <th style="background-color:#ffd9b3;">P>|t|</th>  <th style="background-color:#ff9896;">[0.025</th>    <th style="background-color:#ff9896;">0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>     <td> 5.497e+06</td> <td>  3.3e+06</td> <td>    1.663</td> <td> 0.096</td> <td>-9.81e+05</td> <td>  1.2e+07</td>
</tr>
<tr>
  <th>bedrooms</th>      <td>-3.505e+04</td> <td> 2100.847</td> <td>  -16.681</td> <td> 0.000</td> <td>-3.92e+04</td> <td>-3.09e+04</td>
</tr>
<tr>
  <th>bathrooms</th>     <td> 4.746e+04</td> <td> 3658.519</td> <td>   12.973</td> <td> 0.000</td> <td> 4.03e+04</td> <td> 5.46e+04</td>
</tr>
<tr>
  <th>sqft_living</th>   <td>  142.2869</td> <td>    4.947</td> <td>   28.763</td> <td> 0.000</td> <td>  132.591</td> <td>  151.983</td>
</tr>
<tr>
  <th>sqft_lot</th>      <td>    0.1045</td> <td>    0.051</td> <td>    2.062</td> <td> 0.039</td> <td>    0.005</td> <td>    0.204</td>
</tr>
<tr>
  <th>sqft_above</th>    <td>   35.0195</td> <td>    4.916</td> <td>    7.123</td> <td> 0.000</td> <td>   25.383</td> <td>   44.656</td>
</tr>
<tr>
  <th>sqft_living15</th> <td>   21.1896</td> <td>    3.882</td> <td>    5.458</td> <td> 0.000</td> <td>   13.580</td> <td>   28.799</td>
</tr>
<tr>
  <th>sqft_lot15</th>    <td>   -0.3449</td> <td>    0.078</td> <td>   -4.419</td> <td> 0.000</td> <td>   -0.498</td> <td>   -0.192</td>
</tr>
<tr>
  <th>floors</th>        <td> 6793.8805</td> <td> 4035.403</td> <td>    1.684</td> <td> 0.092</td> <td>-1115.918</td> <td> 1.47e+04</td>
</tr>
<tr>
  <th>waterfront</th>    <td> 5.901e+05</td> <td>  1.9e+04</td> <td>   31.006</td> <td> 0.000</td> <td> 5.53e+05</td> <td> 6.27e+05</td>
</tr>
<tr>
  <th>view</th>          <td> 5.197e+04</td> <td> 2410.166</td> <td>   21.563</td> <td> 0.000</td> <td> 4.72e+04</td> <td> 5.67e+04</td>
</tr>
<tr>
  <th>condition</th>     <td> 2.755e+04</td> <td> 2635.735</td> <td>   10.451</td> <td> 0.000</td> <td> 2.24e+04</td> <td> 3.27e+04</td>
</tr>
<tr>
  <th>grade</th>         <td> 9.735e+04</td> <td> 2397.894</td> <td>   40.597</td> <td> 0.000</td> <td> 9.26e+04</td> <td> 1.02e+05</td>
</tr>
<tr>
  <th>yr_built</th>      <td>-2747.9351</td> <td>   80.962</td> <td>  -33.941</td> <td> 0.000</td> <td>-2906.628</td> <td>-2589.242</td>
</tr>
<tr>
  <th>yr_renovated</th>  <td>   10.0597</td> <td>    4.130</td> <td>    2.436</td> <td> 0.015</td> <td>    1.964</td> <td>   18.156</td>
</tr>
<tr>
  <th>zipcode</th>       <td> -555.7652</td> <td>   37.192</td> <td>  -14.943</td> <td> 0.000</td> <td> -628.664</td> <td> -482.866</td>
</tr>
<tr>
  <th>lat</th>           <td> 6.003e+05</td> <td>  1.2e+04</td> <td>   49.907</td> <td> 0.000</td> <td> 5.77e+05</td> <td> 6.24e+05</td>
</tr>
<tr>
  <th>long</th>          <td>-2.059e+05</td> <td> 1.46e+04</td> <td>  -14.065</td> <td> 0.000</td> <td>-2.35e+05</td> <td>-1.77e+05</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>14886.668</td> <th>  Durbin-Watson:     </th>  <td>   2.036</td>  
</tr>
<tr>
  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1534176.331</td>
</tr>
<tr>
  <th>Skew:</th>           <td> 3.632</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  
</tr>
<tr>
  <th>Kurtosis:</th>       <td>48.572</td>   <th>  Cond. No.          </th>  <td>2.17e+08</td>  
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.17e+08. This might indicate that there are<br/>strong multicollinearity or other numerical problems.
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># using sm.OLS</span>
<span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span>
<span class="n">df_Xtrain</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">df_ytrain</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>

<span class="n">df_Xtest</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">df_ytest</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>

<span class="n">df_X1train</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">df_Xtrain</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">df_ytrain</span><span class="p">,</span> <span class="n">df_X1train</span> <span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="n">print_statsmodels_summary</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">(),</span><span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/poudel/miniconda3/envs/dataSc/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.
  return ptp(axis=axis, out=out, **kwargs)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.699</td>  
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th style="background-color:#aec7e8;">  Adj. R-squared:    </th>  <td>   0.698</td>  
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th style="background-color:#c7e9c0;">  F-statistic:       </th>  <td>   2356.</td>  
</tr>
<tr>
  <th>Date:</th>             <td>Fri, 18 Oct 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   
</tr>
<tr>
  <th>Time:</th>                 <td>23:39:08</td>     <th>  Log-Likelihood:    </th> <td>-2.3571e+05</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td> 17290</td>      <th style="background-color:#bcbddc;">  AIC:               </th>  <td>4.714e+05</td> 
</tr>
<tr>
  <th>Df Residuals:</th>          <td> 17272</td>      <th style="background-color:#ffe699;">  BIC:               </th>  <td>4.716e+05</td> 
</tr>
<tr>
  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>      <td> </td>     
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     
</tr>
</table>
<table class="simpletable">
<tr>
        <td></td>           <th style="background-color:#808080;">coef</th>     <th style="background-color:#ccccff;">std err</th>      <th>t</th>      <th style="background-color:#ffd9b3;">P>|t|</th>  <th style="background-color:#ff9896;">[0.025</th>    <th style="background-color:#ff9896;">0.975]</th>  
</tr>
<tr>
  <th>const</th>         <td> 5.497e+06</td> <td>  3.3e+06</td> <td>    1.663</td> <td> 0.096</td> <td>-9.81e+05</td> <td>  1.2e+07</td>
</tr>
<tr>
  <th>bedrooms</th>      <td>-3.505e+04</td> <td> 2100.847</td> <td>  -16.681</td> <td> 0.000</td> <td>-3.92e+04</td> <td>-3.09e+04</td>
</tr>
<tr>
  <th>bathrooms</th>     <td> 4.746e+04</td> <td> 3658.519</td> <td>   12.973</td> <td> 0.000</td> <td> 4.03e+04</td> <td> 5.46e+04</td>
</tr>
<tr>
  <th>sqft_living</th>   <td>  142.2869</td> <td>    4.947</td> <td>   28.763</td> <td> 0.000</td> <td>  132.591</td> <td>  151.983</td>
</tr>
<tr>
  <th>sqft_lot</th>      <td>    0.1045</td> <td>    0.051</td> <td>    2.062</td> <td> 0.039</td> <td>    0.005</td> <td>    0.204</td>
</tr>
<tr>
  <th>sqft_above</th>    <td>   35.0195</td> <td>    4.916</td> <td>    7.123</td> <td> 0.000</td> <td>   25.383</td> <td>   44.656</td>
</tr>
<tr>
  <th>sqft_living15</th> <td>   21.1896</td> <td>    3.882</td> <td>    5.458</td> <td> 0.000</td> <td>   13.580</td> <td>   28.799</td>
</tr>
<tr>
  <th>sqft_lot15</th>    <td>   -0.3449</td> <td>    0.078</td> <td>   -4.419</td> <td> 0.000</td> <td>   -0.498</td> <td>   -0.192</td>
</tr>
<tr>
  <th>floors</th>        <td> 6793.8805</td> <td> 4035.403</td> <td>    1.684</td> <td> 0.092</td> <td>-1115.918</td> <td> 1.47e+04</td>
</tr>
<tr>
  <th>waterfront</th>    <td> 5.901e+05</td> <td>  1.9e+04</td> <td>   31.006</td> <td> 0.000</td> <td> 5.53e+05</td> <td> 6.27e+05</td>
</tr>
<tr>
  <th>view</th>          <td> 5.197e+04</td> <td> 2410.166</td> <td>   21.563</td> <td> 0.000</td> <td> 4.72e+04</td> <td> 5.67e+04</td>
</tr>
<tr>
  <th>condition</th>     <td> 2.755e+04</td> <td> 2635.735</td> <td>   10.451</td> <td> 0.000</td> <td> 2.24e+04</td> <td> 3.27e+04</td>
</tr>
<tr>
  <th>grade</th>         <td> 9.735e+04</td> <td> 2397.894</td> <td>   40.597</td> <td> 0.000</td> <td> 9.26e+04</td> <td> 1.02e+05</td>
</tr>
<tr>
  <th>yr_built</th>      <td>-2747.9351</td> <td>   80.962</td> <td>  -33.941</td> <td> 0.000</td> <td>-2906.628</td> <td>-2589.242</td>
</tr>
<tr>
  <th>yr_renovated</th>  <td>   10.0597</td> <td>    4.130</td> <td>    2.436</td> <td> 0.015</td> <td>    1.964</td> <td>   18.156</td>
</tr>
<tr>
  <th>zipcode</th>       <td> -555.7652</td> <td>   37.192</td> <td>  -14.943</td> <td> 0.000</td> <td> -628.664</td> <td> -482.866</td>
</tr>
<tr>
  <th>lat</th>           <td> 6.003e+05</td> <td>  1.2e+04</td> <td>   49.907</td> <td> 0.000</td> <td> 5.77e+05</td> <td> 6.24e+05</td>
</tr>
<tr>
  <th>long</th>          <td>-2.059e+05</td> <td> 1.46e+04</td> <td>  -14.065</td> <td> 0.000</td> <td>-2.35e+05</td> <td>-1.77e+05</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>14886.668</td> <th>  Durbin-Watson:     </th>  <td>   2.036</td>  
</tr>
<tr>
  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1534176.331</td>
</tr>
<tr>
  <th>Skew:</th>           <td> 3.632</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  
</tr>
<tr>
  <th>Kurtosis:</th>       <td>48.572</td>   <th>  Cond. No.          </th>  <td>2.17e+08</td>  
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.17e+08. This might indicate that there are<br/>strong multicollinearity or other numerical problems.
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">rsquared</span><span class="p">,</span> <span class="n">results</span><span class="o">.</span><span class="n">rsquared_adj</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(0.6987007086088071, 0.6984041541881465)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Polynomial-Regression">Polynomial Regression<a class="anchor-link" href="#Polynomial-Regression"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;price ~ np.log(sqft_living)&#39;</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df_train</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  price   R-squared:                       0.369
Model:                            OLS   Adj. R-squared:                  0.369
Method:                 Least Squares   F-statistic:                 1.012e+04
Date:                Fri, 18 Oct 2019   Prob (F-statistic):               0.00
Time:                        22:30:14   Log-Likelihood:            -2.4210e+05
No. Observations:               17290   AIC:                         4.842e+05
Df Residuals:                   17288   BIC:                         4.842e+05
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
=======================================================================================
                          coef    std err          t      P&gt;|t|      [0.025      0.975]
---------------------------------------------------------------------------------------
Intercept           -3.427e+06   3.95e+04    -86.762      0.000    -3.5e+06   -3.35e+06
np.log(sqft_living)  5.255e+05   5224.766    100.580      0.000    5.15e+05    5.36e+05
==============================================================================
Omnibus:                    15529.189   Durbin-Watson:                   2.014
Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1270840.426
Skew:                           3.994   Prob(JB):                         0.00
Kurtosis:                      44.234   Cond. No.                         137.
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;price ~ np.log(sqft_living) + np.power(np.log(sqft_living),2)&#39;</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df_train</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  price   R-squared:                       0.499
Model:                            OLS   Adj. R-squared:                  0.499
Method:                 Least Squares   F-statistic:                     8604.
Date:                Fri, 18 Oct 2019   Prob (F-statistic):               0.00
Time:                        22:30:58   Log-Likelihood:            -2.4011e+05
No. Observations:               17290   AIC:                         4.802e+05
Df Residuals:                   17287   BIC:                         4.802e+05
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
====================================================================================================
                                       coef    std err          t      P&gt;|t|      [0.025      0.975]
----------------------------------------------------------------------------------------------------
Intercept                         2.648e+07   4.49e+05     59.040      0.000    2.56e+07    2.74e+07
np.log(sqft_living)              -7.435e+06   1.19e+05    -62.422      0.000   -7.67e+06    -7.2e+06
np.power(np.log(sqft_living), 2)   5.28e+05   7893.686     66.886      0.000    5.13e+05    5.43e+05
==============================================================================
Omnibus:                    11316.265   Durbin-Watson:                   2.017
Prob(Omnibus):                  0.000   Jarque-Bera (JB):           387529.438
Skew:                           2.649   Prob(JB):                         0.00
Kurtosis:                      25.580   Cond. No.                     1.36e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.36e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_train</span><span class="o">.</span><span class="n">columns</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Index([&#39;id&#39;, &#39;date&#39;, &#39;price&#39;, &#39;bedrooms&#39;, &#39;bathrooms&#39;, &#39;sqft_living&#39;,
       &#39;sqft_lot&#39;, &#39;floors&#39;, &#39;waterfront&#39;, &#39;view&#39;, &#39;condition&#39;, &#39;grade&#39;,
       &#39;sqft_above&#39;, &#39;sqft_basement&#39;, &#39;yr_built&#39;, &#39;yr_renovated&#39;, &#39;zipcode&#39;,
       &#39;lat&#39;, &#39;long&#39;, &#39;sqft_living15&#39;, &#39;sqft_lot15&#39;, &#39;log_sqft_living&#39;],
      dtype=&#39;object&#39;)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bedrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;bathrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;sqft_living&#39;</span><span class="p">,</span>
       <span class="s1">&#39;sqft_lot&#39;</span><span class="p">,</span> <span class="s1">&#39;floors&#39;</span><span class="p">,</span> <span class="s1">&#39;waterfront&#39;</span><span class="p">,</span> <span class="s1">&#39;view&#39;</span><span class="p">,</span> <span class="s1">&#39;condition&#39;</span><span class="p">,</span> <span class="s1">&#39;grade&#39;</span><span class="p">,</span>
       <span class="s1">&#39;sqft_above&#39;</span><span class="p">,</span> <span class="s1">&#39;sqft_basement&#39;</span><span class="p">,</span> <span class="s1">&#39;yr_built&#39;</span><span class="p">,</span> <span class="s1">&#39;yr_renovated&#39;</span><span class="p">,</span> <span class="s1">&#39;zipcode&#39;</span><span class="p">,</span>
       <span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="s1">&#39;long&#39;</span><span class="p">,</span> <span class="s1">&#39;sqft_living15&#39;</span><span class="p">,</span> <span class="s1">&#39;sqft_lot15&#39;</span><span class="p">,</span> <span class="s1">&#39;log_sqft_living&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;log_sqft_living&#39;]</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

 


    </main>
    